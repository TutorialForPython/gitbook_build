{"./":{"url":"./","title":"Introduction","keywords":"","body":"python攻略 起因 python3.5+攻略,3.5以后新加了大量特性和语法糖,关键的关键字async和await和其代表的原生的协程. typehint,zipapp等实用工具再加上本身字符串的语义变化和metaclass的语法变化. python3.5已经可以说是一门与2难以兼容的新语言了. 虽然python2于3其设计思路和数据模型没有本质变化,但这些变化足以让人不适应. 而新的实用工具也让我看到了全面迁移向python3的意义.为了自己熟悉python3也为了安利.才有了这样一份攻略. 为什么定在python3.5? python3出来很久了,但在3.5版本之前使用上与python2将差无几,3.5版本是个转折点. 定在3.5的原因有以下这些: 新增了async await和原生的协程概念,不再与生成器混淆使用且无法向前兼容, 使用原生协程的异步框架和工具现在也都出现了,数量不少发展也算迅速,也已经出现了uvloop这种大规模提高异步事件循环性能的包. 新增了type hint,虽然只是注释语法,但可以配合一些工具做类型检测,类似typescript, 以后很可能会有jit支持,cython的一个issue中也提到打算利用这一特性搞点事,目前无法向前兼容 zipapp工具的出现,为应用分发提供了良好的支持,配合自带的虚拟环境已经可以做到比较不错的环境隔离,大大降低了运维成本 metaclass早就无法向前兼容了,string的语义变化也无法向前兼容 numpy系列科学工具包在python3.5上很稳定很成熟,而且新的矩阵乘法运算符@numpy也支持 目前windows上的tensorfolw只支持3.5版本 pypy目前正在开发针对3.5版本的pypy3.现在在beta版本,估计近两年会成熟. 为什么不是3.6? 2017年初python3.6版本发布了,它也确实有些令人欣喜的语法糖,但并没有3.5的冲击巨大,且都有替代方式实现.基于3.5写的代码可以保证在python3.6上使用,而相反却不行. 3.5之后版本的特性也会写出来,但会做出标记,如果以后哪个版本又有了关键字层面或者大的语法层面的改变,本教程也会迁移过去. 怎么学python3.5+? 首先,忘记python2.7,忘记3.5-的python怎么用的,从头开始学.本教程也不会有与之前的对比.一切从新开始 其次,边做边练,本教程并不打算像之前一样先浅再深分级别来讲,也不打算脱离标准库或者一些\"半标准\"的实用库,然后库介绍另起炉灶讲,本教程的写法可能更像 但面向的层面更低些. 善用help()方法,和之前的教程不同本教程不罗列api,光介绍工具和使用场景,细节api请自己help()查看 边学边玩跟例子做,本文代码托管在github上可以自己下下来自己本地跑, 我就不提供服务器端的运行环境了,怕脚本注入. 学了能干嘛? python3.5+貌似没什么大公司在用,也没见啥大项目是基于3.5开发的,那学了干嘛? 简单说这种问题太功利了,学一门编程语言目的当然是编程,python在所有计算机语言中都算是好学好用的, 自己写东西感觉是很方便的. 具体来说有以下几点: 成熟: 因为有悠久的历史,遗产很多,虽然3.5版本的代码很多时候不能让之前的版本兼容, 但大多数时候3.5以上的版本都可以向下兼容之前的老代码.当然了因为历史原因这些代码一般都是同步阻塞的基于线程模型, 异步工具就比较少了,这点和js不同. 有一套自己的规范和哲学但又非常灵活: 我们可以和javascript以及java对比下: java出了名的呆板,javadoc,设计模式,规范到千人一面,瀑布式的开发方式非常依赖架构师,用户写java没有乐趣可言 js则是另一个极端,js项目碎片化比android手机都厉害,光模块化编程的方案就一大堆,浏览器支持和语法实现也进度各异,虽然v8引擎强无敌, node.js单核性能优异内存消耗很小,但老实说js不好学,为啥?没有规范,没人告诉你什么情况下该用啥,选择太多意味着无从选择. 虽然新版本标准语法很cool,箭头函数,不变量,但身为一个脚本语言为了适配不同的浏览器,代码竟然要编译后才能运行... 如果想真当脚本一样写,可能用户只能使用简陋的低版本语法,没有const,没有箭头函数,甚至变量作用域连块的概念都没有. 老实说写ES6或者typescript代码很爽,非常灵活.但就是因为规范没有权威性而非常扯淡. python有官方实现,有规范的pep文档,多数东西都是官方的,有规范.而非官方的实现往往都只是替代方案.总的来说,规范性上非常靠谱. 而且多数规范是非强制的,只是因为代码风格的问题不自觉的用户就会去遵循规范. 而语法上,糖够多,写起来方便,不用考虑大括号,逗号这些问题,由于是鸭子类型完全面向对象,python代码灵活性很高,但也不会高到看起来像天书. 因为规范和本身的缩进语法,代码看起来一目了然,当然代价就是匿名函数只能一行. 语法简单便于维护:我们写个啥最怕过了几个月不知道自己写的是啥了,而python的缩进语法强制性的让你的代码有条理, 文档生成工具也非常成熟,按规范写好注释的情况下都不需要额外的做文档工作. 本文包括些什么? 工具链 基本用法 python的对象模型 元编程 python的并发模型 python与C/C++语言扩展 我尽量让各个部分内聚避免耦合,这样可以不用按顺序看 那么好了开始吧! Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-08 00:26:39 "},"总章.html":{"url":"总章.html","title":"总章","keywords":"","body":"总章 就像九阴真经秘籍一样,总章部分讲的是python这门语言的\"内功\",也就是其设计哲学.python虽然现在很潮,但看现在的版本号和第三方包生态也知道其实这门语言挺古老的.回顾历史上种种编程语言,大多都是昙花一现,但最终还是被埋没在历史的长河中,能长期发展并逐渐构建出一个庞大而有活力的社区的屈指可数.一门语言能经久不衰一定会有其内在原因,而这往往与其设计哲学有相当大的关系.就像搞革命,胜利往往是思想的胜利. 设计哲学 每次给人安利python我都会搬出来python的设计主旨,不废话看下面 import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! python强调实用性,一致性和中庸,奉行少即是多的哲学思想.在这门编程语言的任何地方都可以看到这种设计哲学. 代码可读性 高质量代码有三要素：可读性、可维护性、可变更性.python设计思想非常强调可读性,很多人把它当做能运行的伪代码用.这也是为啥很多非计算机专业的人学习使用python的原因,没有难以阅读的符号,一切看起来就和英语差不多,加上缩进,天然的条理清晰容易理解. 胶水语言 很多人觉得python慢,但他们忽略了python是除lua外最易使用C语言扩展的胶水语言.在多数情况下python的性能足够使用,而在性能遇到瓶颈时可以找到短板将其用C重写以获得性能提升. 在计算密集型应用中python借助其良好的扩展性用哟很大的作为. python是当今最流行的开源科学计算语言之一,开源语言中唯一能在科学计算方面与之匹敌的是r语言;tensorflow,theano等深度学习使用的高性能GPU符号计算工具都是以python作为语言平台的.与之竞争的只有C++的caffe和lua的torch. 在i/o密集型应用中python同样优秀.借助协程和uvloop,单进程下python服务器可以达到惊人的吞吐量和极短的响应时间.而uvloop是利用cython和libuv实现的事件循环.本质上是一个优秀的C扩展. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-17 23:15:20 "},"工具链/":{"url":"工具链/","title":"工具链","keywords":"","body":"Python的环境与工具链 在就像java有maven这些,js有npm这些,现代编程语言都有一套配套的工具链来配合开发流程.这套流程主要会包括如下几个部分: 运行环境,包管理,部署,文档与分发 代码风格和类型检验 测试调试工具 目前python并没有一个统一的官方的工具,但在各自的方面,python却有一套很成熟的工具链.并且他们之间配合的不错. 本章节建议新手先只关注 运行环境的搭建 包管理 选看 代码风格 其他的部分有一定基础了再回头看不迟, Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"工具链/运行环境与部署分发.html":{"url":"工具链/运行环境与部署分发.html","title":"运行环境与部署分发","keywords":"","body":"运行环境的搭建 python的运行环境当然是只要去官网下载对应版本安装即可,注意,我们这边只讲3.5以上的版本,因此不要下载错了!安装好后要注意环境变量的配置,具体的可以参看官方说明. Anaconda集成环境 更好的工具是使用Anaconda集成环境,这样就可以省去很多配置环境呀,配置依赖的问题,它也可以自动将你的python环境放入系统环境变量,省去了手工配置的麻烦.国内访问Anaconda会比较坑爹,好在有清华的镜像 Anaconda是一个全平台的常用于科学计算的python继承环境包.自带虚拟环境工具,python的版本管理和包管理.用它来安装python可以保证python的隔离性,并且它自带的包足够全面好用.如果嫌弃它太重,那么可以安装miniconda.依然是全平台支持,只是少了自带的包而已. Anaconda的就是下载好后bash (windows就是直接双击打开了) 然后一路设置就好(完全可以全默认). 在墙内的我们最好将清华的源设置为默认,linux,mac用户编辑~/.condarc,windows用户编辑C:\\Users\\\\.condarc,输入如下内容即可. channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - defaults show_channel_urls: yes 这个设置文件windows下默认无法创建,所以必须借助第三方的文本编辑器,这边推荐atom,一些小技巧可以在我的相关文章中找到. 如何验证python是否安装成功呢? 打开terminal,window是cmd,之后输入python -V,就可以看到形如Python 3.6.0 :: Anaconda 4.3.1 (64-bit)这样的字样了,如果是Anaconda安装的,也可以在这条信息中看到Anaconda的版本. *关于pypy pypy是现今活下来的cpython外最好的python实现,它使用jit技术,因此比cpython快的不是一星半点.有测试pypy的io效率与node相当,而cpu密集型任务如果使用python自带的数据结构也比原生cpython快上2~3倍.现在对python3.5有个beta版本的支持,目前还不太完善. 抛开这些不说,pypy的c扩展能力很差,许多带c扩展的模块要么无法在其上使用,要么比在cpython上慢很多.因此可以关注,但并不推荐使用 *关于docker docker有官方的python镜像,我们可以直接取来用,如何使用这个镜像创建python应用的镜像并运行可以看我的这篇文章,具体的docker怎么用,那是另一个故事了. 虚拟环境 我们希望项目的环境依赖是独立隔离的,每个项目间各自不会影响其他的项目,最成熟传统的做法就是使用虚拟环境了.虚拟环境可以理解为node.js中npm工具的本地安装,他会把用到的包包括python的虚拟机都放到你指定的目录下,在一个terminal进程中只要你激活了那个虚拟环境,你用到的与python相关联的东西就都是虚拟环境中的了. python3中自带了工具pyvenv(PEP 405)来构建虚拟环境,而如果希望统一的管理虚拟环境,则Anaconda提供的虚拟环境功能可能更加合适 pyvenv使用方法 pyvenv 创建虚拟环境到指定目录 source /bin/activate 使用虚拟环境,在windows下是 /bin/activate.bat 激活后会看到你的命令行每行前面多出一个(venv)字样，表示你在使用虚拟环境 deactivate 退出虚拟环境 Anaconda虚拟环境和多版本的管理 ananconda也有虚拟环境工具,而且可以通过虚拟环境实现多版本python的管理使用,也就是说Anaconda的虚拟环境工具除了创建虚拟环境,还是python的版本控制工具. 创建虚拟环境 conda create -n python= [collection] 输入以上命令我们就建立了一个以为名字的虚拟环境,并且代码和虚拟机都将放在/envs/文件夹下.我们需要指定python的版本,如果想顺便把一些要用的包装了,可以在[collection]位置加上要的包. 激活虚拟环境 Anaconda的虚拟环境激活不需要我们记住虚拟环境创建在哪里,只要记住名字就行 在linux或者mac上使用source activate ,在windows上使用activate 即可,需要注意的是windows下的powershell shell有一个bug,无法激活虚拟环境,要使用的话记得切换到cmd. 退出虚拟环境 在linux或者mac上使用source deactivate,在windows上使用deactivate就可以退出当前的虚拟环境了 查看有哪些虚拟环境 conda env list 要删除一个虚拟环境 conda remove -n --all 包管理与模块 现代的编程场景早已从单打独斗的个人行为转向了多人合作集体行为.而现代编程语言也都有模块化支持以适应模块化的项目编程.python作为一门历史悠久的现代编程语言拥有让许多优秀的第三方包.现如今多数优质的第三方模块都注册在pip上可以很方便的下载安装.而github的兴起也促进了python社区的繁荣,每年都会有很多新的优秀的第三方模块进入pythoner的视野中. 历史悠久的同样意味着历史包袱.与javascript的npm相比,pip并不优秀,而由于python的版本割裂问题,也造成了许多第三方库无法向后兼容,但由于python语言尽量坚持一致性原则和实用至上的理念,python的第三方包相对整体质量更高也更易于定制.因此可以说python的包管理在现今看来依然是实用高效的. python方便的模块引入语法简洁实用,配合第三方库可以让用户有着如同玩乐高积木一般的优秀体验.javascript的ES6语法中模块引入语法很大程度上借鉴了python的模块语法. 包管理 python最常用的包管理工具就是官方的pip,当然Anaconda的conda命令也可以作为包管理工具使用,而且可能更加方便一些,但其实conda命令下载安装python的包也是用的pip. pip pip是python的官方第三方包管理工具(PEP 453)，收录了大部分的第三方包。多数自带python的系统如mac osx， ubuntu都已经有现成的pip安装着了。如果确实没有pip可以去https://pip.pypa.io/en/latest/installing.html#python-os-support 下载get-pip.py文件,下载到本地后，cd到同一文件夹下使用python get-pip.py安装.基本上不会有人不装pip,因为如果不用它,python就少了很多便利性 pip基本使用: pip命令可以单独作为脚本命令使用如pip list,也可以配合python解释器使用python -m pip list 后一种方式的好处是可以在不同的python环境使用pip,pip会自己把模块安装到指定python的第三方包文件夹下 安装模块 pip install packageName 下载并安装最新的版本 pip install packageName==1.0.0下载并安装指定版本 pip install 'packageName>=1.0.0 下载并安装至少某个版本以上的版本的包 pip install url #从指定网址资源安装 pip install path #指定本地位置安装 pip install --find-links=url 从指定url下载安装 pip install --find-links=path 从指定path下载安装 pip install --upgrade packageName 更新一个已经安装过的过期模块 从需求文件安装模块 pip freeze > requirements.txt 将当前pip管理的模块信息存储进文本文件 pip install -r requirements.txt 从文本文件安装依赖的模块 卸载 pip uninstall 查找 pip search 查看模块信息 pip show 查看pip管理了哪些模块 pip list pip list --outdated 查看过期的模块 关于pip的国内源设置 感谢天朝的伟大电子长城,我们很多时候无法练到pypi的服务器,还好国内豆瓣有个一直在维护的镜像站可以提供源作为替代 如何设置呢? 在你的个人根目录下有一个.pip文件夹(没有就自己建个),在其中新建一个pip.conf文件作为配置文件,然后在其中填上如下内容: [global] index-url = http://pypi.douban.com/simple trusted-host = pypi.douban.com conda 包管理工具 Anaconda的定位是数据科学工具箱,它其实并不局限于python. 我们的pip和conda并不冲突,而conda实际上也是依赖于pip工具的,用conda的好处是: 有些复杂的安装过程他会帮你省去, 可以用它安装一些Anaconda公司的商业工具 它对于包版本的追踪更加细致. 可以用它安装一些不是python包的工具,尤其一些C/C++工具,比如windows下的minwg. 和pip一样,conda list是查看已安装包信息的工具 而查找包还是conda search 要安装也还是conda install,只是它可以加上参数--name 来为特定环境跨环境安装包 而删除包就和pip有所不同了,它使用的是conda remove 命令. 包分发 无论使用哪种方式管理python的第三方模块,如果想将自己的包分发出去与别人共享,都应该使用官方的pypi平台.和npm一样,作为开发者,你需要先注册才可以上传代到代码库.注册的时候注意,password必须大于16位,PGPkeyID可以不填. 表单提交好后登入邮箱验证即可注册完成. 包管理文件(setup.py) 安装脚本setup.py就类似npm的package.json,它负责设定包的基本信息和依赖,以下是一个官方的例子的改版 setup.py: # 一般用setuptools from setuptools import setup, find_packages,Command # 维持不同平台文件相同的编码 from codecs import open import distutils from os import path import os import subprocess here = path.abspath(path.dirname(__file__)) # 用同文件夹下的README.rst文件定义长介绍 with open(path.join(here, 'README.rst'), encoding='utf-8') as f: long_description = f.read() # 用同文件夹下的requirements.txt文件定义运行依赖 with open(path.join(here, 'requirements.txt'), encoding='utf-8') as f: REQUIREMETS = f.readlines() packages=find_packages(exclude=['contrib', 'docs', 'test']) class CoverageCommand(Command): description = \"覆盖率\" user_options = [ (\"output=\",\"o\",\"选择报告的输出方式\") ] def initialize_options(self): self.cwd = None self.output = '' def finalize_options(self): self.cwd = os.getcwd() if self.output and self.output not in (\"report\",\"html\"): raise Exception(\"Parameter --output is missing\") def run(self): assert os.getcwd() == self.cwd, 'Must be in package root: {self.cwd}'.format(self=self) command = ['/usr/bin/env', 'python', '-m', 'coverage'] if self.output: command.append('{self.output}'.format(self=self)) else: command.append('report') self.announce('Running command: {command}'.format(command = str(command)), level=distutils.log.INFO) subprocess.check_call(command) class TestCommand(Command): description = \"测试\" user_options = [] def initialize_options(self): self.cwd = None def finalize_options(self): self.cwd = os.getcwd() def run(self): assert os.getcwd() == self.cwd, 'Must be in package root: {self.cwd}'.format(self=self) command = ['/usr/bin/env', 'python', '-m', 'coverage','run' ,'--source=score_card_model', '-m', 'unittest', 'discover', '-v', '-s', 'test'] self.announce('Running command: {command}'.format(command = str(command)), level=distutils.log.INFO) subprocess.check_call(command) setup( name='score_card_model', version='0.0.1', description='A sample Python project', long_description=long_description, # 项目地址 url='https://github.com/pypa/sampleproject', # 作者信息 author='The Python Packaging Authority', author_email='pypa-dev@googlegroups.com', # 维护者信息 maintainer = \"\", maintainer_email = \"\", # 指定可用的平台,一般有c扩展的可能会用到 platforms = [\"any\"], # 许可证信息 license='MIT', # 分类信息,具体看 https://pypi.python.org/pypi?%3Aaction=list_classifiers classifiers=[ # 发展时期,常见的如下 # 3 - Alpha # 4 - Beta # 5 - Production/Stable 'Development Status :: 3 - Alpha', # 开发的目标用户 'Intended Audience :: Developers', # 属于什么类型 'Topic :: Software Development :: Build Tools', # 许可证信息 'License :: OSI Approved :: MIT License', # 目标python版本 'Programming Language :: Python :: 2', 'Programming Language :: Python :: 2.7', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.3', 'Programming Language :: Python :: 3.4', 'Programming Language :: Python :: 3.5', ], # 关键字 keywords='sample setuptools development', # 指定用到的模块,find_packages会找到同文件夹下的模块,用`exclude`指定排除的模块 packages=packages, # 运行时使用的依赖 install_requires=REQUIREMETS, # 是否支持直接引用zip文件,这是setuptools的特有功能 zip_safe=False, # 额外环境的依赖,一般不单独用文件指出 # for example: # pip install -e .[dev,test] # extras_require={ # 'dev': ['check-manifest'], # 'test': ['coverage'], # }, # 指定可执行脚本,如果安装,脚本会被放到默认安装路径 #scripts=[\"scripts/test.py\"], # 模块如果有自带的数据文件,可以用package_data指定 #package_data={ # 'sample': ['package_data.dat'], #}, # 指定模块自带数据所在的文件夹 data_files=[('./', ['requirements.txt'])], # 定义自定义命令 cmdclass = { 'coverage':CoverageCommand, 'test':TestCommand } ) 定义setup.py的子命令 类似package.json,setup.py也可以定义子命令,就是相比node.js的要稍微麻烦些.需要继承setuptools.Command, 需要重写其中的元素: description 描述字符串 user_options 保存子参数设置的列表,每个元素为一个3元的元组,第一位为全称(--xxx),第二位为简称(-o),第三位为描述文字 [(\"output=\",\"o\",\"选择报告的输出方式\")] 其中的方法 initialize_options(self) 初始化子参数self.output = '' finalize_options(self) 判断命令行与设置的匹配与否和后续操作if self.output and self.output not in (\"report\",\"html\"): raise Exception(\"Parameter --output is missing\") run(self) 运行逻辑 assert os.getcwd() == self.cwd, 'Must be in package root: 安装模块 python setup.py install 关于重复造轮子 python提倡任何事务总有一种最好的方式实现,并不鼓励重复造轮子(虽然事实上python重复的轮子相当多,官方与社区也总会有意见不统一的情况发生).自己写一些模块固然可以,但最好还是先看看有没有现成的实现. *关于版本号 pep-440定义了符合python规范的版本号格式.当然了这不是强制要求,你要是喜欢也可以按npm的规范定义版本号,或者自己定义一套规范.最重要的是不能有歧义而且便于管理.当然了更加推荐按照pep-440的规范定义版本号. *将包注册到pypi服务器 完成pypi上的注册,并定义好setup.py脚本后就可以将自己写的模块上传到pypi服务器上了. 注册包 cd到 项目根目录 python setup.py register 用刚才注册的信息来注册本台电脑 注意直接这样会有可能报错,因为和原来有个名字太接近了. 我们应该先检查下名字 pip search 用来查看有哪些相关的包,我们得确定没有重名 上传 Python setup.py sdist upload *使用wheel分发包 wheel是官方钦定的包分发格式,它本质上是一个zip包,使用.whl作为扩展名. wheel提供了一个bdist_wheel作为 setuptools 的扩展命令，这个命令可以用来生成wheel包。 python setup.py bdist_wheel pip提供了对wheel的支持,setup.cfg 可以用来定义 wheel 打包时候的相关信息。 *本地架设pypi服务器 很多时候我们会有这样一种需求,我们希望我们的包私有或者在小范围内传播,这时候我们就可以架设本地的pypi服务器了 本地架设pypi服务器可以使用pypiserver或者localshop他们用法差不多,不同之处在于前者更轻些,而后者除了可以本地架设pypi服务器外还可以自动镜像pypi的包仓库. 模块导入 python中模块和包是一个意思.一个.py文件就是一个模块,如果模块复杂,那么带有__init__.py的文件夹也是一个模块.模块中可以嵌套模块以构建为一个更为复杂的模块. python的模块引入使用的是import语句.具体有3种形式: import package from package import object from package import object as name 而引入机制可以分为两种: 相对引入 完全引入 相对引入 相对引入中一个点号来标识引入类库的精确位置。与linux的相对路径表示相似，一个点表示当前目录，每多一个点号则代表向上一层目录. from .string import a from ..string import a from ...string import a 相对引入使用被引入文件的__name__ 属性来决定该文件在整个包结构的位置。那么如果文件的__name__没有包含任何包的信息，例如__name__被设置为了__main__，则认为其为top level script，而不管该文件的位置，这个时候相对引入就没有引入的参考物. 完全引入 完全引入，非常类似于Java的引入进制, 完全引用是Python的默认的引入机制.它的使用方法如下: from pkg import foo from pkg.moduleA import foo 要注意的是，需要从包目录最顶层目录依次写下，而不能从中间开始. 两种引用方式各有利弊。绝对引用代码更加清晰明了，可以清楚的看到引入的包名和层次，但是，当包名修改的时候，我们需要手动修改所有的引用代码。相对引用则比较精简，不会被包名修改所影响，但是可读性较差，不如完全引用清晰。 PYTHONPATH PYTHONPATH是Python搜索路径，默认我们import的模块都会从PYTHONPATH里面寻找。 使用下面的代码可以打印PYTHONPATH： import os print(os.sys.path) ['', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\python36.zip', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\DLLs', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib', 'C:\\\\Users\\\\87\\\\Anaconda3', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages\\\\setuptools-27.2.0-py3.6.egg', 'C:\\\\Users\\\\87\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\87\\\\.ipython'] 我们的python解释器引入模块就是按这个list的顺序一个一个查找的.因此如果希望修改查找顺序或者将特定位置加入搜索路径,只要将它加入os.sys.path中即可 部署 python有一套完善的项目部署方案,从打包到环境隔离,再到监控,一应俱全.如果没有特殊需求,完全可以跳过容器直接使用.当然了如果运维希望使用docker这类容器部署以限制各个项目的资源使用量时,得益于zipapp和pip,python也同样简单易于部署. 打包与分发 python3.5提供了一种打包分发的方式--zipapp(PEP 441).它可以将写好的项目打包成.pyz文件,这样就可以简单的将项目四处分发了.注意,这种方式最好是打包纯python代码,这样不容易因为平台不同而出现无法使用的情况.如果有c扩展,那么最好单独抽出来写成模块利用pip单独安装. .pyz文件并不能独立运行,依然依赖python环境.因此如果不用docker打包的话最好使用虚拟环境让项目在虚拟环境中运行. zipapp的用法如下: python -m zipapp myapp -m \"myapp:main\" myapp是一个项目文件夹,并非模块,我们使用-m指定使用其中的哪个模块的哪个方法作为入口 同时也可以使用-p指定一个字符串作为Shebang python -m zipapp myapp -m \"myapp:main\" -p \"/user/bin/env python3\" zipapp本质是一个用zip打包项目的工具,它的定位其实是简化版jar.一个打包好的二进制文件远比文件夹好分发使用.这也是go语言的核心竞争力之一.现在python有了这样一个工具,虽然使用起来还是要配合虚拟机和pip包管理工具,但已经很够用了. 使用虚拟环境部署 项目部署运行时不可能通过常规手段激活虚拟环境.而事实上也不需要,其实要使用虚拟环境只要指定好用虚拟环境的python解释器运行项目了.比如有个虚拟环境建在~/VENV文件夹.那么就可以直接使用这个文件夹下的python解释器直接使用. ~/VENV/bin/python myapp.pyz *批量部署 python的运维神器fabric,用它可以实现对远程服务器的批量部署操作 一些使用方法和心得可以看我的博客 *服务监控 python的另一运维神器supervisor,配合cesi可以很好的监控管理项目进程.具体的可以看我的这篇博文 日志工具 代码检查,debug,调优都只能让代码确保当时是可靠的,一些复杂的关联错误,也可能让这些测试呀debug呀失准,,而只有日志才能长期的帮助我们监控项目的健壮性.这种时候就可以使用标准库logging为程序的运行做记录,在试运行之后通过分析logging记录的方式来debug. 在logging框架下首先我们需要初始化一个logger来处理log,之后通过添加handler,Formatter和config子属性来自定义我们的logger. 一个简单的例子 import logging import sys #日志的名字,会在每行的一开始写 logger = logging.getLogger(\"endlesscode\") #格式化 formatter = logging.Formatter('%(name)-12s %(asctime)s %(levelname)-8s %(message)s', '%a, %d %b %Y %H:%M:%S',) #设定输出文件 file_handler = logging.FileHandler(\"src/test.log\") #为handler设置输出格式 file_handler.setFormatter(formatter) #流控制,将信息输出到标准流输出 stream_handler = logging.StreamHandler(sys.stderr) #为logger设置handler logger.addHandler(file_handler) #发送信息到流 logger.addHandler(stream_handler) #设置报错等级 #logger.setLevel(logging.ERROR) #报错 logger.error(\"w\") #移除handler logger.removeHandler(stream_handler) #报错 logger.error(\"f\") w 其中 level: 设置日志级别，默认为logging.WARNING stream: 指定将日志的输出流，可以指定输出到sys.stderr,sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略 输出文本的格式化 元素 格式化字符串 描述 args 不用格式化 参数会是一个元组 asctime %(asctime)s 可读的时间 created %(created)f 记录的创建时间 filename %(filename)s 文件名 funcName %(funcName)s 函数名 levelname %(levelname)s 错误,警报等的名字 levelno %(levelno)s 错误,警报等,是预警等级 lineno %(lineno)d 报错行数 module %(module)s 报错模块 msecs %(msecs)d 毫秒级的出错时间 message %(message)s 错误信息 name %(name)s log的名字 pathname %(pathname)s 报错文件所在path process %(process)d 进程id processName %(processName)s 进程名 relativeCreated %(relativeCreated)d 微秒级的报错时间 thread %(thread)d 线程id threadName %(threadName)s 线程名 日志回滚 日志也不是一直记录就好,也要考录时效性和存储空间的限制,回滚机制便是解决这个问题的 from logging.handlers import RotatingFileHandler #定义一个RotatingFileHandler，最多备份5个日志文件，每个日志文件最大10M Rthandler = RotatingFileHandler('src/myapp.log', maxBytes=10*1024*1024,backupCount=5) Rthandler.setLevel(logging.INFO) formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s') Rthandler.setFormatter(formatter) logging.getLogger('').addHandler(Rthandler) 几种handler StreamHandler(stream=None) 流输出 FileHandler(filename, mode='a', encoding=None, delay=False) 写入文件 WatchedFileHandler(filename[, mode[, encoding[, delay]]]) 监控log文件 RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=0) 轮替日志,根据日志文件的大小来循环 TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None) 轮替日志,根据时间来循环,interval参数可选的值有: \"S\"-Seconds 'M'-Minutes 'H'-Hours 'D'-Days 'W0'~'W6'-Weekday (0=Monday) 'midnight'-半夜循环 SocketHandler(host, port) 把log送到网上的socket DatagramHandler(host, port) 把log送到网上的UDP sockets SysLogHandler(address=('localhost', SYSLOG_UDP_PORT), facility=LOG_USER, socktype=socket.SOCK_DGRAM) log送到unix系统log SMTPHandler(mailhost, fromaddr, toaddrs, subject, credentials=None, secure=None, timeout=1.0) log送到电子邮箱 MemoryHandler(capacity, flushLevel=ERROR, target=None) log存入内存 HTTPHandler(host, url, method='GET', secure=False, credentials=None, context=None) log通过http网络送到服务器 使用设置文件设置logging行为 当然可以在程序中设置log了,但为了改起来方便也可以写在别的文件中然后用config.fileConfig(path)来设置,配置文件的形式是这样: [loggers] keys=root,simpleExample [handlers] keys=consoleHandler [formatters] keys=simpleFormatter [logger_root] level=DEBUG handlers=consoleHandler [logger_simpleExample] level=DEBUG handlers=consoleHandler qualname=simpleExample propagate=0 [handler_consoleHandler] class=StreamHandler level=DEBUG formatter=simpleFormatter args=(sys.stdout,) [formatter_simpleFormatter] format=%(asctime)s - %(name)s - %(levelname)s - %(message)s datefmt=%a, %d %b %Y %H:%M:%S 要注意的是如果用这种方式那么,使用rotation file handler时，不要同时声明file handler，否则rotation发生时，doRollover 函数的os.rename 会报错(「另一个程序正在使用此文件，进程无法访问).当然,可以写另一个py文件专门用来初始化,要用的时候import进来就好了. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"工具链/代码风格.html":{"url":"工具链/代码风格.html","title":"代码风格","keywords":"","body":"代码风格规定 python社区有一套成文的代码规范,就是有名的pep 8规范.而google也有一套成文的风格规范,他们都很不错,但更加推荐使用pep8标准,并且在一些细节上使用google的规范.当然了,python的代码风格并不是强制性的,只是使用这套规则会更加便于团队合作.是否使用还是看使用者个人 代码编排 缩进。4个空格的缩进（编辑器都可以完成此功能），不使用Tap，更不能混合使用Tap和空格。 每行最大长度79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。 类和top-level函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。 文档编排 模块内容的顺序：模块说明和docstring—import—globals&constants—其他定义。其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。 不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。 空格的使用 总体原则，避免不必要的空格。 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如Func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管使用‘；’允许。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。 注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 注释必须使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。 块注释，在一段代码前增加的注释。在‘#’后加一空格。段落之间以只有‘#’的行间隔。比如： # Description : Module config. # # Input : None # # Output : None 行注释，在一句代码后加注释。比如：x = x + 1 # Increment x 但是这种方式尽量少使用。 避免无谓的注释。 文档描述 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 如果docstring要换行，参考如下例子,详见PEP 257 \"\"\"Return a foobang Optional plotz says to frobnicate the bizbaz first. \"\"\" Shebang 大部分.py文件不必以#!作为文件的开始. 根据 PEP-394 , 程序的main文件应该以#!/usr/bin/python2或者 #!/usr/bin/python3开始.但其实更好的方式是使用#! /usr/bin/env/python2或者 #!/usr/bin/env python3 在计算机科学中, Shebang (也称为Hashbang)是一个由井号和叹号构成的字符串行(#!), 其出现在文本文件的第一行的前两个字符. 在文件中存在Shebang的情况下, 类Unix操作系统的程序载入器会分析Shebang后的内容, 将这些内容作为解释器指令, 并调用该指令, 并将载有Shebang的文件路径作为该解释器的参数. 例如, 以指令#!/bin/sh开头的文件在执行时会实际调用/bin/sh程序. #!先用于帮助内核找到Python解释器, 但是在导入模块时, 将会被忽略. 因此只有被直接执行的文件中才有必要加入#!. TODO注释 为临时代码使用TODO注释, 它是一种短期解决方案. 不算完美, 但够好了. TODO注释应该在所有开头处包含TODO字符串, 紧跟着是用括号括起来的你的名字, email地址或其它标识符. 然后是一个可选的冒号. 接着必须有一行注释, 解释要做什么. 主要目的是为了有一个统一的TODO格式, 这样添加注释的人就可以搜索到(并可以按需提供更多细节). 写了TODO注释并不保证写的人会亲自解决问题. 当你写了一个TODO, 请注上你的名字. # TODO(kl@gmail.com): Use a \"*\" here for string repetition. # TODO(Zeke) Change this to use relations. 如果你的TODO是”将来做某事”的形式, 那么请确保你包含了一个指定的日期(“2009年11月解决”)或者一个特定的事件(“等到所有的客户都可以处理XML请求就移除这些代码”). 命名规范 总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。 尽量单独使用小写字母l，大写字母O等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。 异常命名使用CapWords+Error后缀的方式。 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线。 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，subclass API属性前缀一条下划线,这样使用import * from时不会包含,non-public属性前缀两条下划线,这样不使用__dir__无法被查看到. 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明__a,访问时，只能通过Foo._Foo__a，避免歧义。如果子类也叫Foo，那就无能为力了。 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。 编码建议 编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，但是Jython中却非常低，所以应该采用.join()的方式。 尽可能使用is,is not取代==，比如if x is not None 要优于if x。 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。 异常中不要使用裸露的except，except后跟具体的exceptions。 异常中try的代码尽可能少。比如： try: value = collection[key] except KeyError: return key_not_found(key) else: return handle_value(value) 要优于 try: # Too broad! return handle_value(collection[key]) except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) 使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如： if foo.startswith('bar'): 优于 if foo[:3] == 'bar': 使用isinstance()比较对象的类型。比如 if isinstance(obj, int): 优于 if type(obj) is type(1): 判断序列空或不空，有如下规则 if not seq: pass if seq: pass 优于 if len(seq): pass if not len(seq): pass 字符串不要以空格收尾。 二进制数据判断使用if boolvalue的方式。 导入格式 每个导入应该独占一行 Yes: import os import sys No: import os, sys 导入总应该放在文件顶部, 位于模块注释和文档字符串之后, 模块全局变量和常量之前. 导入应该按照从最通用到最不通用的顺序分组: 标准库导入 第三方库导入 应用程序指定导入 每种分组中, 应该根据每个模块的完整包路径按字典序排序, 忽略大小写. import foo from foo import bar from foo.bar import baz from foo.bar import Quux from Foob import ar Main 即使是一个打算被用作脚本的文件, 也应该是可导入的. 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行, 这是一种副作用. 主功能应该放在一个main()函数中. 在Python中, pydoc以及单元测试要求模块必须是可导入的. 你的代码应该在执行主程序前总是检查 if__name__ == '__main__' , 这样当模块被导入时主程序就不会被执行. def main(): pass if __name__ == '__main__': main() 所有的顶级代码在模块导入时都会被执行. 要小心不要去调用函数, 创建对象, 或者执行那些不应该在使用pydoc时执行的操作. docstrings注释风格 python文件中每个对象(模块,函数,方法,类)的开头部分可以使用\"\"\"或者'''包裹起来作为注释,这种注释被称作docstrings.python解释器会将器存放在对应对象的__doc__属性上. docstrings注释是可以被help()内置函数读出打印,也可以被pydoc读出生成文档的注释,使用一对连续3个引号来构建. 我们的docstrings注释要简洁明了,并且最好符合大多数人的阅读习惯,这样才便于维护,这边推荐谷歌风格的注释规范. 模块 每个文件应该包含一个许可样板. 根据项目使用的许可, 选择合适的样板. 函数 一个函数必须要有文档字符串, 除非它满足以下条件: 外部不可见 非常短小 简单明了 文档字符串应该包含函数做什么, 以及输入和输出的详细描述. 通常, 不应该描述”怎么做”, 除非是一些复杂的算法. 文档字符串应该提供足够的信息, 当别人编写代码调用该函数时, 他不需要看一行代码, 只要看文档字符串就可以了. 对于复杂的代码, 在代码旁边加注释会比使用文档字符串更有意义. 关于函数的几个方面应该在特定的小节中进行描述记录， 这几个方面如下文所述. 每节应该以一个标题行开始. 标题行以冒号结尾. 除标题行外, 节的其他内容应被缩进2个空格. Args: 列出每个参数的名字, 并在名字后使用一个冒号和一个空格, 分隔对该参数的描述.如果描述太长超过了单行80字符,使用2或者4个空格的悬挂缩进(与文件其他部分保持一致). 描述应该包括所需的类型和含义. 如果一个函数接受*foo(可变长度参数列表)或者**bar (任意关键字参数), 应该详细列出*foo和**bar. Returns: (或者 Yields: 用于生成器) 描述返回值的类型和语义. 如果函数返回None, 这一部分可以省略. Raises: 列出与接口有关的所有异常. 我们看一个例子: def flatten(items): u\"\"\"压扁序列,将多层结构的序列压为一列. Parameters: items (Iterable): - 复杂的多层序列 Returns: Iterable: - 压扁后的单层序列 \"\"\" for item in items: is_iterable = isinstance(item, Iterable) is_string_or_bytes = isinstance(item, (str, bytes, bytearray)) if is_iterable and not is_string_or_bytes: for i in flatten(item): yield i else: yield item 类 类应该在其定义下有一个用于描述该类的文档字符串. 如果你的类有公共属性(Attributes), 那么文档中应该有一个属性(Attributes)段. 并且应该遵守和函数参数相同的格式. Attributes: 成员属性 我们看一个例子: class SampleClass(object): u\"\"\"一个简单的类例子 Attributes: likes_spam: 布尔型参数 eggs: int型参数 \"\"\" def __init__(self, likes_spam=False): \"\"\"Inits SampleClass with blah.\"\"\" self.likes_spam = likes_spam self.eggs = 0 def public_method(self): \"\"\"Performs operation blah.\"\"\" 代码美化 要完全符合规范是很作孽繁琐的一件事,我们同样可以使用工具简化这个工作,这就是autopep8. 安装: pip install --upgrade autopep8 如果使用atom的话则可以安装Atom Beautify插件,它的python代码美化也是基于autopep8的. *类型注释和检验 python3.5起就支持函数的类型注释(pep 484),它的结构如下: def func(arg:int)->int: pass 类型注释只是注释,python解释器并不会处理它,要让它有类型检验的功能还要有其他工具配合. 函数的参数类型保存在它的__annotations__属性上 func.__annotations__ {'arg': int, 'return': int} *自定义泛型注解 类型注释可以直接使用系统自带的类和自己定义的类,但对于泛型注解就力不从心了,对于这种需求,python内置了typing模块来帮助泛型注释 协程注释 async def spam(ignored: int) -> str: return 'spam' async def foo() -> None: bar = await spam(42) # type: str 类型别名 Url = str def retry(url: Url, retry_count: int) -> None: pass 可调用类型 from typing import Callable def feeder(get_next_item: Callable[[], str]) -> None: pass def async_query(on_success: Callable[[int], None], on_error: Callable[[int, Exception], None]) -> None: pass 生成器类型 from typing import Generator def echo_round() -> Generator[int, float, str]: res = yield while res: res = yield round(res) return 'OK' 容器中的类型 from typing import Mapping, Set def notify_by_email(employees: Set[int], overrides: Mapping[str, str]) -> None: pass 泛型 from typing import Sequence, TypeVar T = TypeVar('T') # Declare type variable def first(l: Sequence[T]) -> T: # Generic function return l[0] 受限泛型 from typing import TypeVar AnyStr = TypeVar('AnyStr', str, bytes)#必须是str或者bytes def concat(x: AnyStr, y: AnyStr) -> AnyStr: return x + y Union类型 Union类型常用于可选类型,最常见的用法就是和None一起使用 from typing import Union def handle_employees(e: Union[int, Sequence[int]]) -> None: if isinstance(e, Employee): e = [e] 用户自定义泛型 from typing import TypeVar, Generic class Logger: pass T = TypeVar('T') class LoggedVar(Generic[T]): def __init__(self, value: T, name: str, logger: Logger) -> None: self.name = name self.logger = logger self.value = value def set(self, new: T) -> None: self.log('Set ' + repr(self.value)) self.value = new def get(self) -> T: self.log('Get ' + repr(self.value)) return self.value def log(self, message: str) -> None: self.logger.info('{}: {}'.format(self.name,message)) from typing import Iterable def zero_all_vars(vars: Iterable[LoggedVar[int]]) -> None: for var in vars: var.set(0) 老实说这么注释类型有点画蛇添足 any类型 any类型和ts中一样,代表任意类型都可以 方法重载 from typing import overload class bytes: @overload def __getitem__(self, i: int) -> int: ... @overload def __getitem__(self, s: slice) -> bytes: ... *静态类型检验 python解释器并不会做静态类型检验,我们可以利用mypy来实现 %%writefile src/C2/mypytest.py from typing import Callable def twice(i: int, next: Callable[[int], int]) -> int: return next(next(i)) def add(i: int) -> str:#写成返回str,这样就会报错! return i + 1 print(twice(3, add)) # 5 Overwriting src/C2/mypytest.py !mypy src/C2/mypytest.py src/C2/mypytest.py:8: error: Incompatible return value type (got \"int\", expected \"str\") src/C2/mypytest.py:10: error: Argument 2 to \"twice\" has incompatible type Callable[[int], str]; expected Callable[[int], int] *变量注解(3.6) 3.6版本起变量类型也可以注释了(pep 526),这看起来就像c语言一样,然而它依然还是注释 from typing import Optional,List foo: Optional[int] bar: List[str] = [] from typing import ClassVar class C: x: int # instance variable y: ClassVar[int] # class variable z = None # type: ClassVar[int] def foo(self) -> None: self.x = 0 # OK self.y = 0 # Error: Cannot assign to class variable \"y\" via instance C.y = 0 # This is OK 模块,类中的的变量注解同样保存在__annotations__中 C.__annotations__ {'x': int, 'y': typing.ClassVar[int]} c = C() c.__annotations__ {'x': int, 'y': typing.ClassVar[int]} __annotations__ {'bar': typing.List[str], 'foo': typing.Union[int, NoneType]} 文档生成 无论代码写的如何,如果没有一个详细清晰的文档会让使用和维护变得非常困难,负责任的开发者应该尽量为自己的代码维护一份文档.python可以使用自带的文档生成器pydoc,它可以读取代码中的docstring,自动的生成文档. 它的使用方式非常简单 !python -m pydoc -k 查找关键字 -p 用localhost打开网页版,后面填端口号 -g GUI版 -w 生成html文件 *sphinx-autodoc pydoc虽然方便,但实话说样式比较老旧,而且可定制性不强,现在的python包一般都用sphinx做文档,sphinx其实也是利用autodoc,结合docstring和规范化的文档格式,可以实现非常美观的项目文档.具体可以看我的这篇博文 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"工具链/调试与测试.html":{"url":"工具链/调试与测试.html","title":"调试与测试","keywords":"","body":"代码调试 代码调试主要是debug,也就是确保程序不出错误.基本可以分为如下几个方面: 单步调试,一步一步的查看代码的运行状态 调用追踪,查看函数报错在堆栈中的状况 段错误追踪,一般用于C写扩展的模块追踪内存泄漏等错误 单步调试模块 pdb是python自带的调试模块,它可以在交互环境中使用,也可以在terminal中作为python的一个模式使用 要调试的脚本: #!/usr/bin/env python3 class Counter(object): \"\"\"一个计数器 用法: >>> counter1 = Counter() >>> counter1() 1 >>> counter1() 2 >>> counter2 = Counter(lambda : 2,-3) >>> counter2() -1 >>> counter2() 1 \"\"\" def __str__(self): return \"state:\"+str(self.value) def __repr__(self): return self.__str__ def __call__(self): def count(): self.value += self.func() return self.value return count() def __init__(self,func=lambda : 1,start=0): self.value = start self.func = func test = Counter() test() test() print(test) if __name__==\"__main__\": counter1 = Counter() counter2 = Counter() for i in range(10): counter1() for i in range(8): counter2() if counter1.value == counter2.value: print(\"not success\") else: print(\"don't known\") import doctest doctest.testmod(verbose=True) 命令行调试 python -m pdb counter.py 在交互shell中调试 import pdb import counter pdb.run('counter.test()') 常用的调试命令可以在调试模式下用help命令来查看 调用追踪 调试的时候我们除了想知道哪条代码错了,也会想知道是谁调用了这条错误的代码,,又或者希望知道运行时的堆栈信息.这个时候调用追踪模块就有用了 一个简单的例子 import traceback def func(): s = traceback.extract_stack() print('%s Invoked me!'%s[-2][2]) def a(): func() b = lambda :func() a() a Invoked me! b() Invoked me! traceback的api是这些，我将它翻译出来，英文不好的同学也可以对照着使用: traceback.print_tb(tb, limit=None, file=None) 如果limit参数是正数,则打印limit条数的(从调用者这一帧开始的)traceback对象的堆栈跟踪条目,否则打印最后的abs(limit)条目,如果limit被省略或为None，则打印所有条目 如果省略file或者None，则输出到sys.stderr,否则它应该是一个打开的文件或类似文件的对象来接收输出。 打印，以限制堆栈跟踪条目从traceback对象(从调用者这帧开始)，如果限制是积极的。否则，打印最后的ABS（限制）条目。如果限制被省略或没有，所有条目打印。如果文件被省略或没有，输出到`sys.stderr`；否则应打开的文件或类似文件的对象来接收输出。 traceback.print_exception(etype, value, tb, limit=None, file=None, chain=True) 将异常信息和堆栈跟踪条目从traceback对象tb打印到文件。这与print_tb()有以下不同: 如果tb不是None，它会打印一个 header Traceback（通常是最近一次调用）： 它在堆栈跟踪之后打印异常etype和值 如果etype是SyntaxError，并且value具有相应的格式，则会打印出语法错误发生的行，并带有指示错误大致位置的插入符号。 可选的limit参数与`print_tb()`的含义相同.如果chain为true（默认值），那么也会打印异常链（`__cause__`或`__context__`异常的属性），就像解释器本身在打印未处理的异常时一样。 traceback.print_exc(limit=None, file=None, chain=True) print_exception(*sys.exc_info(), limit, file, chain)的缩写 traceback.print_last(limit=None, file=None, chain=True) 这是print_exception(sys.last_type，sys.last_value，sys.last_traceback，limit，file，chain)的缩写。一般来说，只有在异常已经达到交互式提示之后才会有效 traceback.print_stack(f=None, limit=None, file=None) 如果limit为正值则以limit参数为条数打印堆栈跟踪条目(从调用点开始)否则，打印最后一个abs(limit)条目。如果省略limit或None，则打印所有条目。可选的f参数可用于指定要启动的备用堆栈帧。可选file参数与print_tb()具有相同的含义。 traceback.extract_tb(tb, limit=None) 返回从traceback对象tb提取的“预处理”堆栈跟踪条目列表。它对于堆栈跟踪的替代格式很有用。可选的limit参数与print_tb()的含义相同。 “预处理”堆栈跟踪条目是表示通常为堆栈跟踪打印的信息的4元组(文件名，行号，函数名称，文本)。文本是带有前导和尾随空格的字符串;如果源不可用，则为None。 traceback.extract_stack(f=None, limit=None) 从当前堆栈帧中提取原始的追溯。返回值的格式与extract_tb()的格式相同。可选的f和limit参数与print_stack()具有相同的含义。 traceback.format_list(extracted_list) 给定一个由extract_tb()或extract_stack()返回的元组列表，返回一个准备打印的字符串列表。结果列表中的每个字符串对应于参数列表中具有相同索引的项。每个字符串以换行符结尾.对于源文本行不为None的项目，字符串也可能包含内部换行符。 traceback.format_exception_only(etype, value) 格式化traceback的异常部分。参数是异常类型和值，例如由sys.last_type和sys.last_value给出的。返回值是一个字符串列表，每个都以换行符结尾。通常，列表包含单个字符串;但是，对于SyntaxError异常，它包含几行(打印时)显示有关发生语法错误的详细信息。指示发生哪个异常的消息是列表中始终最后一个字符串。 traceback.format_exception(etype, value, tb, limit=None, chain=True) 格式化堆栈跟踪和异常信息。参数与print_exception()的相应参数具有相同的含义。返回值是字符串列表，每个都以换行符结尾，一些包含内部换行符。当这些行连接并打印时，打印与print_exception()完全相同的文本。 traceback.format_exc(limit=None, chain=True) 类似print_exc(limit)，但是返回一个字符串而不是打印到一个文件 traceback.format_tb(tb, limit=None) format_list(extract_tb(tb，limit))的缩写 traceback.format_stack(f=None, limit=None) format_list(extract_stack(f, limit))的缩写 traceback.clear_frames(tb) 通过调用每个帧对象的clear()方法来清除traceback对象tb中所有堆栈帧的局部变量。 traceback.walk_stack(f) 从给定帧中的f.f_back后面移动一个堆栈，产生每个帧的帧和行号。如果f为None，则使用当前堆栈。它常用于和StackSummary.extract()一起使用。 traceback.walk_tb(tb) 在tb_next之后走一个回溯，产生每个帧的帧和行号。此帮助程序与StackSummary.extract()一起使用。 class traceback.StackSummary StackSummary对象表示可以进行格式化的调用堆栈,它的静态方法extract 常与traceback.walk_stack或者traceback.walk_tb配合使用 classmethod extract(frame_gen, *, limit=None, lookup_lines=True, capture_locals=False) 从帧生成器构造一个StackSummary对象(例如由walk_stack()或walk_tb()的返回).如果有limit参数，则只有这么多帧是从frame_gen中获取的。如果lookup_lines为False，则返回的FrameSummary对象将不会读取它们的行，从而使得创建StackSummary的成本更低(如果实际上可能没有格式化，则可能是有价值的).如果capture_locals为True，则每个FrameSummary中的局部变量被捕获为对象表示。 段错误追踪 所谓的段错误就是指访问的内存超出了系统所给这个程序的内存空间，通常这个值是由gd tr来保存的，他是一个48位的寄存器，其中的32位是保存由它指向的 gdt表，后13位保存 相应于gdt的下标，最后3位包括了程序是否在内存中以及程序的在cpu中的运行级别，指向 的gdt是由以64位为一个单位的表，在这张表中就保存着程序运行的代码段以及数据段的起 始地址以及与此相应的段限和页面交换还有程序运行级别还有内存粒度等等的信息。 在编程中以下几类做法容易导致段错误,基本上是错误地使用指针引起的。 访问系统数据区，尤其是往系统保护的内存地址写数据最常见就是给一个指针以0地址。 内存越界(数组越界，变量类型不一致等)： 访问到不属于你的内存区域。 python由于与C有着千丝万缕的联系,所以使用ctypes这类模块的时候也很容易出段错误这种问题.python3.5+提供了faulthandler工具来做段错误追踪. %%writefile src/C3/faulthandler_test.py import ctypes ctypes.string_at(0) Overwriting src/C1/faulthandler_test.py !python3 src/C3/faulthandler_test.py !python3 -q -X faulthandler faulthandler_test.py /usr/local/Cellar/python3/3.5.2_3/Frameworks/Python.framework/Versions/3.5/Resources/Python.app/Contents/MacOS/Python: can't open file 'faulthandler_test.py': [Errno 2] No such file or directory 另一中用法是在文件内写入faulthandler.enable() %%writefile src/C3/faulthandler_test2.py import ctypes import faulthandler faulthandler.enable() ctypes.string_at(0) Overwriting src/C1/faulthandler_test2.py !python3 src/C3/faulthandler_test2.py Fatal Python error: Segmentation fault Current thread 0x00007fff7c6a6000 (most recent call first): File \"/usr/local/Cellar/python3/3.5.2_3/Frameworks/Python.framework/Versions/3.5/lib/python3.5/ctypes/__init__.py\", line 491 in string_at File \"src/C1/faulthandler_test2.py\", line 5 in 性能调优 在代码可以实现功能且健壮不出错的前提下,我们往往会有优化性能的需求 性能调优大约可以在运行时间和运行内存占用两方面来考量,下面介绍的工具定位精度由粗到细,也分为这两个方面 测试整体运行时间 Python中的timeit是测试代码执行效率的工具.可以用命令行直接测试脚本,也可以测试代码字符串的效率,当然最简单的还是直接用ipython的内置timeit魔法命令测某段代码的效率 import timeit t = timeit.Timer('map(lambda x: x**2,range(1000))') t.timeit() 0.8133840359951137 !python -m timeit -s \"map(lambda x: x**2,range(1000))\" 10000000 loops, best of 3: 0.065 usec per loop 函数级性能瓶颈定位 python的标准库中有一个可以实现性能瓶颈定位的模块叫cprofile,他是一个开销极小的C扩展.用它可以实现函数级的性能分析,配合pstats模块还可以输出分析报告 使用单独模块分析 %%writefile src/C3/profile_test.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C1/profile_test.py %%writefile src/C3/profile_test.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile except: import cProfile as profile profile.run(\"foo()\") Overwriting src/C1/profile_test.py !python src/C3/profile_test.py 5 function calls in 0.004 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 :0(range) 1 0.001 0.001 0.001 0.001 :0(setprofile) 1 0.000 0.000 0.003 0.003 :1() 1 0.000 0.000 0.004 0.004 profile:0(foo()) 0 0.000 0.000 profile:0(profiler) 1 0.002 0.002 0.003 0.003 profile_test.py:1(foo) 使用命令行分析 %%writefile src/C3/profile_test_foo.py #coding:utf-8 def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C1/profile_test_foo.py !python -m cProfile src/C3/profile_test_foo.py 4 function calls in 0.002 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.002 0.002 profile_test_foo.py:2() 1 0.002 0.002 0.002 0.002 profile_test_foo.py:2(foo) 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} 1 0.000 0.000 0.000 0.000 {range} 统计项说明 统计项 说明 ncalls 函数被调用次数 tottime 函数总计运行时间,不含调用函数运行时间 cumtime 函数总计运行时间,含调用的函数运行时间 percall 函数运行一次平均时间,等于tottime(cumtime)/ncalls filename:lineno 函数所在文件名,函数的行号,函数名 与pstats结合提供多种形式的报表 %%writefile src/C3/profile_test_pstats.py def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile except: import cProfile as profile profile.run(\"foo()\",\"foo.txt\") import pstats p = pstats.Stats(\"foo.txt\") p.sort_stats(\"time\").print_stats() Overwriting src/C1/profile_test_pstats.py !python src/C3/profile_test_pstats.py Fri May 12 00:12:23 2017 foo.txt 5 function calls in 0.002 seconds Ordered by: internal time ncalls tottime percall cumtime percall filename:lineno(function) 1 0.002 0.002 0.002 0.002 src/C1/profile_test_pstats.py:1(foo) 1 0.000 0.000 0.000 0.000 :0(range) 1 0.000 0.000 0.002 0.002 profile:0(foo()) 1 0.000 0.000 0.000 0.000 :0(setprofile) 1 0.000 0.000 0.002 0.002 :1() 0 0.000 0.000 profile:0(profiler) stats有许多函数,可以提供不同的报表 stats函数说明 函数 说明 strip_dirs() 除去文件名前名的路径信息 add(filename,[...]) 把profile输出的文件加入stats实例中统计 dump_stats(filename) 把stats统计结果保存到文件 sort_stats(key,[...]) 最重要的,可以给profile统计结果排序 reverse_order() 数据反排序 print_stats([restriction,...]) 把报表输出到stdout print_callers([restriction,...]) 输出调用指定函数的相关信息 print_callees([restriction,...]) 输出指定函数调用过的函数的相关信息 sort_stats可接受的参数 参数 说明 ncalls 被调次数 cumulative 函数运行总时间 file 文件名 module 模块名 pcalls 简单统计 line 行号 name 函数名 nfl name,file,line stdname 标准函数名 time 函数内部运行时间 语句级性能瓶颈定位 cprofiler只能追踪到哪个函数是性能瓶颈,而函数中哪条语句是性能瓶颈就追踪不到了,对于语句级性能瓶颈定位,python并没有官方工具,但github上有位大神制作了line_profiler,这个工具可以实现这一功能,它也几乎可以说是python的半标准工具之一了. 因为不是标准库中的内容,所以需要pip安装. 使用方法十分简单,在需要分析的函数上面加上装饰器@profile即可(注意不用import任何东西,这条装饰器在定位好后应该删除以保证代码可以运行) %%writefile src/C3/line_profile_test.py @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C1/line_profile_test.py !python3 -m kernprof -l -v src/C3/line_profile_test.py Wrote profile results to line_profile_test.py.lprof Timer unit: 1e-06 s Total time: 0.01045 s File: src/C1/line_profile_test.py Function: foo at line 2 Line # Hits Time Per Hit % Time Line Contents ============================================================== 2 @profile 3 def foo(): 4 1 3 3.0 0.0 sum = 0 5 10001 4928 0.5 47.2 for i in range(10000): 6 10000 5518 0.6 52.8 sum += i 7 1 1 1.0 0.0 return sum 内存分析 memory_profiler是用来分析内存使用情况和追踪内存泄露的工具.它用法比较接近line_profiler 由于不是标准库中的模块,它需要pip安装. 需要注意的是windows下需要在script文件夹下将mprof文件改名为mprof.py并在同一目录下创建一个mprof.bat文件编辑为如下内容 @echo off python \"%~dpn0.py\" %* 它的使用及其简单: %%writefile src/C3/memory_test.py from memory_profiler import profile @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": try : import profile as cProfile except: import cProfile cProfile.run(\"foo()\",\"foo.txt\") import pstats p = pstats.Stats(\"foo.txt\") p.sort_stats(\"time\").print_stats() Overwriting src/C1/memory_test.py 之后使用 python src/C3/memory_test.py 就可以看到详细结果了 指定精度可以在profile装饰器后面加上参数 如: @profile(precision=4) mprof工具类似kernprof,用它可以输出更加友好的统计分析页面 %%writefile src/C3/memory_test_round.py from memory_profiler import profile @profile def foo(): sum = 0 for i in range(10000): sum += i return sum if __name__==\"__main__\": foo() Overwriting src/C1/memory_test_round.py !mprof run src/C3/memory_test_round.py /bin/sh: mprof: command not found !mprof plot /bin/sh: mprof: command not found 对象分析及追踪(windows下不能用) Objgraph可以实现对象分析和追踪,它也是用pip安装,不过它依赖xdot(pip 安装) 和graphviz(brew安装) 它可以实现的功能有: 统计 定义过滤对象 遍历和显示对象图 %%writefile src/C3/Obj_test.py #encoding=utf-8 import objgraph if __name__ == '__main__': x = [] y = [x, [x], dict(x=x)] objgraph.show_refs([y], filename='sample-graph.png') #把[y]里面所有对象的引用画出来 objgraph.show_backrefs([x], filename='sample-backref-graph.png') #把对x对象的引用全部画出来 #objgraph.show_most_common_types() #所有常用类型对象的统计，数据量太大，意义不大 objgraph.show_growth(limit=4) #打印从程序开始或者上次show_growth到现在增加的对象（按照增加量的大小排序） Overwriting src/C1/Obj_test.py !python src/C3/Obj_test.py Traceback (most recent call last): File \"src/C1/Obj_test.py\", line 2, in import objgraph ImportError: No module named objgraph 于是你可以看到图了 异常处理 代码难免会出错,尤其是python这样的动态语言.对于可以预知的异常可能,python可以通过自带的异常处理语句解决. python有完善的异常处理解决方案 异常 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。 一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 python的标准异常可以在官网文档中查看,常用的如下: 异常名称 描述 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 异常捕获处理 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它 try: #运行别的代码 except ： #如果在try部份引发了'name'异常 except ，: #如果引发了'name'异常，获得附加的数据 else: #如果没有异常发生 finally: #退出try时总会执行 try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 无论是否有异常,finally都将被执行,它一般作为存放收尾动作的地方,但是注意,finally有陷阱: 如果主干上的错误分支中没有对应的捕捉,那么他将被保存在一个临时的位置,而如果同时finally中有错误,则这个临时的错误会被finally中的错误给替代. 使用异常捕获处理语句应该尽量精准地包裹可能有错误的代码. Python遵守尽早失败原则,认为程序应该尽早报告错误。例如,Python中没有“未定义”的值:在初始化之前引用变量会报错;如果k不存在,my_dict[k] 会抛出异常(JavaScript 则不然)。还有一例:在 Python 中通过元组 拆包做并行赋值,必须显式处理元组的每一个元素才行;而在 Ruby 中,如果 = 两边的元 素数量不一致,右边未用到的元素会被忽略,或者把 nil 赋给左边多余的变量。 因为尽早失败原则,python代码中try语句会比较多,但即便如此,我们的单个try结构应该尽量精准的包裹可能出错的代码. 抛出异常 我们可以使用raise语句自己触发异常 raise语法格式如下 raise [Exception [, args [, traceback]]] 自定义异常 如果自己写模块,最好自定义模块的异常,一方面可以更好的分析代码,另一方面也让用模块的用户更容易追踪错误. class Networkerror(RuntimeError): def __init__(self, arg): self.args = arg try: raise Networkerror(\"Bad hostname\") except Networkerror as e: print(e.args) ('B', 'a', 'd', ' ', 'h', 'o', 's', 't', 'n', 'a', 'm', 'e') 项目测试 项目写完后应该写测试以确保代码稳定可靠.经过测试稳定可靠的代码才能经得住时间的考验.但即便有测试,如果代码覆盖不够,测试用例不能覆盖全部情况,这样也并不能保准项目就一定稳健.因此条件允许的话也最好将类型注释写好,利用mypy做好静态类型检验. 单元测试 将代码分解为独立不耦合的小部件,针对这些小部件的测试就是单元测试.测试单元应该集中于小部分的功能，并且证明在各种情况下它的行为正确(包括错误行为). 常常将测试代码和运行代码一起写是一种非常好的习惯。聪明地使用这种方法将会帮助你更加精确地定义代码的含义，并且代码的耦合性更低。 一般来说,更加推崇的方法是先写测试用例确定代码行为,再写代码,也就是所谓的测试驱动编程. 测试的通用规则： 测试单元应该集中于小部分的功能，并且证明它是对的。 每个测试单元应该完全独立。每个都能够单独运行，除了调用的命令，都需在测试套件中。要想实现这个规则，测试单元应该加载最新的数据集，之后再做一些清理。 尽量使测试单元快速运行。如果一个单独的测试单元需要较长的时间去运行，开发进度将会延迟，测试单元将不能如期常态性运行。有时候，因为测试单元需要复杂的数据结构，并且当它运行时每次都要加载，所以其运行时间较长。把运行吃力的测试单元放在单独的测试组件中，并且按照需要运行其它测试单元。 学习使用工具，学习如何运行一个单独的测试用例。然后，当在一个模块中开发了一个功能时，经常运行这个功能的测试用例，理想情况下，一切都将自动。 在编码会话前后，要常常运行完整的测试组件。只有这样，你才会坚信剩余的代码不会中断。 实现钩子（hook）是一个非常好的主意。因为一旦把代码放入分享仓库中，这个钩子可以运行所有的测试单元。 如果你在开发期间不得不打断自己的工作，写一个被打断的单元测试，它关于下一步要开发的东西。当回到工作时，你将更快地回到原先被打断的地方，并且步入正轨。 当你调试代码的时候，首先需要写一个精确定位bug的测试单元。尽管这样做很难，但是捕捉bug的单元测试在项目中很重要。 测试函数使用长且描述性的名字。这边的样式指导与运行代码有点不一样，运行代码更倾向于使用短的名字，而测试函数不会直接被调用。在运行代码中，square()或者甚至sqr()这样的命名都是可以的，但是在测试代码中，你应该这样取名test_square_of_number_2()，test_square_negative_number()。当测试单元失败时，函数名应该显示，而且尽可能具有描述性。 当发生了一些问题，或者不得不改变时，如果代码中有一套不错的测试单元，维护将很大一部分依靠测试组件解决问题，或者修改确定的行为。因此测试代码应该尽可能多读，甚至多于运行代码。目的不明确的测试单元在这种情况下没有多少用处。 测试代码的另外一个用处是作为新开发人员的入门。当工作基于代码，运行并且阅读相关的测试代码是一个非常好的做法。开发人员将会或者应该发现热点，而这将引起困难和其它情况，如果他们一定要加一些功能，第一步应该是要增加一个测试单元，通过这种方法，确保新功能不再是一个没有被嵌入到接口中的工作路径。 unittest python标准库中自带了unittest框架以用来做单元测试.unittest已经可以满足一般的测试需求了.它包含了所有测试框架需要的部件.相比较使用第三方测试框架,unittest相对来说更加稳定可靠,而且作为标准库,也避免了额外的依赖安装. 使用 unittest 的标准流程为： 从 unittest.TestCase 派生一个子类 在类中定义各种以 \"test_\" 打头的方法 通过 unittest.main() 函数来启动测试 unittest可以指定测试模块使用 unittest test.py或者unittest test或者unittest test.test 它可以带上以下参数 -v 测试的详细信息 -f 出错就停 -c 可以用ctrol+c停止,并出结果 -b 运行时结果存到stderr和stdout里 unittest 支持自动搜索,这需要在后面加上子选项discover, discover可以有这些参数: -s 指定文件夹 -t 指定模块 -p 模式匹配要测试的文件 unittest 的一个很有用的特性是 TestCase 的 setUp() 和 tearDown() 方法，这种方法统称\"钩子\"它们提供了为测试进行准备和扫尾工作的功能，听起来就像上下文管理器一样。这种功能很适合用在测试对象需要复杂执行环境的情况下。 基本用法 我们将测试如下这个模块 %%writefile src/C3/func_oper_unitest.py #!/usr/bin/env python \"\"\"\\ 这里可以写用到多个函数的 \"\"\" from functools import reduce from operator import mul,add def multiply(*args): \"\"\"\\ 这里可以写单元测试 >>> multiply(2,3) 6 >>> multiply('baka~',3) 'baka~baka~baka~' \"\"\" return reduce(mul,args) def summing(*args): \"\"\"\\ 这里可以写单元测试 >>> summing(2,3) 5 >>> summing(2,3,4) 9 \"\"\" return reduce(add,args) Overwriting src/C3/func_oper_unitest.py 测试用例 测试用例是指一系列相关测试的实例.如何界定这个相关程度根据实际情况而定,比如粗略的测试可以以模块为单位,一个模块的测试都放在一个测试用例中,细致的则可以是针对一个函数或者一个接口的测试都放在一个测试用例中. unittest.TestCase是测试用例的超类,编写测试用例只要继承它即可. %%writefile src/C3/test_my.py import unittest from func_oper_unitest import multiply,summing class Test_mul(unittest.TestCase): def setUp(self): pass def test_number_3_4(self): self.assertEqual(multiply(3,4),12) def test_string_a_3(self): self.assertEqual(multiply('a',3),'aaa') class Test_sum(unittest.TestCase): def setUp(self): pass def test_number_3_4(self): self.assertEqual(summing(3,4),7) def test_number_3_4_5(self): self.assertEqual(summing(3,4,5),12) class TestCase1(unittest.TestCase): def setUp(self): pass def test_sum_mul_2_3_mul_2_3(self): self.assertEqual(summing(multiply(2,3),multiply(2,3)),12) if __name__ == '__main__': unittest.main() Overwriting src/C3/test_my.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.009s FAILED (failures=8, skipped=2, expected failures=2) 钩子 如果要对一个模块中的每一个测试函数都做同样的初始化操作和结尾清除等操作，那么创建n个测试用例就得写n遍一样的代码，为了减少重复的代码， 测试用例的实例可以使用下面两个函数定义其中每个测试样例的初始化和清除工作： setUp(self): 每次执行测试用例之前调用。无参数，无返回值。该方法抛出的异常都视为error，而不是测试不通过。没有默认的实现。 tearDown(self): 每次执行测试用例之后调用。无参数，无返回值。测试方法抛出异常，该方法也正常调用，该方法抛出的异常都视为error，而不是测试不通过。只用setUp()调用成功，该方法才会被调用。没有默认的实现。通过setup 和 tesrDown组装一个module成为一个固定的测试装置。注意：如果setup运行抛出错误，则测试用例代码则不会执行。但是，如果setpu执行成功，不管测试用例是否执行成功都会执行teardown。 测试用例也有一个类级别的钩子,它可以在测试用例类实例化之前和类全部测试实例运行完后进行操作 @classmethod def setUpClass(cls): cls._connection = createExpensiveConnectionObject() @classmethod def tearDownClass(cls): cls._connection.destroy() 测试钩子也可以定义模块级别的钩子,它会在模块被引用和模块运行结束后进行工作 def setUpModule(): createConnection() def tearDownModule(): closeConnection() %%writefile src/C3/test_hook.py import unittest from func_oper_unitest import multiply,summing def setUpModule(): print(\"setUpModule\") def tearDownModule(): print(\"tearUpModule\") class Test_mul(unittest.TestCase): @classmethod def setUpClass(cls): print(\"setUpClass\") @classmethod def tearDownClass(cls): print(\"tearDownClass\") def setUp(self): print(\"instance setUp\") def tearDown(self): print(\"instance tearDown\") def test_number_3_4(self): print(\"t1\") self.assertEqual(multiply(3,4),12) def test_string_a_3(self): print(\"t2\") self.assertEqual(multiply('a',3),'aaa') if __name__ == '__main__': unittest.main() Overwriting src/C3/test_hook.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.006s FAILED (failures=8, skipped=2, expected failures=2) 上面的结果可以很清洗的看到测试钩子的上下文范围. 断言 断言是用来声明结果状态的工具,如果结果符合预期,那么断言就该通过,否则断言就该报断言错误 python自带断言关键字assert assert 1==1 assert 1==0 --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 assert 1==0 AssertionError: 自带的断言关键字功能单一,往往不能完全满足测试需要,比如要测报错的错误类型就很麻烦了,因此除assert关键字外,彪悍尊哭unittest模块还有其他几个断言工具实现更加复杂的断言. 基本断言方法 基本的断言方法提供了测试结果是True还是False。所有的断言方法都有一个msg参数，如果指定msg参数的值，则将该信息作为失败的错误信息返回。 断言方法 断言描述 assertEqual(arg1, arg2, msg=None) 验证arg1=arg2，不等则fail assertNotEqual(arg1, arg2, msg=None) 验证arg1 != arg2, 相等则fail assertTrue(expr, msg=None) 验证expr是true，如果为false，则fail assertFalse(expr,msg=None) 验证expr是false，如果为true，则fail assertIs(arg1, arg2, msg=None) 验证arg1、arg2是同一个对象，不是则fail assertIsNot(arg1, arg2, msg=None) 验证arg1、arg2不是同一个对象，是则fail assertIsNone(expr, msg=None) 验证expr是None，不是则fail assertIsNotNone(expr, msg=None) 验证expr不是None，是则fail assertIn(arg1, arg2, msg=None) 验证arg1是arg2的子串，不是则fail assertNotIn(arg1, arg2, msg=None) 验证arg1不是arg2的子串，是则fail assertIsInstance(obj, cls, msg=None) 验证obj是cls的实例，不是则fail assertNotIsInstance(obj, cls, msg=None) 验证obj不是cls的实例，是则fail 容器断言 判断两个容器中内容是否一样 断言方法 针对容器 断言描述 assertMultiLineEqual(a, b) strings 比较两个字符串是否一样 assertSequenceEqual(a, b) sequences 比较两个序列是否一样 assertListEqual(a, b) lists 比较两个list是否一样 assertTupleEqual(a, b) tuples 比较两个元组是否一样 assertSetEqual(a, b) sets 或者 frozensets 比较两个集合是否一样 assertDictEqual(a, b) dicts 比较两个字典是否一样 模糊比较断言 unittest框架提供的第二种断言类型就是比较断言。 下面我们看下各种比较断言： 断言方法 断言描述 参数说明 assertAlmostEqual (first, second, places = 7, msg = None, delta = None) 验证first约等于second. palces: 指定精确到小数点后多少位，默认为7 assertNotAlmostEqual (first, second, places, msg, delta) 验证first不约等于second。 palces: 指定精确到小数点后多少位，默认为7,注： 在上述的两个函数中，如果delta指定了值，则first和second之间的差值必须≤delta== assertGreater (first, second, msg = None) 验证first > second，否则fail --- assertGreaterEqual (first, second, msg = None) 验证first ≥ second，否则fail --- assertLess (first, second, msg = None) 验证first --- assertLessEqual (first, second, msg = None) 验证first ≤ second，否则fail --- assertRegexpMatches (text, regexp, msg = None) 验证正则表达式regexp搜索==匹配==的文本text regexp：通常使用re.search() assertNotRegexpMatches (text, regexp, msg = None) 验证正则表达式regexp搜索==不匹配==的文本text regexp：通常使用re.search() 异常断言 断言方法 断言描述 assertRaises(exc, fun, *args, **kwds) 验证异常测试，第一个参数是预期的异常,第二个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的异常，否则测试失败. assertRaisesRegex(exc, r, fun, *args, **kwds) 验证异常测试，第一个参数是预期的异常,第二个参数则是一个用来匹配错误信息的正则表达式,第三个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的异常,且错误信息也匹配，否则测试失败. assertWarns(warn, fun, *args, **kwds) 验证警告测试，第一个参数是预期的警告,第二个参数是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的警告否则测试失败. assertWarnsRegex(warn, r, fun, *args, **kwds) 验证警告测试，第一个参数是预期的警告,第二个参数则是一个用来匹配警告信息的正则表达式,第三个则是待测的函数名,后面的则是待测函数的参数.当调用待测试函数时,在传入相应的测试数据后，如果测试通过，则表明待测试函数抛出了预期的警告，且警告信息也匹配否则测试失败. assertLogs(logger, level) 断言log信息 异常断言与其他不太一样,往往结合上下文使用 %%writefile src/C3/test_assert_base.py import unittest class demoTest(unittest.TestCase): def test_eq(self): self.assertEqual(4 + 5,9) def test_not_eq(self): self.assertNotEqual(5 * 2,10) def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) def test_almost_eq(self): self.assertAlmostEqual(1.003, 1.004, places = 2) def test_not_almost_eq(self): self.assertAlmostEqual(1.003, 1.004, places = 4) def test_exc(self): def fun(): assert 0 self.assertRaises(AssertionError, fun) def test_with_exc(self): def fun(): assert 0 with self.assertRaises(AssertionError) as a: fun() Overwriting src/C3/test_assert_base.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.005s FAILED (failures=8, skipped=2, expected failures=2) 跳过测试和预期测试出错 unittest提供了4个装饰器来控制测试的行为 @unittest.skip(reason) 跳过测试用例的某条测试项目 @unittest.skipIf(condition, reason) 如果条件condition条件成立,那就跳过测试用例的某条测试项目 @unittest.skipUnless(condition, reason) 如果条件condition条件不成立,那就跳过测试用例的某条测试项目 @unittest.expectedFailure 断定测试项目会失败 %%writefile src/C3/test_assert_skip.py import unittest class demoTest(unittest.TestCase): @unittest.skip(\"跳过\") def test_eq(self): self.assertEqual(4 + 5,9) @unittest.expectedFailure def test_not_eq(self): self.assertNotEqual(5 * 2,10) @unittest.skipIf(1==0, \"if 1 ==0\") def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) @unittest.skipUnless(1==0, \"unless 1 ==0\") def test_seq_2(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) @unittest.expectedFailure def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) Overwriting src/C3/test_assert_skip.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.005s FAILED (failures=8, skipped=2, expected failures=2) 使用子测验进行迭代测试 有时候我们希望对一个迭代器中的内容分别进行测试,这种时候就可以使用测试样例的subTest上下文 %%writefile src/C3/test_subtest.py import unittest class demoTest(unittest.TestCase): def test_subtest(self): for i in range(0, 6): with self.subTest(i=i): self.assertEqual(i % 2, 0) Overwriting src/C3/test_subtest.py !python3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.006s FAILED (failures=8, skipped=2, expected failures=2) 分组测试 很多时候我们希望将测试用例组织起来一部分一部分的测试而不是一次全测了,这种时候就可以使用unittest.TestSuite组织需要的测试,细化的运行测试. 注意细分的测试不能用命令行工具来运行了,而是应该独立运行脚本 %%writefile src/C3/test_suite.py import unittest class ArithTest(unittest.TestCase): def test_eq(self): self.assertEqual(4 + 5,9) def test_not_eq(self): self.assertNotEqual(5 * 2,10) def test_seq(self): a=[\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\") self.assertSequenceEqual(a, b) def test_not_seq(self): a = [\"1\",\"2\",\"3\"] b = (\"1\",\"2\",\"3\",\"4\") self.assertSequenceEqual(a, b) def suite(): suite = unittest.TestSuite() suite.addTest(ArithTest(\"test_eq\")) suite.addTest(ArithTest('test_seq')) return suite if __name__ == '__main__': runner = unittest.TextTestRunner(verbosity=2) test_suite = suite() runner.run(test_suite) Overwriting src/C3/test_suite.py !python3 src/C3/test_suite.py test_eq (__main__.ArithTest) ... ok test_seq (__main__.ArithTest) ... ok ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK mock测试 mock测试就是在测试过程中，对于某些不容易构造或者不容易获取的对象，用一个虚拟的对象来创建以便测试的测试方法。 mock测试通常有几个使用场景: 调用外部接口 通常我的软件都会调用一些已有的服务,与这些服务进行交互我们才能顺利执行软件.这就引入了副作用——我们测试的时候不希望真的为了测试而这些外部服务,但不调用往往我们的业务逻辑又进展不下去.直观一点,我们希望测试一项扫码付款功能,它需要调用支付宝的付款接口,我们测试的时候当然并不希望真的调用支付宝付款,毕竟会真的产生交易,这种时候就是mock测试的用武之地了. 模拟耗时步骤 比如我们要写一个代码,它会进行一步耗时1小时的计算(可以假设是使用tensorflow训练一个深度学习模型).而我们的测试代码只是希望测试出去训练模型外的业务逻辑有没有出错,这样的话就可以使用mock模拟一下这一步耗时的计算,这样就可以先调通其他逻辑,确保无误后再构建完整的代码了 不修改环境的测试 比如我们的测试要删除数据库中的一条数据,而我们并不是真的要删掉,而是测试功能是否可以实现,这种时候就可以使用mock测试了 一个真实的例子 unittest模块提供了一个mock子模块, 我们以一个测试文件删除的例子来看看mock怎么工作的 待测脚本: 待测脚本可以判断path是不是文件,如果是就删除 %%writefile rm.py import os import os.path def rm(filename): if os.path.isfile(filename): os.remove(filename) Overwriting rm.py 测试用例: %%writefile test/rm_test_1.py from rm import rm from unittest import mock from unittest import TestCase class RmTestCase(TestCase): @mock.patch('rm.os.path') @mock.patch('rm.os') def test_rm(self, mock_os, mock_path): # mock_path就是patch过后的`os.path`,mock_os就是patch过后的`os` #需要注意顺序 #指定`mock_path.isfile`的返回值False mock_path.isfile.return_value = False rm(\"any path\") #测试mock_os.remove有没有被调用 self.assertFalse(mock_os.remove.called, \"Failed to not remove the file if not present.\") # 指定`mock_path.isfile`的返回值为True mock_path.isfile.return_value = True rm(\"any path\") mock_os.remove.assert_called_with(\"any path\") Overwriting test/rm_test_1.py !python3 -m unittest -v test.rm_test_1 test_rm (test.rm_test_1.RmTestCase) ... ok ---------------------------------------------------------------------- Ran 1 test in 0.003s OK mock.patch装饰器将指定的对象替换为mock,其实质就是猴子补丁. 利用patch装饰器将原始对象替换为mock对象,并将替换后的对象作为参数传入测试用例的测试项中 指定mock行为 mock对象是假的,但他可以模拟真实行为,以下是它的接口: from unittest.mock import Mock mock = Mock() 断言行为 assert_called 断言方法被调用过至少一次 mock.method.assert_called() --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 mock.method.assert_called() /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in assert_called(_mock_self) 784 msg = (\"Expected '%s' to have been called.\" % 785 self._mock_name or 'mock') --> 786 raise AssertionError(msg) 787 788 def assert_called_once(_mock_self): AssertionError: Expected 'method' to have been called. mock.method() mock.method.assert_called() assert_called_once 断言方法只被调用过一次(3.6) mock.method.assert_called_once() mock.method() mock.method.assert_called_once() --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) in () ----> 1 mock.method.assert_called_once() /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in assert_called_once(_mock_self) 793 msg = (\"Expected '%s' to have been called once. Called %s times.\" % 794 (self._mock_name or 'mock', self.call_count)) --> 795 raise AssertionError(msg) 796 797 def assert_called_with(_mock_self, *args, **kwargs): AssertionError: Expected 'method' to have been called once. Called 2 times. assert_called_with(*args, **kwargs) 断言方法被调用过且调用时的参数为填入的参数 mock.method(1,2,k=4) mock.method.assert_called_with(1, 2,k=4) assert_called_once_with(*args, **kwargs) 断言方法只被调用过一次且调用时的参数为填入的参数 assert_any_call(*args, **kwargs) 断言对象有方法被用参数调用过调用过 assert_has_calls(calls, any_order=False) 断言某些结果是被mock对象产出的 mock = Mock(return_value=None) call1 = mock(1) call2 = mock(2) call3 = mock(3) call4 = mock(4) mock.mock_calls# 查看mock对象的call对象 [call(1), call(2), call(3), call(4)] call1 = mock.mock_calls[0] call1 call(1) mock.assert_has_calls(mock.mock_calls[:2]) mock.assert_has_calls(mock.mock_calls, any_order=True) assert_not_called() 断言mock对象没被调用过 设置行为 reset_mock(*, return_value=False, side_effect=False) 重置mock对象,side_effect翻译为副作用,可以设置一个异常 mock_add_spec(spec, spec_set=False) 为mock设置规范,来定义mock对象内部的属性(attribute) attach_mock(mock, attribute) 为mock设置一个mock对象在它上面 configure_mock(**kwargs) 设置mock attrs = {'method.return_value': 3, 'other.side_effect': KeyError} mock.configure_mock(**attrs) mock.method() 3 mock.other() --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in () ----> 1 mock.other() /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in __call__(_mock_self, *args, **kwargs) 937 # in the signature 938 _mock_self._mock_check_sig(*args, **kwargs) --> 939 return _mock_self._mock_call(*args, **kwargs) 940 941 /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in _mock_call(_mock_self, *args, **kwargs) 993 if effect is not None: 994 if _is_exception(effect): --> 995 raise effect 996 997 if not _callable(effect): KeyError: return_value 设置mock的返回值 mock = Mock() mock.return_value = 'fish' mock() 'fish' side_effect 设置一个副作用,也就是异常 mock = Mock() mock.side_effect = Exception('Boom!') mock() --------------------------------------------------------------------------- Exception Traceback (most recent call last) in () 1 mock = Mock() 2 mock.side_effect = Exception('Boom!') ----> 3 mock() /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in __call__(_mock_self, *args, **kwargs) 937 # in the signature 938 _mock_self._mock_check_sig(*args, **kwargs) --> 939 return _mock_self._mock_call(*args, **kwargs) 940 941 /Users/huangsizhe/LIB/CONDA/anaconda/envs/py3/lib/python3.6/unittest/mock.py in _mock_call(_mock_self, *args, **kwargs) 993 if effect is not None: 994 if _is_exception(effect): --> 995 raise effect 996 997 if not _callable(effect): Exception: Boom! mock状态监控 called 是否被调用过 call_count 被调用计数 call_args mock的最近的call对象 mock = Mock(return_value=None) print(mock.call_args) None mock() mock.call_args call() mock.call_args == () True mock(3, 4) mock.call_args call(3, 4) mock.call_args == ((3, 4),) True mock(3, 4, 5, key='fish', next='w00t!') mock.call_args call(3, 4, 5, key='fish', next='w00t!') call_args_list mock的call对象列表 mock.call_args_list [call(), call(3, 4), call(3, 4, 5, key='fish', next='w00t!')] method_calls mock对象中的方法调用情况 mock.method_calls [] mock.method1() mock.method_calls [call.method1()] mock_calls mock自身调用和其方法调用情况 mock.mock_calls [call(), call(3, 4), call(3, 4, 5, key='fish', next='w00t!'), call.method1()] 测试覆盖率 测试通过往往也并不能保证程序一定稳健可靠,因为测试很有可能没有覆盖全面.这时候测试覆盖率就成了评价一个项目可靠程度的标准之一了. python标准库没有提供覆盖率统计工具,但coverage.py已经是实质上的覆盖率标准工具了. coverage的使用有两步: 使用coverage脚本的run命令执行脚本 !python3 -m coverage run src/C3/test_suite.py test_eq (__main__.ArithTest) ... ok test_seq (__main__.ArithTest) ... ok ---------------------------------------------------------------------- Ran 2 tests in 0.001s OK 使用report/html命令输出覆盖率结果 !coverage report Name Stmts Miss Cover ------------------------------------------ src/C3/test_suite.py 23 4 83% 如果是针对全局的测试覆盖率,那么这样用: !python3 -m coverage run --source=src/C3 -m unittest discover -v -s ./src/C3 test_almost_eq (test_assert_base.demoTest) ... ok test_eq (test_assert_base.demoTest) ... ok test_exc (test_assert_base.demoTest) ... ok test_not_almost_eq (test_assert_base.demoTest) ... FAIL test_not_eq (test_assert_base.demoTest) ... FAIL test_not_seq (test_assert_base.demoTest) ... FAIL test_seq (test_assert_base.demoTest) ... ok test_with_exc (test_assert_base.demoTest) ... ok test_eq (test_assert_skip.demoTest) ... skipped '跳过' test_not_eq (test_assert_skip.demoTest) ... expected failure test_not_seq (test_assert_skip.demoTest) ... expected failure test_seq (test_assert_skip.demoTest) ... ok test_seq_2 (test_assert_skip.demoTest) ... skipped 'unless 1 ==0' setUpModule setUpClass test_number_3_4 (test_hook.Test_mul) ... instance setUp t1 instance tearDown ok test_string_a_3 (test_hook.Test_mul) ... instance setUp t2 instance tearDown ok tearDownClass tearUpModule test_sum_mul_2_3_mul_2_3 (test_my.TestCase1) ... ok test_number_3_4 (test_my.Test_mul) ... ok test_string_a_3 (test_my.Test_mul) ... ok test_number_3_4 (test_my.Test_sum) ... ok test_number_3_4_5 (test_my.Test_sum) ... ok test_subtest (test_subtest.demoTest) ... test_eq (test_suite.ArithTest) ... ok test_not_eq (test_suite.ArithTest) ... FAIL test_not_seq (test_suite.ArithTest) ... FAIL test_seq (test_suite.ArithTest) ... ok ====================================================================== FAIL: test_not_almost_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 23, in test_not_almost_eq self.assertAlmostEqual(1.003, 1.004, places = 4) AssertionError: 1.003 != 1.004 within 4 places ====================================================================== FAIL: test_not_eq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_assert_base.demoTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_assert_base.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=1) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=3) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_subtest (test_subtest.demoTest) (i=5) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_subtest.py\", line 7, in test_subtest self.assertEqual(i % 2, 0) AssertionError: 1 != 0 ====================================================================== FAIL: test_not_eq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 7, in test_not_eq self.assertNotEqual(5 * 2,10) AssertionError: 10 == 10 ====================================================================== FAIL: test_not_seq (test_suite.ArithTest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/Users/huangsizhe/WORKSPACE/Blog/Docs/Python/TutorialForPython3.5plus/ipynbs/src/C3/test_suite.py\", line 17, in test_not_seq self.assertSequenceEqual(a, b) AssertionError: Sequences differ: ['1', '2', '3'] != ('1', '2', '3', '4') Second sequence contains 1 additional elements. First extra element 3: '4' - ['1', '2', '3'] + ('1', '2', '3', '4') ---------------------------------------------------------------------- Ran 25 tests in 0.014s FAILED (failures=8, skipped=2, expected failures=2) 其中--source=用于指定要测试覆盖率的文件夹 !python3 -m coverage report Name Stmts Miss Cover --------------------------------------------------- src/C3/Obj_test.py 7 7 0% src/C3/__init__.py 0 0 100% src/C3/faulthandler_test.py 2 2 0% src/C3/faulthandler_test2.py 4 4 0% src/C3/func_oper_unitest.py 7 0 100% src/C3/line_profile_test.py 7 7 0% src/C3/memory_test.py 15 15 0% src/C3/memory_test_round.py 8 8 0% src/C3/profile_test.py 11 11 0% src/C3/profile_test_foo.py 7 7 0% src/C3/profile_test_pstats.py 14 14 0% src/C3/test_assert_base.py 27 0 100% src/C3/test_assert_skip.py 18 4 78% src/C3/test_hook.py 23 1 96% src/C3/test_my.py 23 1 96% src/C3/test_subtest.py 6 0 100% src/C3/test_suite.py 23 7 70% --------------------------------------------------- TOTAL 202 88 56% 当然了还有其他的知名测试框架比如nose,green等,都很值得尝试.但个人觉得标准库的测试框架已经相当够用,结合coverage.py,也很简单直接.少即是多,我们的项目应该尽量减少第三方依赖 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"工具链/结语.html":{"url":"工具链/结语.html","title":"结语","keywords":"","body":"结语 python与运维 python在很多时候是作为系统脚本代替bash做运维工具的,因此python的运维工具非常丰富. 而被称为python三大神器的pip,virtualenv(python3中的pyvenv),fabric,每个都是运维工具. 时至今日,许多python程序员也都是运维出身. python与docker 关于这个问题,华莽论坛上也有讨论,大家的意见基本上是一致的,可以说docker是运维的未来. 而以后的运维也不会是简单的运维了,而是所谓devops, 运维也将不会作为独立职位存在. 但python工具确实相当纯粹实用,除了无法控制资源消耗外,光从部署便利角度来说与docker并无区别.因此个人建议: 追求性能,不要使用docker,毕竟虚拟化技术必然会牺牲一些性能 追求可靠性并且有控制运行资源的需求就用docker 一个值得关注的python项目pex就是一个类似docker镜像的工具 关于eggs 其实还有一种模块分发格式,叫做eggs,在之前的一段时间内非常流行,它的本质也是zip包, 他有一些特性很优秀比如可以直接import,因此开源的项目管理软件Trac使用这种格式分发插件 但是最终它成了时代的眼泪,wheel虽然没有实质上取代eggs,但至少在名义上wheel成了正宫.关于wheel和eggs的比较可以看这篇文章 个人认为wheel对eggs并没有压倒性优势,但还是建议跟随时代的步伐,新项目还是用官方钦定的wheel为好 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"Python的数据模型/":{"url":"Python的数据模型/","title":"Python的数据模型","keywords":"","body":"Python的数据模型 Python一直以来以实用性和一致性著称,而简单优雅的对象模型正是其实用性和一致性的来源. 本部分将包括以下几个部分: 数据模型 变量引用与垃圾回收 本部分是python的基本内容,主要是讲的解释器的调用对象方式和对象生命周期控制. python的解释器有一套简单实用的内在逻辑来处理运行时的对象生命周期. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-08 00:06:41 "},"Python的数据模型/数据模型.html":{"url":"Python的数据模型/数据模型.html","title":"数据模型","keywords":"","body":"数据模型 python最好的品质之一是一致性,当你熟悉了python之后遇到一个新的模块你总是可以快速的理解它,这便是得益于其一致性,任何对象都平等一致没有\"魔法\". 如果你用惯了典型的面向对象语言如java这种,初看python的代码会很不习惯.比如希望知道一个列表的长度,符合面向对象语言的查看方式是collection.len()而在python中很奇怪确是len(collection).更奇怪的是无论是列表,字典,集合还是什么,取长度都是len(object) 这是一种设计思想上的差别,python中万物都是对象,但python却不是纯粹的面向对象语言.所谓的pythonic的关键也在于此.这种设计思想完全体现在python的数据模型上,而python数据模型的通用API也为用户自己构建符合python语言特性的对象提供了工具. python的数据模型与其说是模型不如说是语言框架描述,它规范了一套语言自身的交互接口,只要符合这些接口,对象就可以与语言框架与其他符合接口的对象相互交互.正是因为python的一致性,使用python语言不会让你觉得自由,但会让你觉得轻松.因此常有人将python编程比喻为搭乐高积木,衔接用的接口已经都设计好了,玩家要做的只是发挥想象力专注于实现自己的创意. \"魔术方法\" 那么这些用于实现语言框架接口又是什么样呢? 这些接口被戏称为\"魔术方法\",他们的特征是方法名前后都有如__的两个下划线,这些方法能让你自己的对象实现如下的语言框架: 迭代 集合类 属性访问 运算符重载 函数和方法的调用 对象的创建和销毁 字符串表示形式和格式化 上下文管理 协程 实际感受下魔术方法 下面是一个例子用来展示如何使用__getitme__和__len__这两个魔术方法,帮助我们构建一个有序的扑克牌类的过程(例子来自第一章示例1.1) 注:为了便于理解这个例子所有变量用中文.实际编程的时候用中文并不是好习惯,尤其是参与开源项目的时候 from collections import namedtuple Card = namedtuple('扑克牌', ['大小', '花色']) class 牌堆: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = '梅花 方片 红桃 黑桃'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] 首先，我们用collections.namedtuple构建了一个简单的类来表示一张纸牌。namedtuple常用于构建只有少数属性但是没有方法的对象，比如数据库条目。利用namedtuple，我们可以很轻松地得到一个纸牌对象： beer_card = Card(\"7\",\"方片\") beer_card 扑克牌(大小='7', 花色='方片') 当然，我们这个例子主要还是关注FrenchDeck 这个类,它既短小又精悍.首先，它跟任何标准Python集合类型一样,可以用len()函数来查看一叠牌有多少张： deck = 牌堆() len(deck) 52 deck[0] 扑克牌(大小='2', 花色='梅花') 要随机抽取一张牌,只要使用python标准库的random.choice即可 from random import choice choice(deck) 扑克牌(大小='8', 花色='红桃') 现在已经可以体会到通过实现魔术方法来利用Python 数据模型的两个好处 作为你的类的用户，他们不必去记住标准操作的各式名称（\"怎么得到元素的总数？是.size()还是.length()还是别的什么？\"） 由于接口统一,可以更加方便地利用Python的标准库,比如random.choice函数，从而不用重新发明轮子,即便是使用第三方库,只要大家都统一使用相同的接口也可以相互调用. 因为__getitem__ 方法把[]操作交给了self._cards列表,所以我们的deck 类自动支持切片slicing操作 deck[:3] [扑克牌(大小='2', 花色='梅花'), 扑克牌(大小='3', 花色='梅花'), 扑克牌(大小='4', 花色='梅花')] deck[12::13] [扑克牌(大小='A', 花色='梅花'), 扑克牌(大小='A', 花色='方片'), 扑克牌(大小='A', 花色='红桃'), 扑克牌(大小='A', 花色='黑桃')] 同时因为实现了__getitem__方法，这一摞牌就变成可迭代的了 for card in deck: if card.花色 == \"红桃\": print(card) 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='A', 花色='红桃') 迭代通常是隐式的，譬如说一个集合类型没有实现__contains__方法，那么in运算符就会按顺序做一次迭代搜索。于是，in 运算符可以用在我们的FrenchDeck类上，因为它是可迭代的 排序 我们按照常规，用点数来判定扑克牌的大小，2 最小、A 最大；同时还要加上对花色的判定，黑桃最大、红桃次之、方块再次.梅花最小。下面就是按照这个规则来给扑克牌排序的函数，梅花2 的大小是0，黑桃A 是51： def spades_high(card): 花色取值 = dict(梅花=3, 红桃=2, 方片=1, 黑桃=0) rank_value = 牌堆.ranks.index(card.大小) return rank_value * len(花色取值) + 花色取值[card.花色] for card in sorted(deck, key=spades_high): print(card) 扑克牌(大小='2', 花色='黑桃') 扑克牌(大小='2', 花色='方片') 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='2', 花色='梅花') 扑克牌(大小='3', 花色='黑桃') 扑克牌(大小='3', 花色='方片') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='3', 花色='梅花') 扑克牌(大小='4', 花色='黑桃') 扑克牌(大小='4', 花色='方片') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='4', 花色='梅花') 扑克牌(大小='5', 花色='黑桃') 扑克牌(大小='5', 花色='方片') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='5', 花色='梅花') 扑克牌(大小='6', 花色='黑桃') 扑克牌(大小='6', 花色='方片') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='6', 花色='梅花') 扑克牌(大小='7', 花色='黑桃') 扑克牌(大小='7', 花色='方片') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='7', 花色='梅花') 扑克牌(大小='8', 花色='黑桃') 扑克牌(大小='8', 花色='方片') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='8', 花色='梅花') 扑克牌(大小='9', 花色='黑桃') 扑克牌(大小='9', 花色='方片') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='9', 花色='梅花') 扑克牌(大小='10', 花色='黑桃') 扑克牌(大小='10', 花色='方片') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='10', 花色='梅花') 扑克牌(大小='J', 花色='黑桃') 扑克牌(大小='J', 花色='方片') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='J', 花色='梅花') 扑克牌(大小='Q', 花色='黑桃') 扑克牌(大小='Q', 花色='方片') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='Q', 花色='梅花') 扑克牌(大小='K', 花色='黑桃') 扑克牌(大小='K', 花色='方片') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='K', 花色='梅花') 扑克牌(大小='A', 花色='黑桃') 扑克牌(大小='A', 花色='方片') 扑克牌(大小='A', 花色='红桃') 扑克牌(大小='A', 花色='梅花') 为牌堆添加洗牌功能 目前的牌堆无法洗牌,这是因为我们虽然用__getitem__方法将获取牌的位置行为委托给了self._cards,但这实际上只是实现了不可变序列协议,关于这些协议的问题,会在后面讲到.要让牌堆支持洗牌,还需要给它定义一个__setitem__方法. class 牌堆: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = '梅花 方片 红桃 黑桃'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] def __setitem__(self,position,card): self._cards[position] = card deck = 牌堆() from random import shuffle shuffle(deck) for i in deck: print(i) 扑克牌(大小='5', 花色='梅花') 扑克牌(大小='10', 花色='黑桃') 扑克牌(大小='3', 花色='红桃') 扑克牌(大小='8', 花色='红桃') 扑克牌(大小='6', 花色='黑桃') 扑克牌(大小='A', 花色='红桃') 扑克牌(大小='Q', 花色='梅花') 扑克牌(大小='4', 花色='梅花') 扑克牌(大小='4', 花色='方片') 扑克牌(大小='K', 花色='黑桃') 扑克牌(大小='9', 花色='黑桃') 扑克牌(大小='10', 花色='梅花') 扑克牌(大小='5', 花色='红桃') 扑克牌(大小='6', 花色='红桃') 扑克牌(大小='J', 花色='梅花') 扑克牌(大小='6', 花色='梅花') 扑克牌(大小='5', 花色='方片') 扑克牌(大小='7', 花色='黑桃') 扑克牌(大小='K', 花色='梅花') 扑克牌(大小='Q', 花色='黑桃') 扑克牌(大小='7', 花色='梅花') 扑克牌(大小='4', 花色='红桃') 扑克牌(大小='7', 花色='红桃') 扑克牌(大小='8', 花色='黑桃') 扑克牌(大小='4', 花色='黑桃') 扑克牌(大小='K', 花色='方片') 扑克牌(大小='9', 花色='梅花') 扑克牌(大小='Q', 花色='方片') 扑克牌(大小='5', 花色='黑桃') 扑克牌(大小='J', 花色='黑桃') 扑克牌(大小='2', 花色='黑桃') 扑克牌(大小='9', 花色='红桃') 扑克牌(大小='7', 花色='方片') 扑克牌(大小='2', 花色='梅花') 扑克牌(大小='2', 花色='方片') 扑克牌(大小='3', 花色='方片') 扑克牌(大小='3', 花色='梅花') 扑克牌(大小='10', 花色='方片') 扑克牌(大小='K', 花色='红桃') 扑克牌(大小='A', 花色='黑桃') 扑克牌(大小='8', 花色='梅花') 扑克牌(大小='Q', 花色='红桃') 扑克牌(大小='J', 花色='红桃') 扑克牌(大小='3', 花色='黑桃') 扑克牌(大小='6', 花色='方片') 扑克牌(大小='2', 花色='红桃') 扑克牌(大小='10', 花色='红桃') 扑克牌(大小='9', 花色='方片') 扑克牌(大小='A', 花色='梅花') 扑克牌(大小='J', 花色='方片') 扑克牌(大小='A', 花色='方片') 扑克牌(大小='8', 花色='方片') 如何使用魔术方法 首先明确一点，魔术方法的存在是为了被Python 解释器调用的，你自己并不需要调用它们。也就是说没有my_object.__len__()这种写法(虽然其实这样写也会正常运行)，而应该使用len(my_object)。在执行 len(my_object)的时候，如果my_object是一个自定义类的对象，那么Python 会自己去调用其中由你实现的__len__方法。 然而如果是Python 内置的类型，比如列表(list)、字符串(str)、字节序列(bytearray)等，那么CPython 会抄个近路，__len__ 实际上会直接返回PyVarObject里的ob_size属性。PyVarObject是表示内存中长度可变的内置对象的C语言结构体。直接读取这个值比调用一个方法要快很多。 很多时候，魔术方法的调用是隐式的，比如for i in x: 这个语句，背后其实用的是iter(x)，而这个函数的背后则是x.__iter__()方法。当然前提是这个方法在x中被实现了。 通常你的代码无需直接使用魔术方法。除非有大量的元编程存在，直接调用魔术方法的频率应该远远低于你去实现它们的次数。唯一的例外可能是__init__ 方法，你的代码里可能经常会用到它，目的是在你自己的子类的__init__ 方法中调用超类的构造器。 通过内置的函数（例如len、iter、str，等等）来使用魔术方法是最好的选择。这些内置函数不仅会调用魔术方法，通常还提供额外的好处，而且对于内置的类来说，它们的速度更快。 另外:不要自己想当然地随意添加魔术方法，比如__foo__之类的，因为虽然现在这个名字没有被Python 内部使用，以后就不一定了 目前的魔术方法都可以在官网的第3节中找到详细说明.这边不一一复述. 为什么len不是普通方法? 回到最初的问题,为什么不是collection.len()而是len(collection)? len之所以不是一个普通方法,是为了让Python 自带的数据结构可以\"走后门\",让解释器可以针对内置数据类型提供更好的优化.同时多亏了它是魔术方法，我们也可以把len 用于自定义数据类型.纯粹未必是最好的,python的数据模型实现兼顾通用性,效率和一致性.也印证了\"Python之禅\"中的一句话:\"不能让特例特殊到开始破坏既定规则.\" Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-17 23:15:35 "},"Python的数据模型/变量引用与垃圾回收.html":{"url":"Python的数据模型/变量引用与垃圾回收.html","title":"变量引用与垃圾回收","keywords":"","body":"变量引用 中文中太阳叫\"太阳\",英语中太阳叫\"sun\",法语中太阳叫\"soleil\",日语中太阳叫\"たいよう\",不同的叫法其实指的是同一个东西. python中的变量就有点像各种语言中的名词,它只是代表一个对象而已. 通常我们将变量与对象的关系称作打标签,变量就是我们的标签,而对象就是要被打标签的东西. python中的变量与对象的关系比较类似java中的引用,或者说是C中的指针变量. 标识,相等性和别名 我们还是用之前的扑克牌来做例子 from collections import namedtuple Card = namedtuple('扑克牌', ['大小', '花色']) 红桃A = Card(\"A\",\"红桃\") 红桃A 扑克牌(大小='A', 花色='红桃') 红桃Ace = 红桃A 红桃A is 红桃Ace True 可以看到,红桃A和红桃Ace其实是同一个东西.这边又有了一个新的问题,怎么看出来这两个变量其实是一个对象呢? id(红桃A),id(红桃Ace) (4432866328, 4432866328) 内置方法id()可以检查对象identity,每个对象在生成的时候就会产生一个identity,同一个进程中同一时间不会存在不同的identity在虚拟机中,cpython中对象的identity是其内存中的空间. is运算符专门用来判别变量指向的对象的identity是否一样.也就是是不是指向同一个对象. is和== python中也常会有要判别两个对象是否相等的情况 import copy def one(): return [1,2,3] a = one() b = copy.copy(a) a == b True a is b False a和b不是同一个对象,但内容一样.那为啥可以用==判断呢?==实际上是调用对象的魔术方法__eq__而的运算来的,只要在对象中改写这个方法其实也可以让a不等于b,不过__eq__是无法在外部改写的,这也相对增加了安全性 a.__eq__(b) True a.__eq__ = lambda x:False --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 a.__eq__ = lambda x:False AttributeError: 'list' object attribute '__eq__' is read-only 可变对象与不可变对象 一般来说python中的对象分为两类 不可变对象 可变对象 不可变对象包括str,bytes和数字类型,他们特点就是存在内存中,对象的内容是不可变的. 可变对象包括list,dict,set,以及自定义类型的实例等. 对象复制 python标准库提供了一个用于复制可变对象的工具copy import copy a = [1,2,3,4,5] id(a) 4431672264 aa = copy.copy(a) id(aa) 4433718856 a == aa True a is aa False 像python内置的容器,直接使用自身作为参数实例化一个新对象可以简单的复制 ab = list(a) id(ab) 4433904456 list有一个语法糖,可以简单的复制原有列表 aaa = a[:] id(aaa) 4433718408 浅复制和深复制 浅复制是指复制了最外层容器,副本中的元素是源容器中元素的引用.而深复制则是完全复制.python默认使用浅复制. 对于浅复制,如果所有元素都是不可变的,那么这样没有问题,还能节省内存。但是,如果有可变的元素,可能就会导致意想不到的问题. python中浅复制和深复制可以分别使用copy.copy(object)和copy.deepcopy(object)来实现,而对象复制操作对应的接口为__copy__() 和 __deepcopy__() 下面一个例子(来自流畅的python例8-8)可以用来对比浅复制和深复制的差别 class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) import copy bus1 = Bus(['Alice', 'Bill', 'Claire', 'David']) bus2 = copy.copy(bus1) bus3 = copy.deepcopy(bus1) id(bus1), id(bus2), id(bus3) (4433843704, 4433843648, 4433843872) bus1.drop('Bill') bus1.passengers ['Alice', 'Claire', 'David'] bus2.passengers ['Alice', 'Claire', 'David'] id(bus1.passengers), id(bus2.passengers), id(bus3.passengers) (4433855560, 4433855560, 4433905800) bus3.passengers ['Alice', 'Bill', 'Claire', 'David'] bus1 和 bus2 共享同一个列表对象,因为 bus2 是 bus1 的浅复制副本。 函数参数作为引用时 Python 唯一支持的参数传递模式是共享传参(call by sharing)。多数面向对象语言都采用这一模式,包括 Ruby、Smalltalk 和 Java(Java 的引用类型是这样,基本类型按值传参)。共享传参指函数的各个形式参数获得实参中各个引用的副本。也就是说,函数内部的形参 是实参的别名。 这种方案的结果是,函数可能会修改作为参数传入的可变对象,但是无法修改那些对象的标识(即不能把一个对象替换成另一个对象).下例中有个简单的函数,它在参数上 调用 += 运算符。分别把数字、列表和元组传给那个函数,实际传入的实参会以不同的方式受到影响。 def f(a, b): a += b return a x = 1 y = 2 f(x, y) 3 a = [1, 2] b = [3, 4] f(a, b) [1, 2, 3, 4] a, b ([1, 2, 3, 4], [3, 4]) t = (10, 20) u = (30, 40) f(t, u) (10, 20, 30, 40) t, u ((10, 20), (30, 40)) 不要使用可变类型作为参数的默认值 可选参数可以有默认值,这是Python函数定义的一个很棒的特性,这样我们的API在进化的同时能保证向后兼容。然而,我们应该避免使用可变的对象作为参数的默认值。 下面的例子中我们用之前的Bus类为基础定义一个新类,HauntedBus,然后修改 __init__ 方法。这一次,passengers的默认值不是None,而是[], 这样就不用像之前那样使用if判断了。这个'聪明的举动'会让我们陷入麻烦 class HauntedBus: \"\"\"备受幽灵乘客折磨的校车\"\"\" def __init__(self, passengers=[]): self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 然后就会出现下面的诡异行为 bus1 = HauntedBus(['Alice', 'Bill']) bus1.passengers ['Alice', 'Bill'] bus1.pick('Charlie') bus1.drop('Alice') bus1.passengers ['Bill', 'Charlie'] bus2 = HauntedBus() bus2.pick('Carrie') bus2.passengers ['Carrie'] bus3 = HauntedBus() bus3.passengers ['Carrie'] bus3.pick('Dave') bus2.passengers ['Carrie', 'Dave'] bus2.passengers is bus3.passengers True bus1.passengers ['Bill', 'Charlie'] 问题就在于,没有指定初始乘客的HauntedBus实例会共享同一个乘客列表. 这种问题很难发现。如示上例所示,实例化HauntedBus时,如果传入乘客,会按预期运作.但是不为HauntedBus指定乘客的话,奇怪的事就发生了,这是因为self. passengers变成了passengers参数默认值的别名. 出现这个问题的根源是,默认值在定义函数时计算(通常在加载模块时),因此默认值变成了函数对象的属性.因此,如果默认值是可变对象,而且修改了它的值,那么后续的函数调用都会受到影响. HauntedBus.__init__.__defaults__ (['Carrie', 'Dave'],) 我们可以验证bus2.passengers是一个别名,它绑定到HauntedBus.__init__.__ defaults__ 属性的第一个元素上 可变默认值导致的这个问题说明了为什么通常使用None作为接收可变值的参数的默认值 防御可变参数 如果定义的函数接收可变参数,应该谨慎考虑调用方是否期望修改传入的参数. 例如,如果函数接收一个字典,而且在处理的过程中要修改它,那么这个副作用要不要体现到函数外部? 具体情况具体分析。这其实需要函数的编写者和调用方达成共识. 最后一个校车示例中,TwilightBus实例与客户共享乘客列表,这会产生意料之外的结果.在分析实现之前,我们先从客户的角度看看TwilightBus类是如何工作的. class TwilightBus: \"\"\"让乘客销声匿迹的校车\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus = TwilightBus(basketball_team) bus.drop('Tina') bus.drop('Pat') basketball_team ['Sue', 'Maya', 'Diana'] TwilightBus 违反了设计接口的最佳实践,即'最少惊讶原则'.学生从校车中下车后,她的名字就从篮球队的名单中消失了,这确实让人惊讶. 除非本来就有这种需求,否则我们应该让校车自己维护乘客列表 class Bus: \"\"\"行为正常的校车\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers[:] def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus = Bus(basketball_team) bus.drop('Tina') bus.drop('Pat') basketball_team ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] bus.passengers ['Sue', 'Maya', 'Diana'] 内置方法del和垃圾回收 对象绝不会自行销毁;然而,无法得到对象时,可能会被当作垃圾回收. del语句 del语句删除名称,而不是对象.del命令可能会导致对象被当作垃圾回收,但是那仅是当删除的变量保存的是对象的最后一个引用,或者无法得到对象时的情况.重新绑定名字到其他对象如None也可能会导致对象的引用数量归零,导致对象被销毁. 有个__del__特殊方法,但是它不会销毁实例而是在即将销毁实例之前触发,它不应该在代码中调用. 即将销毁实例时,Python解释器会调用__del__方法,给实例最后的机会,释放外部资源.自己编写的代码很少需要实现 __del__代码,有些python 新手会花时间实现,但却吃力不讨好,因为__del__很难用对.具体的可以看Python 语言参 考手册中'Data Model'一章中__del__特殊方法的文档 垃圾回收 在 CPython 中,垃圾回收使用的主要算法是引用计数.实际上,每个对象都会统计有多少引用指向自己.当引用计数归零时,对象立即就被销毁: CPython 会在对象上调用__del__方法(如果定义了), 然后释放分配给对象的内存 CPython 2.0 增加了分代垃圾回收算法, 用于检测引用循环中涉及的对象组——如果一组对象之间全是相互引用,即使再出色的引用方式也会导致组中的对象不可获取. Python的其他实现有更复杂的垃圾回收程序,而且不依赖引用计数,这意味着,对象的引用数量为零时可能不会立即调用__del__方法. 为了演示对象生命结束时的情形,下例使用weakref.finalize注册一个回调函数,在销毁对象时调用. import weakref s1 = {1, 2, 3} s2 = s1 bye = lambda :print('对象随风而逝~') ender = weakref.finalize(s1, bye) ender.alive True del s1 ender.alive True s2 = 'spam' 对象随风而逝~ ender.alive False 你可能觉得奇怪,为什么上例中的{1, 2, 3}对象被销毁了?毕竟,我们把s1引用传给finalize函数了,而为了监控对象和调用回调,必须要有引用。这是因为,finalize持有{1, 2, 3}的弱引用 弱引用 正是因为有引用,对象才会在内存中存在.当对象的引用数量归零后,垃圾回收程序会把对象销毁.但是,有时需要引用对象,而不让对象存在的时间超过所需时间.这经常用在缓存中. 弱引用不会增加对象的引用数量.引用的目标对象称为所指对象(referent).因此我们说,弱引用不会妨碍所指对象被当作垃圾回收. 弱引用在缓存应用中很有用,因为我们不想仅因为被缓存引用着而始终保存缓存对象. 下例展示了如何使用weakref.ref实例获取所指对象.如果对象存在,调用弱引用可以获取对象;否则返回None. weakref.getweakrefcount(object) 可以获取对象object关联的弱引用对象数 weakref.getweakrefs(object)可以获取object关联的弱引用对象列表 import weakref def callback(reference): \"\"\"Invoked when referenced object is deleted\"\"\" print('callback(', reference, ')') obj = {2, 3} r = weakref.ref(obj, callback) print('obj:', obj) print('ref:', r) print('r():', r()) print('deleting obj') del obj print('r():', r()) obj: {2, 3} ref: r(): {2, 3} deleting obj callback( ) r(): None 代理Proxy 使用weakref.proxy和使用普通weakref的区别就是不需要()，可以像原对象一样地使用proxy访问原对象的属性。 import weakref def test_func(reference): print('Hello from Callback function!') a = {1,2,3} #建立一个对a的代理(弱引用) x = weakref.proxy(a, test_func) print(a) print(x) del a {1, 2, 3} {1, 2, 3} Hello from Callback function! weakref模块的文档指出,weakref.ref类其实是低层接口,供高级用途使用,多数程序最好使用weakref集合和finalize.也就是说,应该使用WeakKeyDictionary、WeakValueDictionary、WeakSet 和 finalize(在内部使用弱引用),不要自己动手创建并处理weakref.ref实例. 下面以WeakValueDictionary为例子看看weakref的高级接口如何使用. WeakValueDictionary类实现的是一种可变映射,里面的值是对象的弱引用.被引用的对象在程序中的其他地方被当作垃圾回收后,对应的键会自动从WeakValueDictionary中删除.因此,WeakValueDictionary经常用于缓存。 我们对WeakValueDictionary的演示是奶酪店,客户问了40多种奶酪,包括切达干酪和马苏里拉奶酪,但是都没有货. class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return 'Cheese({self.kind})'.format(self=self) 我们把catalog中的各种奶酪载入WeakValueDictionary实现的stock中。然而,删除catalog后,stock 中只剩下一种奶酪了. import weakref stock = weakref.WeakValueDictionary() catalog = [Cheese('Red Leicester'), Cheese('Tilsit'),Cheese('Brie'), Cheese('Parmesan')] for cheese in catalog: stock[cheese.kind] = cheese sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] del catalog sorted(stock.keys()) ['Parmesan'] del cheese sorted(stock.keys()) [] 删除catalog之后,stock中的大多数奶酪都不见了,这是WeakValueDictionary的预期行为。为什么不是全部呢? 临时变量引用了对象,这可能会导致该变量的存在时间比预期长。通常,这对 局部变量来说不是问题,因为它们在函数返回时会被销毁。但是在上例中,for循环中的变量cheese是全局变量,除非显式删除,否则不会消失 与WeakValueDictionary对应的是 WeakKeyDictionary, 后者的键是弱引用. WeakKeyDictionary 实例可以为应用中其他部分拥有的对象附加数据,这样就无需为对象添加属性。这对覆盖属性访问权限的对象尤其有用。 weakref模块还提供了WeakSet类,按照文档的说明,这个类的作用很简单--'保存元素弱 引用的集合类.元素没有强引用时,集合会把它删除' 如果一个类需要知道所有实例, 一种好的方案是创建一个WeakSet类型的类属性,保存实例的引用。如果使用常规的set, 实例永远不会被垃圾回收,因为类中有实例的强引用,而类存在的时间与Python进程一样 长,除非显式删除类。 这些集合,以及一般的弱引用,能处理的对象类型有限.不是每个Python对象都可以作为弱引用的目标(或称所指对象)。基本的 list和dict实例不能作为所指对象,但是它们的子类可以轻松地解决这个问题 class MyList(list): \"\"\"list的子类,实例可以作为弱引用的目标\"\"\" pass a_list = MyList(range(10)) # a_list可以作为弱引用的目标 wref_to_a_list = weakref.ref(a_list) set实例可以作为所指对象,因此上例才使用set实例.用户定义的类型也没问题,但是int和tuple实例不能作为弱引用的目标,甚至它们的子类也不行。 这些局限基本上是CPython的实现细节,在其他Python解释器中情况可能不一样.这些局限是内部优化导致的结果. Python对不可变类型施加的把戏 python的内部有一种优化措施较驻留(interning).他的结果之一就是共享字符串字面量,以及在小的整数防止重复创建'热门'数字,如 0、—1 和 42。注意,CPython不会驻留 所有字符串和整数,驻留的条件是实现细节,而且没有文档说明.这一优化措施可以节省内存,提升解释器的速度.但只有不可变类型会受到影响.这也是为什么弱引用在int,tuple这类不可变类型中无法使用的原因 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-17 23:15:29 "},"Python的数据模型/结语.html":{"url":"Python的数据模型/结语.html","title":"结语","keywords":"","body":"结语 '数据模型'一词的由来 数据模型(Data model)来自于官网的第3节, 全文中出现了400次object,个人认为叫\"对象模型\"似乎更合适,可能叫数据模型的意图是不想被认为python是一门纯粹的面向对象语言吧. '魔术方法' 在 Ruby 中也有类似“特殊方法”的概念,但是 Ruby 社区称之为“魔术方法”,而实际上 Python 社区里也有不少人用的是后者。Python 和 Ruby 都利用了这个概念来提供丰富的元对象协议,这既不是魔术也不特殊,而是让语言的用户和核心开发者拥有并使用同样的工具。 考虑一下 JavaScript,情况就正好反过来了.JavaScript 中的对象有不透明的魔术般的特性,而你无法在自定义的对象中模拟这些行为。比如在 JavaScript 1.8.5 中,用户的自定义对象不能有只读属性,然而不少 JavaScript 的内置对象却可以有。因此在 JavaScript 中,只读属性是“魔术”般的存在,对于普通的 JavaScript 用户而言,它 就像超能力一样。2009 年推出的 ECMAScript 5.1 才让用户可以定义只读属性。 JavaScript 中跟元对象协议有关的部分一直在进化,但由于历史原因,这方面它还是赶不上 Python 和 Ruby。 python中人人平等 Python 采取了直观的方式来比较对象. ==运算符比较对象的值,而 is 比较引用. 你可以在自己的类中定义 __eq__ 方法,决定 == 如何比较实例。如果不覆盖 __eq__ 方法,那么从 object 继承的方法比较对象的ID,因此这种后备机制认为用户定义的类的各个实例是不同的。 此外,Python 支持重载运算符,== 能正确处理标准库中的所有对象,包括None——这是一个正常的对象.说来python中语言层面来讲所有对象都是正常对象,有相似的行为 可变性 如果所有 Python 对象都是不可变的,那么本章就没有存在的必要了。处理不可变的对象时,变量保存的是真正的对象还是共享对象的引用无关紧要。如果a == b成立,而且两个对象都不会变,那么它们就可能是相同的对象。这就是为什么字符串可以安全 使用驻留。仅当对象可变时,对象标识才重要. 在“纯”函数式编程中,所有数据都是不可变的,如果为集合追加元素,那么其实会创建新的集合。然而,Python不是函数式语言,更别提纯不纯了。在 Python 中,用户定义的类,其实例默认可变(多数面向对象语言都是如此)。自己创建对象时,如果需要不可变的对象,一定要格外小心。此时,对象的每个属性都必须是不可变的,否则会出现类似元组那种行为:元组本身不可变,但是如果里面保存着可变对象,那么元组的值可能会变. 可变对象还是导致多线程编程难以处理的主要原因,因为某个线程改动对象后,如果不正确地同步,那就会损坏数据。但是过度同步又会导致死锁. 对象析构和垃圾回收 Python 没有直接销毁对象的机制,这一疏漏其实是一个好的特性:如果随时可以销毁对象,那么指向对象的强引用怎么办? CPython 中的垃圾回收主要依靠引用计数,这容易实现,但是遇到引用循环容易泄露内存,因此 CPython 2.0实现了分代垃圾回收程序,它能把引用循环中不可获取的对象销毁。 但是引用计数仍然作为一种基准存在,一旦引用数量归零,就立即销毁对象。这意味着,在CPython中,这样写是安全的(至少目前如此): open('test.txt', 'w', encoding='utf-8').write('1, 2, 3') 这行代码是安全的,因为文件对象的引用数量会在 write 方法返回后归零,Python 在销毁内存中表示文件的对象之前,会立即关闭文件。然而,这行代码在 Jython 或 IronPython 中却不安全,因为它们使用的是宿主运行时(Java VM 和 .NET CLR)中的垃圾回收程序,那些回收程序更复杂,但是不依靠引用计数,而且销毁对象和关闭文件的时间可能更长。在任何情况下,包括 CPython,最好显式关闭文件;而关闭文件的最可靠方式是使用 with 语句,它能保证文件一定会被关闭,即使打开文件时抛出了 异常也无妨。使用 with,上述代码片段变成了: with open('test.txt', 'w', encoding='utf-8') as fp: fp.write('1, 2, 3') 参数传递:共享传参 解释 Python 中参数传递的方式时,人们经常这样说:\"参数按值传递,但是这里的值是引用.\" 这么说没错,但是会引起误解,因为在旧式语言中,最常用的参数传递模式有按值传递(如C语言,函数得到参数的副本)和 按引用传递(函数得到参数的指针).在 Python 中,函数得到参数的副本,但是参数始终是引用.因此,如果参数引用的是可变对象, 那么对象可能会被修改,但是对象的标识不变.此外,因为函数得到的是参数引用的副本,所以重新绑定对函数外部没有影响. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-08 00:24:59 "},"文本_文件与字节序/":{"url":"文本_文件与字节序/","title":"文本,文件与字节序","keywords":"","body":"文本,内存与字节序列 人类使用文本,计算机使用字节序列. 说到底计算机语言就是将人类使用的文本转化为机器使用字节序列的工具,而内存则是存放要处理内容的空间. 本节讲文本与字节序列的,并且讲解python中的内存工具和流工具 文本和编码 字节序列与内存视图 正则表达式 文件与IO流 序列化 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/文本和编码.html":{"url":"文本_文件与字节序/文本和编码.html","title":"文本和编码","keywords":"","body":"文本和编码 字符串是个相当简单的概念:一个字符串是一个字符序列。问题出在\"字符\"的定义上。 在2015 年,\"字符\"的最佳定义是Unicode字符。因此，从Python 3 的str对象中获取 的元素是Unicode字符 Unicode 标准把字符的标识和具体的字节表述进行了如下的明确区分。 字符的标识，即码位，是0~1 114 111的数字（十进制），在Unicode标准中以4~6个十六进制数字表示，而且加前缀U+。例如，字母A的码位是U+0041，欧元符号的码位是U+20AC，高音谱号的码位是U+1D11E. 在Unicode 6.3标准中，约10% 的有效码位有对应的字符。 字符的具体表述取决于所用的编码。编码是在码位和字节序列之间转换时使用的算法。在UTF-8编码中,A(U+0041)的码位编码成单个字节\\x41，而在UTF-16LE编码中编码成两个字节\\x41\\x00。再举个例子，欧元符号(U+20AC)在UTF-8编码中是三个字节——\\xe2\\x82\\xac，而在UTF-16LE中编码成两个字节：\\xac\\x20. 把码位转换成字节序列的过程是编码,使用encode；把字节序列转换成码位的过程是解码,使用decode. 非英语用户常常会搞反所谓的编码解码,可以这样理解: 把Unicode字符串想成“人类可读”的文本.那么， 把字节序列变成人类可读的文本字符串就是解码 而把字符串变成用于存储或传输的字节序列就是编码 s = \"中文文本\" len(s) 4 b = s.encode(\"utf-8\")#编码 b b'\\xe4\\xb8\\xad\\xe6\\x96\\x87\\xe6\\x96\\x87\\xe6\\x9c\\xac' len(b) 12 b.decode(\"utf-8\") '中文文本' 混乱的编码问题 现今使用UTF-8编码是最通用的,但编码存在很多\"历史遗留问题\",比如中文编码混乱的问题(非英语都有这个问题) chardet是一个用于推断编码类型的工具,可以使用pip安装,使用它可以大致判断出文本使用的是什么编码,并给出该编码的可能性大小.具体用法可以看它的文档,下面是最简单的用法 import chardet chardet.detect(b) {'confidence': 0.938125, 'encoding': 'utf-8'} from requests import get rawdata = get('http://yahoo.co.jp/').content chardet.detect(rawdata) {'confidence': 0.99, 'encoding': 'utf-8'} 基本的编解码器 Python 自带了超过100 种编解码器(codec, encoder/decoder),用于在文本和字节之间相互转换.每个编解码器都有一个名称，如utf_8,而且经常有几个别名，如utf8、utf-8 和U8。这些名称可以传给open()、str.encode()、bytes.decode() 等函数的encoding参数。 如下是几种最常见的编码: latin1(即iso8859_1) 一种重要的编码， 是其他编码的基础， 例如cp1252 和Unicode(注意，latin1与cp1252的字节值是一样的，甚至连码位也相同) cp1252 微软制定的latin1超集，也是windows下各种编码问题的万恶之源,相对于latin1添加了有用的符号，例如弯引号和€(欧元);有些Windows 应用把它称为ANSI，但它并不是ANSI标准. cp437 IBM PC 最初的字符集,包含框图符号。与后来出现的latin1不兼容. gb2312 用于编码简体中文的陈旧标准,这是亚洲语言中使用较广泛的多字节编码之一.网络上中文乱码的万恶之源之一 utf-8 目前Web中最常见的8位编码;与ASCII兼容(纯ASCII文本是有效的UTF-8文本) utf-16le UTF-16的16位编码方案的一种形式;所有UTF-16支持通过转义序列（称为\"代理对\"，surrogate pair）表示超过U+FFFF的码位. UTF-16取代了1996年发布的Unicode 1.0编码(UCS-2).这个编码在很多系统中仍在使用,但是支持的最大码位是U+FFFF.从Unicode 6.3起，分配的码位中有超过50% 在U+10000以上,包括逐渐流行的表情符号(emoji pictograph). for codec in ['latin_1', 'utf_8', 'utf_16']: print(codec, 'El Niño'.encode(codec), sep='\\t') latin_1 b'El Ni\\xf1o' utf_8 b'El Ni\\xc3\\xb1o' utf_16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' 大字节序还是小字节序 ，你可能注意到了,UTF-16编码的序列开头有几个额外的字节\\xff\\xfe这是BOM，即字节序标记(byte-order mark),指明编码时使用Intel CPU的小字节序. 在小字节序设备中，各个码位的最低有效字节在前面：字母'E'的码位是U+0045（十进制数69），在字节偏移的第2位和第3位编码为69和0。 在大字节序CPU中,编码顺序是相反的；'E'编码为0和69。 为了避免混淆,UTF-16编码在要编码的文本前面加上特殊的不可见字符ZERO WIDTH NOBREAK SPACE(U+FEFF).在小字节序系统中，这个字符编码为b'\\xff\\xfe'（十进制数 255, 254）。因为按照设计,U+FFFE字符不存在，在小字节序编码中，字节序列b'\\xff\\xfe'必定是ZERO WIDTH NO-BREAK SPACE，所以编解码器知道该用哪个字节序。 UTF-16有两个变种： UTF-16LE，显式指明使用小字节序; UTF-16BE,显式指明使用大字节序。 如果使用这两个变种,不会生成BOM. 与字节序有关的问题只对一个字(word)占多个字节的编码(如UTF-16和UTF-32)有影响。UTF-8的一大优势是，不管设备使用哪种字节序,生成的字节序列始终一致,因此不需要BOM.尽管如此,某些Windows应用(尤其是Notepad)依然会在UTF-8编码的文 件中添加BOM；而且，Excel 会根据有没有BOM 确定文件是不是UTF-8编码，否则，它假设内容使用Windows代码页(codepage)编码.UTF-8编码的U+FEFF字符是一个三字节序列:b'\\xef\\xbb\\xbf'.因此,如果文件以这三个字节开头,有可能是带有BOM的UTF-8文件.然而,Python不会因为文件以b'\\xef\\xbb\\xbf' 开头就自动假定它是UTF-8编码的. ascii码支持 binascii是处理ascii编码的工具, binascii模块包含很多在二进制和ASCII编码的二进制表示转换的方法。通常情况不会直接使用这些功能，而是使用像UU，base64编码，或BinHex封装模块。 binascii模块包含更高级别的模块使用的，用C语言编写的低级高效功能. 接口如下: binascii.a2b_uu(string) 将一行uuencoded数据转换回二进制并返回二进制数据。线通常包含45（二进制）字节，除了最后一行。行数据后面可以是空格。 binascii.b2a_uu(data) 将二进制数据转换成一行ASCII字符，返回值是转换行，包括换行符。数据长度最多为45。 binascii.a2b_base64(string) 将一个base64数据块转换回二进制数据并返回二进制数据。一次可能会传递多条线。 binascii.b2a_base64(data, *, newline=True) 将二进制数据转换为base64编码中的ASCII字符行。返回值是转换行，如果换行符为true，则包含换行符。此功能的输出符合RFC 3548. binascii.a2b_qp(data, header=False) 将可打印数据块转换回二进制数据并返回二进制数据。一次可能会传递多条线。如果可选参数头存在且为真，下划线将被解码为空格。 binascii.b2a_qp(data, quotetabs=False, istext=True, header=False) 将二进制数据转换成可引用可打印编码的ASCII字符行。返回值是转换行。如果可选参数quotetabs存在且为真，则将对所有选项卡和空格进行编码。如果可选参数istext存在且为真，那么换行不会被编码，而尾随空白将被编码。如果可选参数头存在且为真，则空格将按照RFC1522编码为下划线。如果可选参数头存在且为false，则换行符也将被编码;否则换行转换可能会损坏二进制数据流。 binascii.a2b_hqx(string) 将binhex4格式的ASCII数据转换为二进制，无需进行RLE解压缩。字符串应包含完整数量的二进制字节，或（在binhex4数据的最后一部分的情况下）剩余的位为零。 binascii.rledecode_hqx(data) 根据binhex4标准对数据执行RLE解压缩。该算法在一个字节后使用0x90作为重复指示符，后跟计数。计数为0指定字节值0x90。例程返回解压缩的数据，除非数据输入数据在孤立的重复指示符中结束，在这种情况下会引发Incomplete异常。 binascii.rlecode_hqx(data) 对数据执行binhex4风格的RLE压缩并返回结果。 binascii.b2a_hqx(data) 执行hexbin4二进制到ASCII转换并返回生成的字符串。该参数应该已经是RLE编码，并且可以将长度除以3(除了可能的最后一个片段) binascii.crc_hqx(data, value) 计算数据的16位CRC值，以值作为初始CRC开始，并返回结果。这使用CRC-CCITT多项式x16 x12 x5 1，通常表示为0x1021.该CRC用于binhex4格式。 binascii.crc32(data[, value]) 计算CRC-32，数据的32位校验和，以值的初始CRC开始。默认的初始CRC为零。该算法与ZIP文件校验和一致。由于该算法被设计为用作校验和算法，因此不适合用作通用散列算法。使用如下： import binascii print(binascii.crc32(b\"hello world\")) # Or, in two pieces: crc = binascii.crc32(b\"hello\") crc = binascii.crc32(b\" world\", crc) print('crc32 = {:#010x}'.format(crc)) 222957957 crc32 = 0x0d4a1185 binascii.b2a_hex(data) binascii.hexlify(data) 返回二进制数据的十六进制表示。数据的每个字节被转换成相应的2位十六进制表示。因此，返回的字节对象是数据长度的两倍。 binascii.a2b_hex(hexstr) binascii.unhexlify(hexstr) 返回由十六进制字符串hexstr表示的二进制数据。这个函数是b2a_hex（）的倒数。 hexstr必须包含偶数个十六进制数字（可以是大写或小写），否则会出现错误异常。 python3支持Unicode python3从头到脚都支持Unicode,这也意味着像java一样,你可以将类名,函数名,变量名都设为中文(或者其他语言).不少人认为这样做不好,但考虑到代码的传播范围,其实使用更加便于交流的文字是更好的方法.比如,这个代码是一个日本企业内部使用的,而且他们并不打算让外国人用也不打算向前兼容python2,那么他们完全可以使用全日语来写文档,定义变量,函数,类. 为了正确比较而规范化Unicode字符串 因为Unicode有组合字符(变音符号和附加到前一个字符上的记号，打印时作为一个整体),所以拉丁语系文字比如法语,意大利语字符串比较起来很复杂,我们拿café这个词来作为例子.这个词可以使用两种方式构成，分别有4个和5个码位,但是结果完全一样. s1 = 'café' s2 = 'cafe\\u0301' s1, s2 ('café', 'café') len(s1), len(s2) (4, 5) s1 == s2 False U+0301是COMBINING ACUTE ACCENT，加在e后面得到é.在Unicode标准中，é 和e\\u0301 这样的序列叫\"标准等价物\"(canonical equivalent),应用程序应该把它们视作相同的字符.但是,Python看到的是不同的码位序列,因此判定二者不相等. 这个问题的解决方案是使用标准库的unicodedata.normalize函数提供的Unicode规范化.这个函数的第一个参数是这4个字符串中的一个：'NFC'、'NFD'、'NFKC' 和'NFKD' NFC（Normalization Form C）和NFD (Normalization Form D) 使用最少的码位构成等价的字符串，而NFD 把组合字符分解成基字符和单独的组合字符。这两种规范化方式都能让比较行为符合预期： from unicodedata import normalize s1 = 'café' s2 = 'cafe\\u0301' len(normalize('NFC', s1)), len(normalize('NFC', s2)) (4, 4) len(normalize('NFD', s1)), len(normalize('NFD', s2)) (5, 5) 西方键盘通常能输出组合字符,因此用户输入的文本默认是NFC 形式。不过,安全起见,保存文本之前,最好使用normalize('NFC', user_text) 清洗字符串.NFC也是W3C的Character Model for the World Wide Web: String Matching and Searching规范推荐的规范化形式。 NFKC和NFKD 在另外两个规范化形式（NFKC 和NFKD）的首字母缩略词中，字母K 表示“compatibility”(兼容性).这两种是较严格的规范化形式，对“兼容字符”有影响。虽然Unicode的目标是为各个字符提供“规范的”码位，但是为了兼容现有的标准，有些字符会出现多次。例如，虽然希腊字母表中有“μ”这个字母(码位是U+03BC，GREEK SMALL LETTER MU),但是Unicode还是加入了微符号μ（U+00B5），以便与latin1相互转换.因此，微符号是一个“兼容字符”. 在NFKC 和NFKD 形式中，各个兼容字符会被替换成一个或多个“兼容分解”字符，即便这样有些格式损失，但仍是“首选”表述——理想情况下，格式化是外部标记的职责，不应该由Unicode 处理。下面举个例子。二分之一½(U+00BD)经过兼容分解后得到的是三个字符序列'1/2'；微符号μ(U+00B5)经过兼容分解后得到的是小写字母μ(U+03BC) from unicodedata import normalize, name half = '½' normalize('NFKC', half) '1⁄2' four_squared = '4²' normalize('NFKC', four_squared) '42' micro = 'μ' micro_kc = normalize('NFKC', micro) micro, micro_kc ('μ', 'μ') ord(micro), ord(micro_kc) (956, 956) name(micro), name(micro_kc) ('GREEK SMALL LETTER MU', 'GREEK SMALL LETTER MU') 使用1/2 替代½可以接受，微符号也确实是小写的希腊字母μ，但是把4²转换成42就改变原意了.某些应用程序可以把4²保存为42，但是normalize函数对格式一无所知。因此，NFKC 或NFKD 可能会损失或曲解信息,但是可以为搜索和索引提供便利的中间表述：用户搜索1 ⁄ 2 inch时，如果还能找到包含½ inch 的文档，那么用户会感到满意. 使用NFKC 和NFKD 规范化形式时要小心，而且只能在特殊情况中使用，例如搜索和索引，而不能用于持久存储，因为这两种转换会导致数据损失。 大小写折叠 大小写折叠其实就是把所有文本变成小写，再做些其他转换。这个功能由str.casefold()实现. 对于只包含latin1字符的字符串s，s.casefold()得到的结果与s.lower()一样，唯有两个例外: 微符号μ 会变成小写的希腊字母μ（在多数字体中二者看起来一样）； 德语Eszett(“sharp s”，ß)会变成ss 自Python 3.4 起,str.casefold()和str.lower()得到不同结果的有116个码位。Unicode6.3命名了110122个字符，这只占0.11% 极端“规范化”：去掉变音符号 去掉变音符号不是正确的规范化方式，因为这往往会改变词的意思，而且可能误判搜索结果。但是对现实生活却有所帮助：人们有时很懒，或者不知道怎么正确使用变音符号，而且拼写规则会随时间变化，因此实际语言中的重音经常变来变去。 比如café,对于中国人来说é很难打出来,所以用户往往就打cafe了,我们需要一个去掉组合记号的函数用来实现这种极端的规范化 import unicodedata import string def shave_marks(txt): \"\"\"去掉全部变音符号\"\"\" norm_txt = unicodedata.normalize('NFD', txt) shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c)) return unicodedata.normalize('NFC', shaved) order = '“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”' shave_marks(order) '“Herr Voß: • ½ cup of OEtker™ caffe latte • bowl of acai.”' Greek = 'Zέφupoς, Zéfiro' shave_marks(Greek) 'Zεφupoς, Zefiro' 总结unicode规范化: NFC 和NFD 可以放心使用，而且能合理比较Unicode 字符串 对大多数应用来说，NFC 是最好的规范化形式 不区分大小写的比较应该使用str.casefold() 在必要的时候,我们可以删除一些变音符号来做规范化 文本排序 Python比较任何类型的序列时,会一一比较序列里的各个元素.对字符串来说,比较的是码位.可是在比较非ASCII字符时,得到的结果不尽如人意. l = [\"前\",\"后\",\"左\",\"右\"] sorted(l) ['前', '右', '后', '左'] 按照中文传统,我们应该希望按拼音首字母顺序排序即后前右左,但明显不是. 实际上在Python中,非ASCII 文本的标准排序方式是使用locale.strxfrm函数，根据locale模块的文档,这个函数会“把字符串转换成适合所在区域进行比较的形式”.使用locale.strxfrm函数之前，必须先为应用设定合适的区域设置，还要祈祷操作系统支持这项设置.在区域设为pt_BR的GNU/Linux(Ubuntu 14.04)中.而在windows中还没这个功能. 在Linux操作系统中，中国大陆的读者可以使用zh_CN.UTF-8，简体中文会按照汉语拼音顺序进行排序，它也能对葡萄牙语进行正确排序. unicode排序工具PyUCA James Tauber，一位高产的Django贡献者，他一定是感受到了这一痛点，因此开发了 PyUCA 库,这是Unicode排序算法包. PyUCA 没有考虑区域设置。如果想定制排序方式，可以把自定义的排序表路径传给Collator()构造方法。PyUCA 默认使用项目自带的allkeys.txt，这就是Unicode 6.3.0的\"Default Unicode Collation Element Table\"的副本 import pyuca coll = pyuca.Collator() fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] sorted_fruits = sorted(fruits, key=coll.sort_key) sorted_fruits ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] 以指定列宽格式化字符串 文本标注 python定义字符串使用成对的',\",\"\"\",'''构建而成,而文本可以标注为r,u,b,f等 s = \"这是一句话\\n\" s '这是一句话\\n' 原始文本标注r 用r标注的文本表示不会理会转义字符\\ s = r\"这是一句话\\n\" s '这是一句话\\\\n' unicode文本标注u 用u标注的文本表示字符串为unicode,python3中str就是Unicode,所以其实这个没什么意义,主要是为了给python3向前兼容的 btypes文本标注b 用b标注的文本标识文本为bytes,使用这个标注说明文本是字节序列 格式化文本标注f 用f标注的文本表示其中有用{}占位的内容由前面定义的变量填充,需要注意一旦标注为f则文本实际上已经不是文本了,而是一个函数,如果占位符没有找到对应的变量,则会报错,将f标注的文本放入函数中指定参数为其中的占位符也没有用 a = 1 b = 2 f\"asdf{a}{b}\" 'asdf12' 格式化字符串 python可以使用str.format()方法来格式化字符串这种方式更加直观 \"{}是{}\".format(\"一\",1) '一是1' \"{a}是{b}\".format(a=\"一\",b=1) '一是1' 文本模板 python提供了一个模块from string import Template,可以用于定义文本模板.它通常用来作为文件的内容模板. Template用起来和字符串的format方法类似,使用$标识要替换的占位字符,然后使用方法substitute来替换.以下是一个dockerfile的文本模板 from string import Template file = Template(\"\"\" FROM python:$v1:$v2 ADD requirements/requirements.txt /code/requirements.txt ADD $project_name.$suffix /code/$project_name.$suffix WORKDIR /code RUN pip install -r requirements.txt \"\"\") content = file.substitute(v1=3,v2=6,project_name=\"my project\",suffix=\"pyz\") print(content) FROM python:3:6 ADD requirements/requirements.txt /code/requirements.txt ADD my project.pyz /code/my project.pyz WORKDIR /code RUN pip install -r requirements.txt Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/字节序列与内存视图.html":{"url":"文本_文件与字节序/字节序列与内存视图.html","title":"字节序列与内存视图","keywords":"","body":"字节与字节序列 Python内置了两种基本的二进制序列类型： Python 3 引入的不可变bytes 类型 Python 2.6 添加的可变bytearray 类型 bytes 或bytearray 对象的各个元素是介于0~255(含)之间的整数.然而，二进制序列的切片始终是同一类型的二进制序列，包括长度为1 的切片 cafe = bytes('café', encoding='utf_8') cafe b'caf\\xc3\\xa9' cafe[0] # 单个元素为0~255之间的整数 99 cafe[:1] # 使用切片则返回同类型序列 b'c' bytearray是可变序列 不同于bytes,bytearray是可变序列.它是可以修改的,行为类似list. cafe_arr = bytearray(cafe) cafe_arr.append(2) cafe_arr bytearray(b'caf\\xc3\\xa9\\x02') 虽然二进制序列其实是整数序列，但是它们的字面量表示法表明其中有ASCII文本。因 此，各个字节的值可能会使用下列三种不同的方式显示。 可打印的ASCII 范围内的字节（从空格到~），使用ASCII 字符本身。 制表符、换行符、回车符和\\对应的字节，使用转义序列\\t、\\n、\\r 和\\\\。 其他字节的值，使用十六进制转义序列（例如，\\x00 是空字节）。 格式化二进制序列 除了格式化方法(format 和format_map) 和几个处理Unicode数据的方法(包括casefold、isdecimal、isidentifier、isnumeric、isprintable 和encode) 之外，str 类型的其他方法都支持bytes和bytearray 类型。这意味着，我们可以使用熟悉的字符串方法处理二进制序列，如endswith、replace、strip、translate、upper 等，只有少数几个其他方法的参数是bytes 对象，而不是str 对象。 此外，如果正则表达式编译自二进制序列而不是字符串，re 模块中的正则表达式函数也能处理二进制序列. Python不能使用foramte方法处理二进制序列,只能使用%运算符处理二进制序列. print(b\"sadfg%d\" % (12)) b'sadfg12' print(b\"sadfg{}\".format(12)) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 print(b\"sadfg{}\".format(12)) AttributeError: 'bytes' object has no attribute 'format' 二进制序列创建 二进制序列有个类方法是str没有的,名为fromhex,它的作用是解析十六进制数字对(数字对之间的空格是可选的),构建二进制序列: bytes.fromhex('31 4B CE A9') b'1K\\xce\\xa9' 通过str编码而来 \"流星雨\".encode(\"utf-8\") b'\\xe6\\xb5\\x81\\xe6\\x98\\x9f\\xe9\\x9b\\xa8' 构建bytes 或 bytearray 实例还可以调用各自的构造方法,传入下述参数。 一个 str 对象和一个 encoding 关键字参数。 bytes('sphinx',encoding=\"utf-8\") b'sphinx' 一个可迭代对象,提供 0~255 之间的数值。 bytes([12,34,32,212]) b'\\x0c\" \\xd4' 一个实现了缓冲协议的对象(如 bytes、bytearray、memoryview、array.array);此时,把源对象中的字节序列复制到新建的二进制序列中 import array numbers = array.array('h', [-2, -1, 0, 1, 2]) octets = bytes(numbers) octets b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00' python与内存 Cpython本质上是建筑在C语言上的,python也有工具直接如同C语言一样处理内存. 内存与位 所谓内存是一段连续的物理内存片段,一般内存都是按bytes分段使用的,一位(bit)就是一个二进制位(存储二进制数据),而一个byte就是8位二进制位.因此每一位看作一个10进制数的话,其范围为$0\\to(2^8-1)$ 也就是0~255这就与我们python的bytes对象对应起来了. 无论是什么对象什么类型,数据存在内存中的永远是0,1构成的编码,因此总可以使用bytes来处理.而类型本质上来说只是指示编码的工具. 位运算 python的数字但一般来说默认的表现形式是10进制的,也有2进制,8进制16进制的表现形式,但实际上是转化为str. num1 = 1 num2 = 0 bnum1 = bin(num1) bnum1 '0b1' hnum1 = hex(num1) hnum1 '0x1' onum1 = oct(num1) onum1 '0o1' bnum2 = bin(num2) bnum2 '0b0' hnum2 = hex(num2) hnum2 '0x0' onum2 = oct(num2) onum2 '0o0' python也有位运算.但只有int类型才可以使用 bin(num1&num2)#按位与 & '0b0' bin(num1&num1)#按位与 & '0b1' bin(num2&num2)#按位与 & '0b0' bin(num1|num2)#按位或 '0b1' bin(num1|num1)#按位或 '0b1' bin(num2|num2)#按位或 '0b0' bin(num1^num2)#按位异或 ^ '0b1' bin(num1^num1)#按位异或 ^ '0b0' bin(num2^num2)#按位异或 ^ '0b0' bin(~num2)#按位翻转~ '-0b1' ~num2 -1 bin(~num1)#按位翻转~ '-0b10' ~num1 -2 bin(num1 '0b10' bin(num1>>1)#左移运算符 >> '0b0' array对象 python有一个很特殊的序列类型array.array,它是同构可变序列,需要指定类型,事实上str,bytes,btyearray,memoryview都是同构序列,他们实际上是一段连续的内存,因此更加紧凑也更加高效. array.array,它是同构可变序列,需要指定类型.这些类型必须是与C语言中对应的.可以指定的类型有: Type code C Type Minimum size in bytes 'c' character 1 'b' signed integer 1 'B' unsigned integer 1 'u' Unicode character 2 'h' signed integer 2 'H' unsigned integer 2 'i' signed integer 2 'I' unsigned integer 2 'l' signed integer 4 'L' unsigned integer 4 'f' floating point 4 'd' floating point 8　　 from array import array from random import random floats = array('d', (random() for i in range(10**7))) floats[-1] 0.13967783903892583 with open('output/floats.bin', 'wb') as fp: floats.tofile(fp) floats2 = array('d') with open('output/floats.bin', 'rb') as fp: floats2.fromfile(fp,10**7)#把1000 万个浮点数从二进制文件里读取出来 floats2[-1] 0.13967783903892583 floats2 == floats True array.tofile和array.fromfile用起来很简单。把这段代码跑一跑，你还会发现它的速度也很快。一个小试验告诉我，用array.fromfile 从一个二 进制文件里读出1000万个双精度浮点数只需要0.1 秒，这比从文本文件里读取的速度要快60 倍，因为后者会使用内置的float 方法把每一行文字转换成浮点数。另外，使用array.tofile 写入到二进制文件，比以每行一个浮点数的方式把所有数字写入到文本文件要快7倍。另外，1000 万个这样的数在二进制文件里只占用80 000 000 个字节（每个浮点数占用8 个字节，不需要任何额外空间），如果是文本文件的话，我们需要181 515 739 个字节。 内存缓冲对象与二进制序列 使用缓冲类对象创建 bytes 或 bytearray 对象时,始终复制源对象中的字节序列。与之相反, memoryview 对象允许在二进制数据结构之间共享内存。如果想从二进制序列中提取结构化信息,struct模块是重要的工具。 memoryview memoryview 是一个内置类,它能让用户在不复制内容的情况下操作同一个数组的不同切片.memoryview的概念受到了NumPy的启发其实是泛化和去数学化的NumPy数组.它让你在不需要复制内容的前提下, 在数据结构之间共享内存。其中数据结构可以是任何形式,比如PIL图片、SQLite数据库和 NumPy的数组,等等。这个功能在处理大型数据集合的时候非常重要。 memoryview.cast 的概念跟数组模块类似,能用不同的方式读写同一块内存数据,而且内容 字节不会随意移动。这听上去又跟C 语言中类型转换的概念差不多.memoryview.cast 会把同一块内存里的内容打包成一个全新的 memoryview 对象给你。 我们利用 memoryview 精准地修改了一个数组的某个字节,这个数组的元素是 16 位二进制整数 numbers = array.array('h', [-2, -1, 0, 1, 2]) #有符号整数(2个字节) memv = memoryview(numbers) len(memv) 5 memv[0] -2 memv_oct = memv.cast('B') # 转化为无符号(单字节) memv_oct.tolist() [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] memv_oct[5] = 4 memv_oct.tolist() [254, 255, 255, 255, 0, 4, 1, 0, 2, 0] numbers array('h', [-2, -1, 1024, 1, 2]) struct struct就是结构体,C中的结构体就是一段连续的内存空间,顺序地存储指定类型的内容. struct解包需要知道字节顺序,打包的后的字节顺序默认上是由操作系统的决定的，当然struct模块也提供了自定义字节顺序的功能，可以指定大端存储、小端存储等特定的字节顺序，对于底层通信的字节顺序是十分重要的，不同的字节顺序和存储方式也会导致字节大小的不同。在format字符串前面加上特定的符号即可以表示不同的字节顺序存储方式，例如采用小端存储 s = struct.Struct(‘就可以了。 字节顺序字符串定义规则如下: Character Byte order Size Alignment @ native native native = native standard none little-endian standard none > big-endian standard none ! network (= big-endian) standard none python中也是类似功能.与array类似,也需要为每段指定数据类型: Format C Type Python type Standard size Notes x pad byte no value --- --- c char bytes of length 1 1 --- b signed char integer 1 --- B unsigned char integer 1 --- ? _Bool bool 1 --- h short integer 2 --- H unsigned short integer 2 --- i int integer 4 --- I unsigned int integer 4 --- l long integer 4 --- L unsigned long integer 4 --- q long long integer 8 --- Q unsigned long long integer 8 --- n ssize_t integer --- --- N size_t integer --- --- e --- float 2 半精度浮点数 f float float 4 --- d double float 8 --- s char[] bytes --- --- p char[] bytes --- --- P void * integer --- --- 利用buffer，使用pack_into和unpack_from方法 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境。而在上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回，也就是说我们每次pack都会在内存中分配出相应的内存资源，这有时是一种很大的性能浪费。struct模块还提供了pack_into() 和 unpack_from()的方法用来解决这样的问题，也就是对一个已经提前分配好的buffer进行字节的填充，而不会每次都产生一个新对象对字节进行存储。 import struct import binascii import ctypes values = (1, b'abc', 2.7) s = struct.Struct('I3sf')# 指定类型 prebuffer = ctypes.create_string_buffer(s.size)#ctypes模块创建一个缓冲 print('Before :',binascii.hexlify(prebuffer)) Before : b'000000000000000000000000' s.pack_into(prebuffer,0,*values) print('After pack:',binascii.hexlify(prebuffer)) After pack: b'0100000061626300cdcc2c40' unpacked = s.unpack_from(prebuffer,0) print('After unpack:',unpacked) After unpack: (1, b'abc', 2.700000047683716) 我们可以把多个对象pack到一个buffer里面，然后通过指定不同的offset进行unpack import struct import binascii import ctypes values1 = (1, b'abc', 2.7) values2 = (b'defg',101) s1 = struct.Struct('I3sf') s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size) print('Before :',binascii.hexlify(prebuffer)) s1.pack_into(prebuffer,0,*values1) s2.pack_into(prebuffer,s1.size,*values2) print('After pack:',binascii.hexlify(prebuffer)) print(s1.unpack_from(prebuffer,0)) print(s2.unpack_from(prebuffer,s1.size)) Before : b'0000000000000000000000000000000000000000' After pack: b'0100000061626300cdcc2c406465666765000000' (1, b'abc', 2.700000047683716) (b'defg', 101) memoryview 和 struct struct 模块提供了一些函数,把打包的字节序列转换成不同类型字段组成的元组,还有一些函数用于执行反向转换,把元组转换成打包的字节序列。struct 模块能处理bytes、bytearray和memoryview对象。 memoryview 类不是用于创建或存储字节序列的,而是共享内存,让你访问其他二进制序列、打包的数组和缓冲中的数据切片,而无需复制字节序列,例如PIL 就是这样处理图像的. 下例使用memoryview 和struct 提取一个 GIF 图像的宽度和高度 import struct # 结构体的格式: b'GIF89a,\\x01,\\x01' # 拆包 memoryview 对象,得到一个元组,包含类型、版本、宽度和高度 struct.unpack(fmt, header) (b'GIF', b'89a', 300, 300) #删除引用,释放 memoryview 实例所占的内存 del header del img mmap做文件映射 python提供一个mmap模块用于将文件映射至内存,即将一个文件或者其它对象映射到进程的地址空间,实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系.mmap对象可以作为进程间通过文件进行 IPC 的一种替换手段. 创建 mmap 对象 windows mmap(filedesc, length, tagname='') Unix mmap(filedesc, length, flag=MAP_SHARED, prot=PROT_READ|PROT_WRITE) 创建并返回一个 mmap 对象，参数 filedesc 通常是由 f.fileno()获得的. mmap 创建对象的含义是：将指定 fd 的前 length 字节映射到内存。 Windows中，可以通过参数tagname为一段内存映射指定名称，这样一个文件上面可以同时具有多个 mmap。windows中的内存映射都是可读可写的，同时在进程之间共享。 Unix平台上，参数 flags 的可选值包括： mmap.MAP_PRIVATE：这段内存映射只有本进程可用； mmap.MAP_SHARED：将内存映射和其他进程共享，所有映射了同一文件的进程，都能够看到其中一个所做的更改； 参数 prot 对应的取值包括：mmap.PROT_READ, mmap.PROT_WRITE 和 mmap.PROT_WRITE | mmap.PROT_READ。最后一者的含义是同时可读可写。 mmap 对象的方法: m.close() 　　关闭 m 对应的文件； m.find(str, start=0) 　　从 start 下标开始，在 m 中从左往右寻找子串 str 最早出现的下标； m.flush([offset, n]) 　　把 m 中从offset开始的n个字节刷到对应的文件中，参数 offset 要么同时指定，要么同时不指定； m.move(dstoff, srcoff, n) 　　等于 m[dstoff:dstoff+n] = m[srcoff:srcoff+n]，把从 srcoff 开始的 n 个字节复制到从 dstoff 开始的n个字节，可能会覆盖重叠的部分。 m.read(n) 　　返回一个字符串，从 m 对应的文件中最多读取 n 个字节，将会把 m 对应文件的位置指针向后移动； m.read_byte() 　　返回一个1字节长的字符串，从 m 对应的文件中读1个字节，要是已经到了EOF还调用 read_byte()，则抛出异常 ValueError； m.readline() 　　返回一个字符串，从 m 对应文件的当前位置到下一个'\\n'，当调用 readline() 时文件位于 EOF，则返回空字符串； m.resize(n) 　　把 m 的长度改为 n，m 的长度和 m 对应文件的长度是独立的； m.seek(pos, how=0) 　　同 file 对象的 seek 操作，改变 m 对应的文件的当前位置； m.size()　 　返回 m 对应文件的长度（不是 m 对象的长度len(m)）； m.tell() 　　返回 m 对应文件的当前位置； m.write(bytes) 　　把二进制字节序列写到 m 对应文件的当前位置，如果从 m 对应文件的当前位置到 m 结尾剩余的空间不足len(str)，则抛出ValueError； m.write_byte(byte) 　　把1个字节（对应一个字符）写到 m 对应文件的当前位置，实际上m.write_byte(ch) 等于 m.write(ch)。如果 m 对应文件的当前位置在 m 的结尾，也就是 m 对应文件的当前位置到 m 结尾剩余的空间不足1个字节，write()抛出异常ValueError，而write_byte() 什么都不做。 对于EOF的处理，write() 和 read_byte() 抛出异常ValueError，而 write_byte()和 read() 什么都不做。 使用mmap模块了，其大致特点如下： 普通文件被映射到虚拟地址空间后，程序可以向访问普通内存一样对文件进行访问，在有些情况下可以提高IO效率。 它占用物理内存空间少，可以解决内存空间不足的问题，适合处理超大文件。 不同于通常的字符串对象，它是可变的，可以通过切片的方式更改，也可以定位当前文件位置m.tell()或m.seek()定位到文件的指定位置，再进行m.write(str)固定长度的修改操作。 mmap常用于处理大数据 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/正则表达式.html":{"url":"文本_文件与字节序/正则表达式.html","title":"正则表达式","keywords":"","body":"正则表达式 正则表达式，又称规则表达式,它是用于匹配字符串,unicode,bytes的通用方法.使用特定的格式对特定的文本做模式匹配,以此来定位要处理的字符. 这种模式匹配的特定格式是各个语言通用的,可以看https://deerchao.net/tutorials/regex/regex.htm这个网站学习,本文不做多余阐述. python中使用re模块来使用正则表达式,它的接口有: re.compile(pattern) 产生正则匹配对象 prog = re.compile(r\"\\W+\") prog.match(\"Words, words, words.\") re.match(pattern, string) --------------------------------------------------------------------------- NameError Traceback (most recent call last) in () ----> 1 re.match(pattern, string) NameError: name 'pattern' is not defined re.search(pattern, string, flags=0) 扫描通过字符串查找正则表达式模式产生匹配的第一个位置，并返回相应的匹配对象。如果字符串中没有位置匹配模式则返回None;请注意，这不同于在字符串中的某一点找到零长度匹配。 re.match(pattern, string, flags=0) 如果字符串开头的零个或多个字符与正则表达式模式匹配，则返回相应的匹配对象。如果字符串与模式不匹配，返回None;请注意，这与零长度匹配不同。请注意，即使在MULTILINE模式下，re.match()只会在字符串的开头匹配，而不是在每一行的开头。如果要在字符串中的任意位置找到匹配项，请改用search() re.fullmatch(pattern, string, flags=0) 如果整个字符串与正则表达式模式匹配，则返回一个相应的匹配对象。如果字符串与模式不匹配，返回None;请注意，这与零长度匹配不同。 上面的接口都会返回一个匹配对象用于展示匹配的结果 re.split(pattern, string, maxsplit=0, flags=0) 按pattern的出现拆分字符串。如果在模式中使用捕获括号，则模式中所有组的文本也作为生成列表的一部分返回。如果maxsplit不为零，则最多会出现maxsplit拆分，并将该字符串的其余部分作为列表的最后一个元素返回。 import re re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] re.split(r'[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] re.split(r'x*', 'axbc') C:\\Users\\87\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match. return _compile(pattern, flags).split(string, maxsplit) ['a', 'bc'] re.split(\"^$\", \"foo\\n\\nbar\\n\", flags=re.M) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 re.split(\"^$\", \"foo\\n\\nbar\\n\", flags=re.M) C:\\Users\\87\\Anaconda3\\lib\\re.py in split(pattern, string, maxsplit, flags) 210 and the remainder of the string is returned as the final element 211 of the list.\"\"\" --> 212 return _compile(pattern, flags).split(string, maxsplit) 213 214 def findall(pattern, string, flags=0): ValueError: split() requires a non-empty pattern match. re.findall(pattern, string, flags=0) 返回字符串中模式的所有非重叠匹配，作为字符串列表。字符串从左到右扫描，并按照找到的顺序返回匹配项。如果模式中存在一个或多个组，则返回组的列表;如果模式有多个组，这将是一个元组的列表。结果中包含空模式匹配，除非他们触及另一个模式匹配的开始。 re.finditer(pattern, string, flags=0) 返回一个迭代器，在字符串中的RE模式的所有非重叠匹配上产生匹配对象。字符串从左到右扫描，并按照找到的顺序返回匹配项。结果中包含空匹配，除非他们触及另一个匹配的开始. re.sub(pattern, repl, string, count=0, flags=0) 返回通过替换repl替换字符串中最左侧不重叠的pattern的字符串获取的字符串.如果没有找到模式，则字符串不会更改. repl可以是一个字符串或一个函数;如果是字符串，则会处理其中的任何反斜杠转义。 这个接口将在3.7中弃用 re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', r'static PyObject*\\npy_\\1(void)\\n{', 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' def dashrepl(matchobj): if matchobj.group(0) == '-': return ' ' else: return '-' re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' re.subn(pattern, repl, string, count=0, flags=0) 执行与sub()相同的操作，但返回一个元组(new_string，number_of_subs_made). re.escape(pattern) 脱离除ASCII字母，数字和'_'以外的所有字符。如果要匹配任意的可能具有正则表达式元字符的字符串，这将非常有用。 print(re.escape('python.exe')) python\\.exe import string legal_chars = string.ascii_lowercase + string.digits + \"!#$%&'*+-.^_`|~:\" print('[%s]+' % re.escape(legal_chars)) [abcdefghijklmnopqrstuvwxyz0123456789\\!\\#\\$\\%\\&\\'\\*\\+\\-\\.\\^_\\`\\|\\~\\:]+ operators = ['+', '-', '*', '/', '**'] print('|'.join(map(re.escape, sorted(operators, reverse=True)))) \\/|\\-|\\+|\\*\\*|\\* re.purge() 清除正则表达式缓存。 正则表达式与unicode python的re模块可以匹配unicode, se = re.search(r\"收\",\"一定要收复台湾\") se.start() 3 \"一定要收复台湾\"[3] '收' Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/文件与IO流.html":{"url":"文本_文件与字节序/文件与IO流.html","title":"文件与IO流","keywords":"","body":"文件与IO流 计算机离不开文件与IO流,文件是多数操作系统的基本构成单位,而IO流则是将数据用于运算和输出结果的工具.无论是文件还是IO流,都是由bytes构成的,表现形式也只有两种: str 经过编码的bytes bytes 一般图片音频等使用bytes 标准输入输出 python提供了标准输入输出函数 input(prompt:str='')->str prompt是提示文本 input(\"输入吧\") 输入吧好了 '好了' print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) file: 默认为标准输出,但可以指定一个文件对象用于输出 sep: 字符串插入值之间，默认为空格。 end: 字符串附加在最后一个值之后，默认换行符。 flush: 是否强制冲洗替换流。 print(\"1234\") 1234 流对象 python的流对象都定义在io模块中,包括如下种类: TextIOWrapper,继承自TextIOBase,IOBase BufferedReader/BufferedWriter,继承自BufferedIOBase,IOBase StringIO继承自TextIOBase, IOBase BytesIO继承自BufferedIOBase,IOBase FileIO继承自RawIOBase, IOBase 文件对象 python从硬盘中读入的文件会被封装为文件对象(TextIOWrapper). 文件对象实质上是一个流对象. 从文件中提取文件对象的方式是使用 open(filepath, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) buffering 指定缓冲策略,0为关闭缓冲(必须带b),大于0的整数为缓冲区大小,-1表示不固定 encoding 指定编码方式 errors 解码报错时报什么错 newline 定义使用何种方式换行可以是None, '', '\\n', '\\r', and '\\r\\n' closefd,如果closefd为False，底层文件描述符将保持打开状态,文件关闭时。当给出文件名时，这不起作用在这种情况下必须为True。 opener,传递一个可打开的作为opener可以使用自定义的开启者。默认通过os.open作为opener mode, 指定文件的读写模式 模式 描述 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 w 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 w+ 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 mode中带有b的返回的对象是BufferedReader对象,不带的是TextIOWrapper而读写的不同也会带来方法的不同 open的使用方式最好结合上下文工具with语句使用 with open(\"src/hello.txt\",\"wb\") as f: print(type(f).mro()) [, , , ] 针对不同的打开模式,文件对象的的方法会有些不同,但有些基本方法是共用的,就是继承自IOBase的方法 IOBase的基本方法 close() 关闭文件对象 fileno() 返回流的底层文件描述符（一个整数）（如果存在）。如果IO对象不使用文件描述符，则会引发OSError。 flush() 冲洗流的写入缓冲区（如果适用）。这对于只读和非阻塞流不起作用。 isatty() 如果流是交互式的（即，连接到终端/ tty设备），返回True. seek(offset[, whence]) 将流位置更改为给定的字节偏移。偏移量相对于由whence指示的位置进行解释。 offset的默认值为SEEK_SET。值的值为： SEEK_SET or 0 – 流的开始（默认）;偏移量应为零或正数 SEEK_CUR or 1 – 当前流位置;偏移可能为负 SEEK_END or 2 – 流的结尾,偏移量通常为负数 返回新的绝对位置。 seekable() 如果流支持随机访问，则返回True. tell() 返回当前流的位置。 truncate(size=None) 将流调整为给定大小（以字节为单位）（如果未指定大小，则调整当前位置）。当前流位置不变。这种调整大小可以扩展或减少当前的文件大小。在扩展的情况下，新文件区域的内容取决于平台（在大多数系统上，其他字节为零填充）。将返回新的文件大小。 与读写相关的方法有: readable() 如果流可以读取，返回True。如果为False，则read()将引发OSError。 readline(size=-1) 从流中读取并返回一行。如果指定了大小，则读取最多大小的字节。对于二进制文件，行终止符始终为b'\\ n';对于文本文件，open（）的newline参数可用于选择识别的行终止符。 readlines(hint=-1) 读取并返回流中的行列表。可以指定提示来控制读取的行数：如果所有行的总大小（以字节/字符为单位）超过提示，则不会读取更多行。请注意，已经有可能使用文件中的行迭代文件对象：...而不调用file.readlines(). writable() 如果流支持写入，则返回True。如果为False，write（）和truncate（）将引发OSError。 writelines(lines) 将行写入流 TextIOBase的基本方法 detach() 将底层二进制缓冲区与TextIOBase分开并返回。底层缓冲区分离后，TextIOBase处于不可用状态。一些TextIOBase实现（如StringIO）可能不具有底层缓冲区的概念，并调用此方法将引发UnsupportedOperation。 read(size) 读入 +　write(s) 写字符串到对象 BufferedIOBase的基本方法 detach() 将底层原始流与缓冲区分开并返回。原始流已分离后，缓冲区处于不可用状态。一些缓冲区，如BytesIO，没有从该方法返回的单个原始流的概念。它们引发UnsupportedOperation。 read(size=-1) 读取并返回到大小字节。如果省略参数，则None或者否定数据被读取并返回，直到达到EOF。如果流已经处于EOF，则返回空字节对象。如果参数为正，并且底层原始流不具有交互性，则可能会发出多个原始读取以满足字节计数（除非首先达到EOF）。但是对于交互式原始流，最多只会发出一次原始读取，结果并不意味着EOF即将到来。如果底层原始流处于非阻塞模式，并且目前没有可用的数据，则会引发BlockingIOError。 read1(size=-1) 读取并返回到大小字节，最多只能调用底层原始流的read()(或readinto())方法。如果您在BufferedIOBase对象之上实现自己的缓冲区，这将非常有用。 readinto(b) 将字节读入预先分配的可写入字节的对象b并返回读取的字节数。像read()一样，可能会向底层的原始流发出多次读取，除非后者是交互式的。如果底层原始流处于非阻塞模式，并且目前没有可用的数据，则会引发BlockingIOError。 readinto1(b) 将字节读入预先分配的可写入字节的对象b，最多使用一个对底层原始流的read（）（或readinto（））方法的调用。返回读取的字节数。如果底层原始流处于非阻塞模式，并且目前没有可用的数据，则会引发BlockingIOError。 write(b) 编写给定的类似字节的对象b，并返回写入的字节数（总是等于b的长度，以字节为单位），因为如果写入失败OSError将被引发）。根据实际的实现，这些字节可以容易地写入底层流，或者由于性能和延迟原因而被保存在缓冲器中。当处于非阻塞模式时，如果数据需要写入原始流，但无法接受所有数据而不阻塞，则会引发BlockingIOError。该方法返回后，调用者可能会释放或变异b，因此在方法调用期间，实现只能访问b. 另一种读写文件的方式 FileIO类是读写文件的另一种方式,与open不同之处在于它继承自RawIOBase,也就是说它是没有缓冲区也没有解码过的的单纯文件io from io import FileIO with FileIO(\"src/hello.txt\", mode='r', closefd=True, opener=None) as f: print(f.read()) b'asd' RawIOBase的基本方法 read(size=-1) 读出bytes readall() 从流中读取并返回所有字节，直到EOF，如果需要，可以使用多个流调用。 readinto(b) 将字节读入预分配的可写入字节的对象b，并返回读取的字节数。如果对象处于非阻塞模式，并且没有字节可用，则返回None. write(b) 写入bytes 内存中生成文件对象 io模块可以用于生成文件对象其中有StringIO和BytesIO两种,头一种文件对象保存字符串,后一种则保存字节流 使用io模块生成的文件对象更多的是作为流使用,因此有一些特别的方法 getvalue() 返回一个包含缓冲区的全部内容的str或者bytes read1() BytesIO对象可以使用,读取并返回到大小字节，最多只能调用底层原始流的read()(或readinto())方法。如果您在BufferedIOBase对象之上实现自己的缓冲区，这将非常有用。 readinto1() BytesIO对象可以使用, 将字节读入预先分配的可写入字节的对象b，最多使用一个对底层原始流的read（）（或readinto（））方法的调用。返回读取的字节数。如果底层原始流处于非阻塞模式，并且目前没有可用的数据，则会引发BlockingIOError。 getbuffer() BytesIO对象可以使用,在缓冲区的内容上返回可读写的视图(memoryview)，而不复制它们。另外，视图的突变将会透明地更新缓冲区的内容 from io import StringIO ,BytesIO steam = BytesIO(b\"asdfg\") steam.read() b'asdfg' steam.write(b\"1234\") 4 steam.getvalue() b'asdfg1234' view = steam.getbuffer() view[2:4] = b\"56\" steam.getvalue() b'as56g1234' Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/序列化.html":{"url":"文本_文件与字节序/序列化.html","title":"序列化","keywords":"","body":"序列化 序列化是最常见的字节应用.所谓序列化就是将特定对象转化为一串字节序列,用以存储或者传输.它的反向操作被称为反序列化. python有丰富的序列化工具如标准库中的base64,json,pickle,又如一些开源的第三方序列化工具如dill,msgpack等. 这些工具虽然都是序列化工具,但设计目的并不相同,本文将会对他们中有代表性的进行介绍 base64用于序列化文件 Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一,常用于传输小文件,网址等.下面是使用base64序列化网址的例子(注意base64编码的参数只能是bytes) import base64 url = b\"http://blog.hszofficial.site\" url_b64 = base64.b64encode(url)#编码base64 url_b64 b'aHR0cDovL2Jsb2cuaHN6b2ZmaWNpYWwuc2l0ZQ==' base64.b64decode(url_b64)#解码base64 b'http://blog.hszofficial.site' 很多时候base64被作为加密算法做简单的加密,当然这有点自欺欺人的意思,所谓的加密也只是让人无法直接读出而已 Base64更常见的使用场景之一就是在http协议中传输小图片.它的效果是将整个图片的信息都序列化到一串字节序中 with open(\"source/mysite.gif\",\"rb\") as f: pic = f.read() pic_64 = base64.b64encode(pic) pic_64[:5] b'R0lGO' isinstance(pic_64,bytes) True len(pic_64) 31092 pic_64.decode()[:5] 'R0lGO' 同学们可以扫描下面的二维码来访问我的主站 from IPython.display import HTML HTML(''.format(value=pic_64.decode())) 显然这种方式传输大文件很不靠谱,但小图片还是可以的 pickle用于持续化python的内置简单对象 有的时候我们想序列化的不光是数据和数据结构,还有对象,这种时候就需要将对象以一定的协议序列化为二进制数据. python的pickle模块是标准库中最常用的序列化模块,它实现了基本的数据序列和反序列化。通过pickle模块的序列化操作我们能够将程序中运行的对象信息保存到文件中去，永久存储；通过pickle模块的反序列化操作，我们能够从文件中创建上一次程序保存的对象。 需要注意,pickel的文件并不是默认跨版本支持的,可以对照这张表设定需要的参数 pickel到目前为止有5种序列化格式: 版本 说明 支持python版本 0 人类可读的文本,用于最早期 全部版本 1 老的二进制版本文本同样用于早期 全部版本 2 出现于2.3版本,用以支持新类 2.3+ 3 出现于3.0版本,用以支持bytes类型 3.0+ 4 出现于Python 3.4.用于扩充pickel的支持类型和大对象 3.4+ python3.5+默认使用的是版本4的pickle格式 要指定使用某一种pickle格式,可以在方法中使用protocol:int=n来指定 pickle的局限性 pickle的兼容性问题一直让人诟病,除了python没有别的语言使用pickle,而如上表所示,pickle在各个版本的python中也不是默认通用的 pickle实际上并不能传递函数或者类,而是只能记录下它的状态信息而已,因此不能跨模块传递,除此之外,一些对象类型也是不可 pickle 的。例如，Python 不能 pickle 文件对象（或者任何带有对文件对象引用的对象），因为 Python 在 unpickle 时不能保证它可以重建该文件的状态。 pickle的接口 pickle的接口与json类似带s为序列化或反序列化为字符串,不带的则是处理文件对象 import pickle exa_l=[1,2,3,4,5] exa_b = pickle.dumps(exa_l) exa_b b'\\x80\\x03]q\\x00(K\\x01K\\x02K\\x03K\\x04K\\x05e.' pickle.loads(exa_b) [1, 2, 3, 4, 5] with open(\"source/pickle_test.txt\",\"wb\") as f: pickle.dump(exa_l,f) with open(\"source/pickle_test.txt\",\"rb\") as f: view_exam = pickle.load(f) view_exam [1, 2, 3, 4, 5] 命令行工具 pickletools 在python3中提供了一个命令行工具来管理pickle文件 !python -m pickle source/pickle_test.txt [1, 2, 3, 4, 5] !python -m pickletools source/pickle_test.txt 0: \\x80 PROTO 3 2: ] EMPTY_LIST 3: q BINPUT 0 5: ( MARK 6: K BININT1 1 8: K BININT1 2 10: K BININT1 3 12: K BININT1 4 14: K BININT1 5 16: e APPENDS (MARK at 5) 17: . STOP highest protocol among opcodes = 2 可用的参数: -a, –annotate 用简短的操作码描述来标注每一行。 -o, –output= 写入输出的文件的名称。 -l, –indentlevel= 用于缩进新的MARK级别的空白数。 -m, –memo 拆卸多个物体时，请在拆卸之间保留备注。 -p, –preamble= 当指定多于一个pickle文件时，在每次分解之前打印给定的前导码 *dill用于序列化python对象 dill支持几乎所有的python数据,按github上的说法,它支持: none, type, bool, int, long, float, complex, str, unicode, tuple, list, dict, file, buffer, builtin, both old and new style classes, instances of old and new style classes, set, frozenset, array, functions, exceptions functions with yields, nested functions, lambdas cell, method, unboundmethod, module, code, methodwrapper, dictproxy, methoddescriptor, getsetdescriptor, memberdescriptor, wrapperdescriptor, xrange, slice, notimplemented, ellipsis, quit 还不支持的有: frame(帧), generator(生成器对象,因为包含帧状态), traceback(依然是因为无法保存帧状态) 与pickle不同,dill的序列化可以跨模块传递,事实上dill也是为了分布式计算传递python对象而设计的. dill对python3.5+支持不错,它支持协程,也支持numpy数组,只是序列化的过程中typehint会被消除. dill可以直接使用pip安装,使用也相当简单,只要替代pickle就行了,他们接口相同 import dill from asyncio import sleep import asyncio async def asyng(n:int): print(\"n:\"+str(n)+\" wait\") await sleep(1) print(\"n:\"+str(n)+\"done\") with open(\"source/dill_cor.txt\",\"wb\") as f: dill.dump(asyng,f) with open(\"source/dill_cor.txt\",\"rb\") as f: s1 = dill.load(f) loop = asyncio.new_event_loop() loop.run_until_complete(asyncio.wait([s1(1),s1(2),s1(3)])) n:3 wait n:1 wait n:2 wait n:3done n:1done n:2done ({:3> result=None>, :3> result=None>, :3> result=None>}, set()) json用于消息传输 json是当今网络数据传递的标准格式之一,相比较于xml,它更轻量,因此更加便于传输,而且其本身就可以被javascript识别为js对象,更加便于前端处理. python的标准变量类型与js十分相像因此有天然的Json支持,也就是他的json模块了. python标准库中有json模块专门用于序列化和反序列化json 与其他序列化不太一样的地方在于,python中json序列化出来并不是bytes而是字符串.其实json作为一种标准格式其实应该和html,xml这些放在一起类比才对,但这里作为序列化工具主要是因为它可以直接对应python中的list和dict import json d = dict(name='Bob', age=20, score=88) json_str = json.dumps(d) json_str '{\"name\": \"Bob\", \"age\": 20, \"score\": 88}' json.loads(json_str) {'age': 20, 'name': 'Bob', 'score': 88} json模块可以直接处理json格式的文件,使用的接口与处理json格式字符串类似,只是方法名后面没有s with open('source/new.json', 'w') as f: cont = json.dump(d,f) with open('source/new.json', 'r') as f: cont = json.load(f) print(cont) {'name': 'Bob', 'age': 20, 'score': 88} ujson 虽然Python自带这个json序列化工具,但因为它的代码是纯净的python代码,因此比较慢,如果想有更快的序列化和反序列化速度的话,可以使用ujson,这个快很多因为是C写的底层. 他们接口完全相同 import ujson %timeit json.loads(json_str) The slowest run took 16.64 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 3: 2.81 µs per loop %timeit ujson.loads(json_str) The slowest run took 106.01 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 638 ns per loop %timeit json.dumps(d) 100000 loops, best of 3: 3.26 µs per loop %timeit ujson.dumps(d) The slowest run took 95.41 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 598 ns per loop 可以看到ujson无论是序列化还是反序列化都比自带的json模块快上一个数量级 *msgpack用于更好的传递消息 msgpack是现在最快最小的通用序列化协议,官方的说法是It's like JSON.but fast and small.有测试确实效率非常高. 但其实msgpack和json适用范围并不完全重叠,json作为通用传输协议活跃于web应用,它传递的是字符串,而mspack传递的更多的是bytes,用途也更加底层,常用于分布式服务的消息传递,rpc等 import msgpack 序列化为bytes msgpack可以序列化list和dict pack = msgpack.packb([1, 2, 3]) pack b'\\x93\\x01\\x02\\x03' msgpack.unpackb(pack) [1, 2, 3] msgpack.unpackb(pack,use_list=False)# 指定use_list为False则会返回tuple (1, 2, 3) pack = msgpack.packb(dict(a=1,b=2,c=3)) pack b'\\x83\\xa1a\\x01\\xa1b\\x02\\xa1c\\x03' msgpack.unpackb(pack) {b'a': 1, b'b': 2, b'c': 3} 反序列化为字符串 pack = msgpack.packb([\"你\", \"我\", \"他\"]) pack b'\\x93\\xa3\\xe4\\xbd\\xa0\\xa3\\xe6\\x88\\x91\\xa3\\xe4\\xbb\\x96' msgpack.unpackb(pack) [b'\\xe4\\xbd\\xa0', b'\\xe6\\x88\\x91', b'\\xe4\\xbb\\x96'] msgpack.unpackb(pack,encoding='utf-8') ['你', '我', '他'] 序列化流 unpacker可以反序列化流,它可以从一个流（或从通过其feed方法提供的字节）中分离多个对象。 import msgpack from io import BytesIO buf = BytesIO() for i in range(10): buf.write(msgpack.packb(list(range(i)))) buf.seek(0) unpacker = msgpack.Unpacker(buf) for unpacked in unpacker: print(unpacked) [] [0] [0, 1] [0, 1, 2] [0, 1, 2, 3] [0, 1, 2, 3, 4] [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6, 7] [0, 1, 2, 3, 4, 5, 6, 7, 8] 自定义对象序列化 也可以序列化自定义数据类型.以下是datetime.datetime的示例. 我们可以用default来指定自定义序列化和反序列化的方法. 需要注意的是序列化后的对象字段和值都会被变成bytes,因此需要适当的decode import datetime import msgpack useful_dict = { \"id\": 1, \"created\": datetime.datetime.now(), } def decode_datetime(obj): if b'__datetime__' in obj: obj = datetime.datetime.strptime(obj[b\"as_str\"].decode(), \"%Y%m%dT%H:%M:%S.%f\") return obj def encode_datetime(obj): if isinstance(obj, datetime.datetime): return {b'__datetime__': True, b'as_str': obj.strftime(\"%Y%m%dT%H:%M:%S.%f\")} return obj packed_dict = msgpack.packb(useful_dict, default=encode_datetime) packed_dict b'\\x82\\xa2id\\x01\\xa7created\\x82\\xac__datetime__\\xc3\\xa6as_str\\xb820170601T14:18:18.572902' this_dict_again = msgpack.unpackb(packed_dict, object_hook=decode_datetime) this_dict_again {b'created': datetime.datetime(2017, 6, 1, 14, 18, 18, 572902), b'id': 1} 如上面的自定义方法,序列化是将容器中的对象找出来,一个一个执行自定义的序列化方法,因此需要用isinstance方法来判别出类型来再做特殊处理. 而反序列化则是需要通过指定的字段找出序列化的内容,再执行反序列化 结合dill传递对象 import dill class Vector2D: def __repr__(self): return \"Vector2D\".format(self=self) def __dill__(self): return dill.dumps(self) def __init__(self,a:int,b:int): self.a = a self.b = b def __add__(self,c): a = self.a+c.a b = self.b+c.b return Vector2D(a,b) def encode_v2d(obj): if isinstance(obj, Vector2D): return {b'__Vector2D__': True, b'as_bytes': obj.__dill__()} return obj def decode_v2d(obj): if b'__Vector2D__' in obj: obj = dill.loads(obj[b\"as_bytes\"]) return obj useful_dict = { \"id\": 1, \"created\": Vector2D(1,2), } packed_dict = msgpack.packb(useful_dict, default=encode_v2d) packed_dict b'\\x82\\xa2id\\x01\\xa7created\\x82\\xac__Vector2D__\\xc3\\xa8as_bytes\\xda\\x03\\x87\\x80\\x03cdill.dill\\n_create_type\\nq\\x00(cdill.dill\\n_load_type\\nq\\x01X\\x04\\x00\\x00\\x00typeq\\x02\\x85q\\x03Rq\\x04X\\x08\\x00\\x00\\x00Vector2Dq\\x05h\\x01X\\x06\\x00\\x00\\x00objectq\\x06\\x85q\\x07Rq\\x08\\x85q\\t}q\\n(X\\n\\x00\\x00\\x00__module__q\\x0bX\\x08\\x00\\x00\\x00__main__q\\x0cX\\x08\\x00\\x00\\x00__repr__q\\rcdill.dill\\n_create_function\\nq\\x0e(h\\x01X\\x08\\x00\\x00\\x00CodeTypeq\\x0f\\x85q\\x10Rq\\x11(K\\x01K\\x00K\\x01K\\x03KCC\\x0cd\\x01j\\x00|\\x00d\\x02\\x8d\\x01S\\x00q\\x12NX\\x1b\\x00\\x00\\x00Vector2Dq\\x13X\\x04\\x00\\x00\\x00selfq\\x14\\x85q\\x15\\x87q\\x16X\\x06\\x00\\x00\\x00formatq\\x17\\x85q\\x18h\\x14\\x85q\\x19X \\x00\\x00\\x00q\\x1ah\\rK\\x03C\\x02\\x00\\x01q\\x1b))tq\\x1cRq\\x1dc__builtin__\\n__main__\\nh\\rNN}q\\x1etq\\x1fRq X\\x08\\x00\\x00\\x00__dill__q!h\\x0e(h\\x11(K\\x01K\\x00K\\x01K\\x02KCC\\nt\\x00j\\x01|\\x00\\x83\\x01S\\x00q\"N\\x85q#X\\x04\\x00\\x00\\x00dillq$X\\x05\\x00\\x00\\x00dumpsq%\\x86q&h\\x14\\x85q\\'h\\x1ah!K\\x05C\\x02\\x00\\x01q())tq)Rq*c__builtin__\\n__main__\\nh!NN}q+tq,Rq-X\\x08\\x00\\x00\\x00__init__q.h\\x0e(h\\x11(K\\x03K\\x00K\\x03K\\x02KCC\\x10|\\x01|\\x00_\\x00|\\x02|\\x00_\\x01d\\x00S\\x00q/N\\x85q0X\\x01\\x00\\x00\\x00aq1X\\x01\\x00\\x00\\x00bq2\\x86q3h\\x14h1h2\\x87q4h\\x1ah.K\\x07C\\x04\\x00\\x01\\x06\\x01q5))tq6Rq7c__builtin__\\n__main__\\nh.NN}q8tq9Rq:X\\x07\\x00\\x00\\x00__add__q;h\\x0e(h\\x11(K\\x02K\\x00K\\x04K\\x03KCC\"|\\x00j\\x00|\\x01j\\x00\\x17\\x00}\\x02|\\x00j\\x01|\\x01j\\x01\\x17\\x00}\\x03t\\x02|\\x02|\\x03\\x83\\x02S\\x00q(h\\x14X\\x01\\x00\\x00\\x00cq?h1h2tq@h\\x1ah;K\\nC\\x06\\x00\\x01\\x0c\\x01\\x0c\\x01qA))tqBRqCc__builtin__\\n__main__\\nh;NN}qDtqERqFX\\x07\\x00\\x00\\x00__doc__qGNX\\r\\x00\\x00\\x00__slotnames__qH]qIutqJRqK)\\x81qL}qM(h1K\\x01h2K\\x02ub.' this_dict_again = msgpack.unpackb(packed_dict, object_hook=decode_v2d) this_dict_again {b'created': Vector2D, b'id': 1} v1 = this_dict_again[b\"created\"] v2 = Vector2D(2,2) v1+v2 Vector2D Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"文本_文件与字节序/配置文件解析.html":{"url":"文本_文件与字节序/配置文件解析.html","title":"配置文件解析","keywords":"","body":"配置文件解析 项目通常会将一些全部局配置放在配置文件中.常见的配置文件格式有.ini,和.yml,有时候我们也会使用.json来作为配置文件. python中,json前面已经讲过,而标准库的ConfigParser模块可以解析配置.conf,文件..yml则需要使用第三方包pyyaml .ini文件解析 .ini文件形如下面 [DEFAULT] serveraliveinterval = 45 compression = yes compressionlevel = 9 forwardx11 = yes [bitbucket.org] user = hg [topsecret.server.com] port = 50022 forwardx11 = no 可以分为几个部分: Sections 节,每个节代表一项配置系列 Case insensitivity 参数字段,具体要配置的字段对应的值 可以理解成一个两层的字典 写 ConfigParser()用于初始化一个解析器,这个解析器可以像字典一样使用 import configparser config = configparser.ConfigParser() config['DEFAULT'] = {'ServerAliveInterval': '45', 'Compression': 'yes', 'CompressionLevel': '9'} config['bitbucket.org'] = {} config['bitbucket.org']['User'] = 'hg' config['topsecret.server.com'] = {} topsecret = config['topsecret.server.com'] topsecret['Port'] = '50022' # mutates the parser topsecret['ForwardX11'] = 'no' # same here config['DEFAULT']['ForwardX11'] = 'yes' with open('example.ini', 'w') as configfile: config.write(configfile) 读 初始化一个空的解析器后可以通过.read方法来读入一个已有的配置. config = configparser.ConfigParser() config.sections() [] config.read('example.ini') ['example.ini'] 可以通过sections方法获取所有节 config.sections() ['bitbucket.org', 'topsecret.server.com'] 'bitbucket.org' in config True 'bytebong.com' in config False 获取到节后,就可以像操作字典一样操作这个节内的内容了 for k,v in config['bitbucket.org'].items(): print(k,v) user hg serveraliveinterval 45 compression yes compressionlevel 9 forwardx11 yes config['bitbucket.org']['User'] 'hg' config['DEFAULT']['Compression'] 'yes' topsecret = config['topsecret.server.com'] topsecret['ForwardX11'] 'no' topsecret['Port'] '50022' for key in config['bitbucket.org']: print(key) user serveraliveinterval compression compressionlevel forwardx11 .yml文件解析 .yml文件需要使用第三方包pyyaml来解析,据说效率很高. .yml文件形如: name: Silenthand Olleander race: Human traits: [ONE_HAND, ONE_EYE] 是很多现代项目的标准配置格式.比如gitpage默认的静态页面生成框架jekyll就是使用这种格式配置项目 写 pyyml可以像json一样直接将字典写成配置文件,甚至可以将pyhton对象写成配置文件 import yaml so = {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE'] } so {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE']} print(yaml.dump(so)) name: Silenthand Olleander race: Human traits: [ONE_HAND, ONE_EYE] with open(\"exsample.yml\",'w') as f: f.write(yaml.dump(so)) class Hero: def __init__(self, name, hp, sp): self.name = name self.hp = hp self.sp = sp def __repr__(self): return \"%s(name=%r, hp=%r, sp=%r)\" % (self.__class__.__name__, self.name, self.hp, self.sp) h= Hero(\"Galain Ysseleg\", hp=-3, sp=2) print(yaml.dump(h)) !!python/object:__main__.Hero {hp: -3, name: Galain Ysseleg, sp: 2} 读 with open(\"exsample.yml\") as f: result = yaml.load(f) result {'name': 'Silenthand Olleander', 'race': 'Human', 'traits': ['ONE_HAND', 'ONE_EYE']} Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-13 21:43:40 "},"文本_文件与字节序/结语.html":{"url":"文本_文件与字节序/结语.html","title":"结语","keywords":"","body":"结语 编码 关于编码实际上除了文本文件,几乎所有数据都要有格式有编码.MP3,jpg都是编码方式, 也就是按照统一蓝本描绘内容的数据.正因为有了编码我们才能区别数据的类型.数据才能被人类所使用. python 在内存中如何表示字符串 Python 官方文档对字符串的码位在内存中如何存储避而不谈.毕竟,这是实现细节.理论上,怎么存储都没关系：不 管内部表述如何,输出时每个字符串都要编码成字节序列. 在内存中,Python3使用固定数量的字节存储字符串的各个码位,以便高效访问各个字符或切片. 在Python 3.3 之前,编译CPython 时可以配置在内存中使用16 位或32 位存储各个码位. 16 位是\"窄构建\"（narrow build） 32 位是\"宽构建\"（wide build）. 如果想知道用的是哪个,要查看sys.maxunicode 的值--65535 表示\"窄构建\",不能透明地处理U+FFFF以上的码位. \"宽构建\"没有这个限制,但是消耗的内存更多：每个字符占4个字节,就算是中文象形文字的码位大多数也只占2 个字节. 这两种构建没有高下之分,应该根据自己的需求选择. 从Python 3.3 起,创建str对象时,解释器会检查里面的字符,然后为该字符串选择最经济的内存布局： 如果字符都在latin1 字符集中,那就使用1 个字节存储每个码位 否则,根据字符串中的具体字符,选择2 个或4 个字节存储每个码位. 这是简述,完整细节参阅\"PEP 393—Flexible String Representation\". 灵活的字符串表述类似于Python 3 对int 类型的处理方式：如果一个整数在一个机器 字中放得下,那就存储在一个机器字中；否则解释器切换成变长表述,类似于Python 2 中的long 类型.这种聪明的做法得到推广,真是让人欢喜! 流 流是一种抽象概念,它代表了数据的无结构化传递.按照流的方式进行输入输出,数据被当成无结构的字节序或字符序列. 从流中取得数据的操作称为提取操作,而向流中添加数据的操作称为插入操作.用来进行输入输出操作的流就称为IO流. 换句话说,IO流就是以流的方式进行输入输出. 现如今很多工具都是基于流的,比如我们在网络上看的视频听的歌,都是使用流技术实现的.而基于流的计算工具也非常中要,比如strom,比如spark Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-07 20:50:27 "},"流程控制/":{"url":"流程控制/","title":"流程控制","keywords":"","body":"流程控制 现今的神经科学表明人类的思维是跳跃的,分布式的,并行的,而计算机只能按步一步一步的顺序执行. 如何让计算机理解我们人类设计的计算流程就是本部分探讨的课题.python提供了许多工具可以描述我们想要的计算工具. 但他们各自有各自的特性,有各自的适用场景. 单线程同步流程控制 阻塞异步与协程 多线程与GIL 多进程 并行编程的惯用法 并发模型 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 22:42:52 "},"流程控制/单线程同步流程控制.html":{"url":"流程控制/单线程同步流程控制.html","title":"单线程同步流程控制","keywords":"","body":"单线程同步流程控制 python与多数其他语言一样默认是单线程同步的顺序执行语句.这也是所有语言的基础. python中语句会一行一行地被解释执行,而流控制语句则是用于控制当前解释执行哪条语句的工具 流程分支 python只有if语句没有switch,这也带来了语义上的歧义: if/else代表判断逻辑,一般用于根据一条语句的结果正误来确定下一步的执行内容 if/elif/else代表分支,一般用于根据一个变量的取值不同来确定下一步执行的内容. 虽然这种方式看似减少了关键字数量,但实际上增加了错误语义的使用可能.个人认为是python设计的一大败笔. 使用字典结合匿名函数更加优雅的实现简单流程分支 if/elif来实现switch并取优雅,需要为一个变量写多次判断语句,因此如果分支逻辑简单,完全可以使用字典+lambda函数 def which_type(x): return { int:lambda x:print(x,\"is int\"), float:lambda x:print(x,\"is float\"), list:lambda x:print(x,\"is list\") }.get(type(x),lambda x:print(\"i dont know\"))(x) which_type(2) 2 is int 循环语句 循环语句主要目的就是让一段代码反复顺序执行,python有两种循环语句: for循环 主要用于根据先验循环次数执行循环内代码的情况.他会遍历一个迭代器,先验的次数就是这个迭代器的长度,每取出一个对象都会执行for块中的语句 while循环 主要用于没有先验循环次数,而是根据判断条件执行循环内代码的情况 for i in range(10): print(i) 0 1 2 3 4 5 6 7 8 9 i = 0 while i 0 1 2 3 4 5 6 7 8 9 打断语句break和continue 循环中可以使用break跳出循环或者使用continue跳出当次循环 i = 0 while True: i += 1 if i > 10 : break if i % 2 == 0 : continue print(i) 1 3 5 7 9 try/except 不仅用于处理错误，还常用于控制流程 在Python 中，try/except 不仅用于处理错误，还常用于控制流程。为此，Python 官方词汇表还定义了一个缩略词(口号): EAFP 取得原谅比获得许可容易(easier to ask for forgiveness than permission).这是一种常见的Python 编程风格，先假定存在有效的键或属性，如果假定不成立，那么捕获异常.这种风格简单明快，特点是代码中有很多try 和except 语句.与其他很多语言一样(如C 语言)，这种风格的对立面是LBYL 风格. LBYL 三思而后行(look before you leap).这种编程风格在调用函数或查找属性或键之前显式测试前提条件.与EAFP 风格相反，这种风格的特点是代码中有很多if 语句.在多线程环境中，LBYL 风格可能会在“检查”和“行事”的空当引入条件竞争.例如，对if key in mapping: return mapping[key] 这段代码来说，如 果在测试之后，但在查找之前，另一个线程从映射中删除了那个键，那么这段代码就会失败。这个问题可以使用锁或者EAFP风格解决. 如果选择使用EAFP风格，那就要更深入地了解else子句，并在try/except语句中合理使用 特殊的else语句 else子句不仅能在if语句中使用，还能在for、while 和try语句中使用.for/else、while/else 和try/else的语义关系紧密，不过与if/else差别很大. 此处的else语句理解为then可能更加合适,它代表的是\"没有遇到特殊情况就执行以下代码\"这样的语义.具体到不同的语句,语义如下: for 仅当for循环运行完毕时)即for循环没有被break语句终止)才运行else块 while 仅当while循环因为条件为假值而退出时(即while循环没有被break语句中止)才运行else块 循环语句中使用else语句可以省去大量的状态变量,最典型的就是为避免网络异常而多次访问某个地址的场景 import requests conn = requests.get(\"http://www.baidu.com\") def get_html(url): for i in range(3): try: conn = requests.get(url) except: print(f\"第{i+1}次连不上服务器\") else: return conn.text else: raise ConnectionError(\"连不上服务器\") get_html(\"http://www.baidu.com\") '\\r\\n ç\\x99¾åº¦ä¸\\x80ä¸\\x8bï¼\\x8cä½\\xa0å°±ç\\x9f¥é\\x81\\x93 æ\\x96°é\\x97» hao123 å\\x9c°å\\x9b¾ è§\\x86é¢\\x91 è´´å\\x90§ ç\\x99»å½\\x95 document.write(\\'ç\\x99»å½\\x95\\'); æ\\x9b´å¤\\x9aäº§å\\x93\\x81 å\\x85³äº\\x8eç\\x99¾åº¦ About Baidu &copy;2017&nbsp;Baidu&nbsp;ä½¿ç\\x94¨ç\\x99¾åº¦å\\x89\\x8då¿\\x85è¯»&nbsp; æ\\x84\\x8fè§\\x81å\\x8f\\x8dé¦\\x88&nbsp;äº¬ICPè¯\\x81030173å\\x8f·&nbsp; \\r\\n' get_html(\"http://www.bidss.ecom\") 第1次连不上服务器 第2次连不上服务器 第3次连不上服务器 --------------------------------------------------------------------------- ConnectionError Traceback (most recent call last) in () ----> 1 get_html(\"http://www.bidss.ecom\") in get_html(url) 8 return conn.text 9 else: ---> 10 raise ConnectionError(\"连不上服务器\") 11 ConnectionError: 连不上服务器 try 仅当try块中没有异常抛出时才运行else块。官方文档还指出--else子句抛出的异常不会由前面的except子句处理. 在所有情况下，如果异常或者return,break或continue语句导致控制权跳到了复合语句的主块之外,else子句也会被跳过 EAFP风格的python代码 上面说道EAFP风格,需要注意的是这种风格下try/else语句应当被大量有针对性地使用,它应当细粒度的防守单条语句而不是像多数人那样防守一段代码.这会让代码看起来很啰嗦,但相对来说更加安全 上下文管理器和with块 上下文管理器对象存在的目的是管理with语句，就像迭代器的存在是为了管理for语句一样. with语句的目的是简化try/finally模式。这种模式用于保证一段代码运行完毕后执行某项操作，即便那段代码由于异常、return语句或sys.exit()调用而中止，也会执行指定的操作。finally 子句中的代码通常用于释放重要的资源，或者还原临时变更的状态。 上下文管理器协议包含__enter__ 和__exit__ 两个方法。with 语句开始运行时，会在上下文管理器对象上调用__enter__ 方法。with 语句运行结束后，会在上下文管理器对象上调用__exit__ 方法，以此扮演finally子句的角色。 最常见的例子是确保关闭文件对象.这在前文已经有所描述.注意,与函数和模块不同，with块没有定义新的作用域. __enter__() 方法 __enter__() 方法要求最好返回一个对象(如果不返回一个对象,as语句会捕获一个None),一般是self,但不一定.除了返回上下文管理器之外，还可能返回其他对象. __exit__(exc_type, exc_value, traceback)方法 exc_type 异常类（例如ZeroDivisionError）。 exc_value 异常实例。有时会有参数传给异常构造方法，例如错误消息，这些参数可以使用exc_value.args 获取。 traceback traceback 对象 不管控制流程以哪种方式退出with 块，都会在上下文管理器对象上调用__exit__方法，而不是在__enter__方法返回的对象上调用。with语句的as子句是可选的。对open函数来说，必须加上as子句，以便获取文件的引用.不过，有些上下文管理器会返回None，因为没什么有用的对象能提供给用户. 下面看一个上下文管理器修改上下文环境中print函数行为的例子: import sys class LookingGlass: def __enter__(self): self.original_write = sys.stdout.write sys.stdout.write = self.reverse_write return 'JABBERWOCKY' def reverse_write(self, text): self.original_write(text[::-1]) def __exit__(self, exc_type, exc_value, traceback): sys.stdout.write = self.original_write if exc_type is ZeroDivisionError: print('Please DO NOT divide by zero!') return True with LookingGlass() as what: print('Alice, Kitty and Snowdrop') print(what) pordwonS dna yttiK ,ecilA YKCOWREBBAJ what 'JABBERWOCKY' print('Back to normal.') Back to normal. 抛开了with语句,上下文管理器也可以这样使用 manager = LookingGlass() monster = manager.__enter__() print(monster == 'JABBERWOCKY') print(monster) manager.__exit__(None, None, None) print(monster) eurT YKCOWREBBAJ JABBERWOCKY 使用try/finally可以这样写 manager = LookingGlass() try: monster = manager.__enter__() print(monster == 'JABBERWOCKY') print(monster) except: pass finally: manager.__exit__(None, None, None) print(monster) eurT YKCOWREBBAJ JABBERWOCKY contextlib模块 contextlib模块中提供了一些类和其他函数，用于快速的构建上下文管理器 closing 如果对象提供了close() 方法，但没有实现__enter__/__exit__ 协议，那么可以使用这个函数构建上下文管理器。 suppress 构建临时忽略指定异常的上下文管理器 @contextmanager 这个装饰器把简单的生成器函数变成上下文管理器，这样就不用创建类去实现管理器协 议了。 ContextDecorator 这是个基类，用于定义基于类的上下文管理器。这种上下文管理器也能用于装饰函数， 在受管理的上下文中运行整个函数。 ExitStack 这个上下文管理器能进入多个上下文管理器。with 块结束时，ExitStack 按照后进先出的顺序调用栈中各个上下文管理器的__exit__ 方法。如果事先不知道with 块要进入多少个上下文管理器，可以使用这个类。例如，同时打开任意一个文件列表中的所有文件. 使用@contextmanager @contextmanager装饰器能减少创建上下文管理器的样板代码量，因为不用编写一个完整的类，定义__enter__ 和__exit__ 方法，而只需实现有一个yield 语句的生成器，生成想让__enter__ 方法返回的值。 在使用@contextmanager 装饰的生成器中，yield语句的作用是把函数的定义体分成三部分： yield 语句前面的所有代码在with 块开始时(即解释器调用__enter__ 方法时)执行 yield 语句,用于抛出 __enter__要返回的对象,并可以接收异常 yield 语句后面的代码在with块结束时(即调用__exit__方法时)执行 import contextlib @contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write yield 'JABBERWOCKY' sys.stdout.write = original_write with looking_glass() as what: print(what) print(\"12345\") print(what) print(\"12345\") YKCOWREBBAJ 54321 JABBERWOCKY 12345 其实,contextlib.contextmanager 装饰器会把函数包装成实现__enter__ 和__exit__ 方法的类. 这个类的__enter__方法有如下作用 调用生成器函数，保存生成器对象（这里把它称为gen）。 调用next(gen)，执行到yield关键字所在的位置。 返回next(gen)产出的值，以便把产出的值绑定到with/as 语句中的目标变量上。 with 块终止时，__exit__ 方法会做以下几件事 检查有没有把异常传给exc_type；如果有，调用gen.throw(exception)，在生成器函数定义体中包含yield关键字的那一行抛出异常。 否则，调用next(gen)，继续执行生成器函数定义体中yield 语句之后的代码 如果在with块中抛出了异常，Python 解释器会将其捕获，然后在looking_glass 函数的yield 表达式里再次抛出。但是，那里没有处理错误的代码， 因此looking_glass 函数会中止，永远无法恢复成原来的sys.stdout.write 方法，导致系统处于无效状态。因此上面的例子并不完整,下面给出完整的例子 @contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write try: yield 'JABBERWOCKY' except Exception as e: msg = 'a error!' finally: sys.stdout.write = original_write if msg: print(msg) with looking_glass() as what: print(what) print(\"12345\") raise AssertionError(\"123\") print(what) print(\"12345\") YKCOWREBBAJ 54321 a error! JABBERWOCKY 12345 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 21:36:28 "},"流程控制/阻塞异步与协程.html":{"url":"流程控制/阻塞异步与协程.html","title":"阻塞异步与协程","keywords":"","body":"从顺序执行到并行执行 前几天去外地参加朋友婚礼,作为一个外地人我是不认路的,但我被安排了去接其他客人,于是我不得不依赖导航.我需要打开导航,听着它的指挥开车. 这就是一个典型的并行执行的过程,我要同时开车,并且同时监听着手机上的导航的指挥. 人们往往是同时做几件,比如边看电视边吃饭,边听音乐边工作,边打电话边开车(千万不要这么做).并且很多时候我们不得不同时做几件事,而一件事是另一件事的依赖. 人可以并行的执行任务(事实上人脑就是并行处理事件的)但电脑'不行',单核电脑比较耿直只会按固定好的顺序执行任务.前文也已经介绍过了如何组织单线程过程. 但好在电脑的运转速度远比人的反应速度快,因此我们可以耍点小花招让多个任务看起来是一起执行的. 拿之前看导航开车的例子来说,实际上我开车这个事件可以看作一个循环,每个循环中我有两个动作 我的耳朵在监听着手机(使用声音的音色语调等特征识别),当它有指示的时候我会按照指示执行 没有指示就根据路况开一段 当然了这个事件看起来作为并发的例子更加合适,但道理是一样的. 阻塞与非阻塞 阻塞和非阻塞关注的是程序在等待调用结果(消息,返回值)时的状态. 阻塞调用是指调用结果返回之前，当前线程会被挂起.调用线程只有在得到结果之后才会返回. 非阻塞调用指在不能立刻得到结果之前,该调用不会阻塞当前线程. 如果开车的时候我监听导航是阻塞的,那就意味着我的关注点转移到了导航上,必须要有它的指导我才会有动作,这么开车早就出事故了. 推广到我们的程序,也就是说我们的流程需要可以被保存状态,将线程的控制权转移到其他流程中.同时也要可以下次再被转移回来接着上次的继续运行. 同步与异步 同步与异步同步和异步关注的是消息通信机制(synchronous communication/ asynchronous communication). 所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。 而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。 开车的时候导航就是异步的,当打开导航后就会有个反馈--地图上我们的位置会被标记出来.而实际的导航信息都是由导航自己语音通知我们的. 有了上面的概念,我们就可以来看看python中官方的单线程并行解决方案了 协程 协程是一种单线程通过调度器或者事件循环从而实现的并行的解决方案.它是由用户控制的\"并行\",因此只要代码一样(没有使用random)协程的运行顺序就是一样的.实际上完全可以等价的用回调函数实现. 协程是实现高并发的方案中开销最小的方案.在io密集型任务中往往是最高效的方案.python3.5以后协程语法已经基本定型. python的协程模型可以分为如下几个部分: coroutine 协程对象:协程对象,指一个使用async关键字定义的函数,它的调用不会立即执行函数,而是会返回一个协程对象.协程对象需要注册到事件循环,由事件循环调用. 调度器/事件循环(event_loop):用于调度协程运行的顺序,调度器用于调度协程而事件循环则是一种特殊的调度器--程序开启一个无限的循环,程序员会把一些函数注册到事件循环上.当满足事件发生的时候,调用相应的协程函数. 协程及其语法 协程语法可以说是函数的一个超集,它的特征是使用async def来定义,并且可以在其内部使用await关键字等待另一个协程完成.协程对象的抽象基类为collections.abc.Coroutine，实现send(value)，throw(type, exc, tb)，close()和__await__()接口。 可以看出协程与生成器接口相似,就是多了个__await__()少了迭代器相关的__next__()和__iter__()事实上,在3.7版本之前,协程都是使用生成器来实现的. 协程对象内部需要实现Awaitable协议,也就是要实现__await__接口,这个接口必须返回一个迭代器,带有这一接口的对象我们称之为Future-like对象,有它的就可以被程序用await关键字挂起等待,Future-like类的抽象基类为collections.abc.Awaitable await语法 await就是用来挂起等待任务结束的关键字它只能在协程中使用. 有效用法： 表达式 被解析为 if await fut: pass if (await fut): pass if await fut + 1: pass if (await fut) + 1: pass pair = await fut, 'spam' pair = (await fut), 'spam' with await fut, open(): pass with (await fut), open(): pass await foo()['spam'].baz()() await ( foo()['spam'].baz()() ) return await coro() return ( await coro() ) res = await coro() ** 2 res = (await coro()) ** 2 func(a1=await coro(), a2=0) func(a1=(await coro()), a2=0) await foo() + await bar() (await foo()) + (await bar()) -await foo() -(await foo()) 无效用法： 表达式 应该写为 await await coro() await (await coro()) await -coro() await (-coro()) 一般来说await会挂起直到它下面的一串Future-like对象都运行结束才会继续向下. async 语法 除了用async def创建协程,async还有其他几个用法 异步迭代器和async for 异步迭代器可以在它的iter实现里挂起、调用异步代码，也可以在它的__next__方法里挂起、调用异步代码。要支持异步迭代，需要： 对象必须实现一个__aiter__接口,返回一个异步迭代器对象，这个异步迭代器对象在每次迭代时会返回一个Future-like对象 一个异步迭代器必须实现一个__anext__方法,在每次迭代时返回一个Future-like对象 要停止迭代，__anext__必须抛出一个StopAsyncIteration异常。 python的buildin方法中有aiter()和anext()可以直接调用异步迭代器的对应接口实现. 例子: import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i async def main(): async for i in Ticker(1,5): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 异步列表解析(3.6) 列表解析中可以使用await来等待Future-like对象的结果,如: result = [await fun() for fun in funcs if await condition()] 在列表中允许使用async for来做迭代,它的形式如下: [i async for i in Ticker(1,5) if i % 2] import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i async def main(): result = [i async for i in Ticker(1,5) if i % 2] print(result) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) [1, 3] 异步上下文管理器和async with 异步上下文管理器类似普通的上下文管理器，可以让程序在进入上下文和离开上下文之间挂起状态,调用异步代码. 异步上下文管理器需要实现两个接口 __aenter__处理进入上下文时的操作,如果有返回值,则可以使用as标定上下文中的变量名 __aexit__处理离开上下文时的操作,和__exit__的参数一样,它的参数必须是self,exc_type, exc, tb,分别代表对象自身对象,exception_type , exception_value , 和 traceback,如果正常退出,exc_type, exc, tb将会是 None. __aenter__和__aexit__，它们必须返回一个Future-like对象 和普通的with语句一样，可以在单个async with语句里指定多个上下文管理器。 异步上下文管理器的一个示例： import asyncio class Ticker: \"\"\"Yield numbers from 0 to `to` every `delay` seconds.\"\"\" def __init__(self, delay, to): self.delay = delay self.i = 0 self.to = to def __aiter__(self): return self async def __anext__(self): i = self.i if i >= self.to: raise StopAsyncIteration self.i += 1 if i: await asyncio.sleep(self.delay) return i class AsyncContextTicker: def __init__(self,delay, to): self.data = Ticker(delay, to) async def __aenter__(self): print('entering context') await asyncio.sleep(1) return self.data async def __aexit__(self, exc_type, exc, tb): await asyncio.sleep(1) print('exit context') async def main(): async with AsyncContextTicker(1,5) as ticker: async for i in ticker: print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) entering context 0 1 2 3 4 exit context 异步生成器(3.6) 带yield关键字的函数是生成器,带yield关键字的协程就是异步生成器,从效果上看异步生成器效果和异步迭代器效果差不多,它需要实现协议: PyAsyncGenASend : __anext__和asend()接口 ,对应一般生成器中的__next__和send(),用于在异步生成器间交互信息 PyAsyncGenAThrow : athrow() and aclose()接口,对应一般生成器的throw()和close(),用于关闭异步生成器或者抛出错误 StopAsyncIteration用于标注结束 import asyncio async def ticker(delay, to): \"\"\"Yield numbers from 0 to *to* every *delay* seconds.\"\"\" for i in range(0,to): yield i await asyncio.sleep(delay) async def main(): async for i in ticker(1,5): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 关于yield from 因为异步步生成器本质上是异步迭代器的子类,我们可以利用这一点使用async for语句代替yield from的语义. import asyncio async def g1(x): for i in range(x): yield i async def g2(): async for v in g1(5): yield v async def main(): async for i in g2(): print(i) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) 0 1 2 3 4 协程的状态 协程可以有4种状态,可以是用python的反射模块inspect.getcoroutinestate(coroutine)来查看 CORO_CREATED: 等待被使用 CORO_RUNNING: 目前执行中 CORO_SUSPENDED: 目前在await处暂停等待信号中 CORO_CLOSED: 执行结束 实用例子 协程有三种不同的代码编写风格: 拉取式 典型的异步生成器和异步迭代器使用场景 推送式 通过将数据推送给协程让协程一步一步的计算返回数据 任务式 根据状态来排定运行顺序 推送式 我们用一个计算移动平均值的异步生成器来看看协程是如何工作的. async def averager(): total = 0.0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count async def grouper(): aver = averager() await aver.__anext__() for i in range(11): j = await aver.asend(i) print(j) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(grouper()) 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 任务式 一个简单的离散事件仿真类--出租车队运营仿真 import random from collections import namedtuple import queue import argparse import time Event = namedtuple('Event',[ 'time', 'proc', 'action'])#定义事件 DEFAULT_NUMBER_OF_TAXIS = 3#出租车数量 DEFAULT_END_TIME = 180#运行时间默认180 SEARCH_DURATION = 5 #找乘客时间默认为5 TRIP_DURATION = 20 #载客时间默认为20 DEPARTURE_INTERVAL = 5#出库间隔默认5 async def taxi_process(ident, trips, start_time=0): \"\"\"每次改变状态时创建事件，把控制权让给仿真器\"\"\" # 定义一个异步生成器,用于描述process time = yield Event(start_time, ident, 'leave garage') for i in range(trips): time = yield Event(time, ident, 'pick up passenger') time = yield Event(time, ident, 'drop off passenger') yield Event(time, ident, 'going home') def compute_duration(previous_action): \"\"\"Compute action duration using exponential distribution\"\"\" if previous_action in ['leave garage', 'drop off passenger']: # new state is prowling interval = SEARCH_DURATION elif previous_action == 'pick up passenger': # new state is trip interval = TRIP_DURATION elif previous_action == 'going home': interval = 1 else: raise ValueError('Unknown previous_action: %s' % previous_action) return int(random.expovariate(1/interval)) + 1 class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() self.procs = dict(procs_map) async def run(self, end_time): \"\"\"排定并显示事件，直到时间结束\"\"\" for _, proc in sorted(self.procs.items()): first_event = await proc.__anext__() self.events.put(first_event) sim_time = 0 while sim_time taxis = {i: taxi_process(i, (i + 1) * 2, i * DEPARTURE_INTERVAL) for i in range(DEFAULT_NUMBER_OF_TAXIS)} sim = Simulator(taxis) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(sim.run(DEFAULT_END_TIME)) taxi: 0 Event(time=0, proc=0, action='leave garage') taxi: 1 Event(time=5, proc=1, action='leave garage') taxi: 1 Event(time=8, proc=1, action='pick up passenger') taxi: 2 Event(time=10, proc=2, action='leave garage') taxi: 2 Event(time=11, proc=2, action='pick up passenger') taxi: 0 Event(time=18, proc=0, action='pick up passenger') taxi: 2 Event(time=25, proc=2, action='drop off passenger') taxi: 2 Event(time=28, proc=2, action='pick up passenger') taxi: 2 Event(time=34, proc=2, action='drop off passenger') taxi: 1 Event(time=39, proc=1, action='drop off passenger') taxi: 1 Event(time=40, proc=1, action='pick up passenger') taxi: 1 Event(time=45, proc=1, action='drop off passenger') taxi: 1 Event(time=47, proc=1, action='pick up passenger') taxi: 2 Event(time=47, proc=2, action='pick up passenger') taxi: 2 Event(time=78, proc=2, action='drop off passenger') taxi: 2 Event(time=92, proc=2, action='pick up passenger') taxi: 0 Event(time=93, proc=0, action='drop off passenger') taxi: 0 Event(time=95, proc=0, action='pick up passenger') taxi: 2 Event(time=96, proc=2, action='drop off passenger') taxi: 2 Event(time=103, proc=2, action='pick up passenger') taxi: 2 Event(time=116, proc=2, action='drop off passenger') taxi: 0 Event(time=119, proc=0, action='drop off passenger') taxi: 0 Event(time=121, proc=0, action='going home') taxi: 2 Event(time=122, proc=2, action='pick up passenger') taxi: 1 Event(time=124, proc=1, action='drop off passenger') taxi: 1 Event(time=127, proc=1, action='pick up passenger') taxi: 2 Event(time=141, proc=2, action='drop off passenger') taxi: 2 Event(time=143, proc=2, action='going home') taxi: 1 Event(time=159, proc=1, action='drop off passenger') taxi: 1 Event(time=164, proc=1, action='going home') *** end of events *** 事件循环 事件循环是一个无限的的循环,用来监控触发事件.一般我们用loop = asyncio.new_event_loop()来创建一个事件循环的实例,然后将其使用asyncio.set_event_loop(loop)来将循环实例定义为当前的事件循环.如果程序并不需要考虑使用多个循环的话我们也可以直接使用asyncio.get_event_loop()来获取当前事件循环的实例 事实上python原生的事件循环并不高效,uvloop是一个高效的事件循环,它使用cython编写,并使用libuv,就是node.js用的那个高性能事件驱动的程序库.我们在生产环境可以使用它来运行协程.(windows下无法使用) python的协程运转需要显式的指定循环.asyncio则提供了如'中央处理设备'一般的功能，它支持如下操作： 产生,设置和管理事件循环 异步时间管理 将回调函数注册到事件循环 管理协程的执行,包括取消,延迟,调用等 将耗时函数调用委托给一个线程池 协程错误处理 创建可用于多种类型的通信的服务端和客户端的Transports 启动进程以及相关的和外部通信程序的Transports 后两个操作在网络部分再讨论,本篇只讨论前面的功能 产生,设置和管理事件循环 上面已经介绍了如何产生事件循环,以下是关于设置管理事件循环的接口,这些接口的实例为loop: run_forever() 运行直到stop()被调用.如果在调用run_forever()之前调用stop()，则以超时为0轮询I/O选择器一次,运行所有响应I/O事件(以及已经安排的回调)的回调，然后退出。 如果在运行run_forever()时调用stop(),则会运行当前批次的回调,然后退出.请注意,在这种情况下,回调计划的回调将不会运行;他们会在下一次run_forever()被调用时运行. run_until_complete(future) 跑到期物完成.如果参数是一个coroutine对象，那么它被wrap_future()包装起来成为一个期物.返回期物的结果，或者抛出异常. is_running() 返回时间循环的状态 stop() 停止事件循环 is_closed() 如果事件循环被关闭，则返回True。 close() 关闭事件循环.循环不能再次运行,待处理的回调将丢失.这将清除队列并关闭执行程序且不等待执行程序完成.这一过程不可逆转,要再次使用必须重新创建一个时间循环并设置为当前事件循环 *3.6 coroutine shutdown_asyncgens() 安排所有当前打开的异步生成器对象，以aclose()调用。调用此方法后，事件循环将在每次迭代新的异步生成器时发出警告。应该用于可靠地完成所有调度的异步生成器. 异步时间管理 asyncio.sleep(nbr) 这是一个异步的延迟工具,必须在协程中使用await调用 loop.time() 根据事件循环的内部时钟，将当前时间作为浮点值返回,返回的是时间戳 from datetime import datetime import time from asyncio import sleep async def now(): print(datetime.now()) await sleep(1) print(datetime.now()) await sleep(1) print(asyncio.get_event_loop().time()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(now()) print(loop.time()) loop.close() 2017-06-13 21:54:35.382406 2017-06-13 21:54:36.383539 2576.235886889 2576.236275465 将回调函数注册到事件循环 它的工作机制类似于先进先出队列，所以如果一些回调需要一段时间来处理任务，其它的回调就会相应的延迟，直到先前的回调结束 回调函数处理的接口同样是loop,他们有: call_soon(callback, *args) 基本的回调注册,行为如前面介绍类似先进先出队列 call_later(delay, callback, *args) 在一定延迟后执行回调 call_at(when, callback, *args) 使用int或者float代表时间戳,在该时间执行回调函数 import asyncio def hello_world(loop): print('Hello World') loop.stop() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Schedule a call to hello_world() loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) loop.call_soon(hello_world, loop) # Blocking call interrupted by loop.stop() loop.run_forever() loop.close() Hello World Hello World Hello World Hello World call_soon_threadsafe(callback, *args) call_soon(callback, *args)的线程安全版本 很多时候，我们的事件循环用于注册协程，而有的协程需要动态的添加到事件循环中。一个简单的方式就是使用多线程。当前线程创建一个事件循环，然后在新建一个线程，在新线程中启动事件循环。当前线程不会被block。 from threading import Thread import time now = lambda: time.time() def start_loop(loop): asyncio.set_event_loop(loop) loop.run_forever() def more_work(x): print('More work {}'.format(x)) time.sleep(x) print('Finished more work {}'.format(x)) start = now() new_loop = asyncio.new_event_loop() t = Thread(target=start_loop, args=(new_loop,)) t.start() print('TIME: {}'.format(time.time() - start)) new_loop.call_soon_threadsafe(more_work, 6) new_loop.call_soon_threadsafe(more_work, 3) TIME: 0.0018198490142822266 More work 6 :8> 启动上述代码之后，当前线程不会被block，新线程中会按照顺序执行call_soon_threadsafe方法注册的more_work方法，后者因为time.sleep操作是同步阻塞的，因此运行完毕more_work需要大致6 + 3 期物 asyncio模块的将协程注册到时间需要先将其包装为期物,也就是Future或者Task. Task类用来管理协同程序运行的状态,是Future的子类,Future的接口如下: cancel() 取消期物对象并安排回调.如果期物对象已经完成或取消,返回False.否则,将期物对象的状态更改为取消,调度回调并返回True. cancelled() 如果期物对象被取消，返回True。 done() 如果期物对象完成，返回True。完成意味着结果/异常可用，或者期物对象被取消。 result() 返回期物对象代表的结果.如果期物对象取消，则会引发CancelledError.如果期物对象的结果尚不可用,则会引发InvalidStateError.如果期物对象已经完成并且设置了异常,则会引发异常. exception() 返回在期物对象设置的异常.异常(如果没有设置异常,则为None)仅在期物对象完成时才会返回.如果期物对象取消,则会引发CancelledError.如果期物对象尚未完成,则会引发InvalidStateError. add_done_callback(fn) 添加一个回调,以便在期物对象完成时运行.使用单个参数(未来对象)调用回调.如果在调用此函数时已经完成了未来,则使用call_soon()调度回调. 通常需要结合functools.partial使用 fut.add_done_callback(functools.partial(print, \"Future:\", flush=True)) 会在回调时执行 print(\"Future:\", fut, flush=True) remove_done_callback(fn) 从'完成调用'列表中删除回调的所有实例.返回删除的回调数. set_result(result) 标记期物对象的状态为done并设定其结果。如果在调用此方法时期物对象已经完成，则引发InvalidStateError set_exception(exception) 标记期物对象的状态为done并设定一个异常。如果在调用此方法时期物对象已经完成，则引发InvalidStateError Task作为Future的子类,额外的方法有: classmethod all_tasks(loop=None) 返回一组事件循环的所有任务对象.默认情况下,返回当前事件循环的所有任务. classmethod current_task(loop=None) 返回事件循环正在执行的任务对象,默认为当前的事件循环.在任务的上下文中调用时返回None. cancel() 请求此任务自行取消.这将安排一个CancelledError通过事件循环在下一个循环中被引入到包装的协同程序中,然后,协调程序有机会使用try / except / finally清理甚至拒绝该请求.与Future.cancel()不同,这不保证任务将被取消. 异常可能会被捕获并被执行,延迟取消任务或者完全阻止取消.该任务也可能返回值或引发不同的异常.在调用此方法之后,cancelled()将不会返回True(除非该任务已被取消).当包装的协同程序以CancelledError异常终止(即使未调用cancel()时,任务将被标记为已取消. get_stack(*, limit=None) 返回此任务的协程的堆栈帧列表。 print_stack(*, limit=None, file=None) 打印此任务的协程的堆栈或追溯。对于由get_stack()检索到的帧，它会产生与追溯模块类似的输出.limit参数传递给get_stack().文件参数是写入输出的I/O流;默认情况下，输出将写入sys.stderr。 创建期物 创建期物必须使用事件循环loop,接口为: create_future() 创建一个期物 create_task(coro) 使用一个协程创建一个任务 set_task_factory(factory) 设置一个由AbstractEventLoop.create_task()使用的工厂函数. 如果工厂为无，则将设置默认任务工厂 如果工厂是可调用的,它应该有一个签名匹配(loop,coro),其中循环将是对活动事件循环的引用,coro将是一个协程对象。 工厂函数必须返回一个asyncio.Future兼容的对象。 get_task_factory() 尝试任务工厂，如果默认工作正在使用，则为“无”。 管理协程的执行,包括取消,延迟,调用等 事件循环实际上上面只能注册期物,而asyncio的很多接口可以直接使用协程,其原因是这些接口会自动将协程包装为期物task. loop.run_until_complete()是最简单的将协程注册进事件循环中并运行的方法. import asyncio import datetime async def display_date(loop): end_time = loop.time() + 5.0 while True: print(datetime.datetime.now()) if (loop.time() + 1.0) >= end_time: break await asyncio.sleep(1) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Blocking call which returns when the display_date() coroutine is done loop.run_until_complete(display_date(loop)) loop.close() 2017-06-13 21:54:43.613908 2017-06-13 21:54:44.618651 2017-06-13 21:54:45.619773 Finished more work 6 More work 3 2017-06-13 21:54:46.624828 2017-06-13 21:54:47.629833 Finished more work 3 asyncio.run_coroutine_threadsafe(coro, loop) 线程安全的执行协程,可以看做是loop.run_until_complete()的线程安全版本. def start_loop(loop): asyncio.set_event_loop(loop) loop.run_forever() async def do_some_work(x): print('Waiting {}'.format(x)) await asyncio.sleep(x) print('Done after {}s'.format(x)) def more_work(x): print('More work {}'.format(x)) time.sleep(x) print('Finished more work {}'.format(x)) start = now() new_loop = asyncio.new_event_loop() t = Thread(target=start_loop, args=(new_loop,)) t.start() print('TIME: {}'.format(time.time() - start)) asyncio.run_coroutine_threadsafe(do_some_work(6), new_loop) asyncio.run_coroutine_threadsafe(do_some_work(4), new_loop) TIME: 0.006371974945068359Waiting 6 Waiting 4 Done after 4s Done after 6s 上述的例子，主线程中创建一个new_loop，然后在另外的子线程中开启一个无限事件循环。主线程通过run_coroutine_threadsafe新注册协程对象。这样就能在子线程中进行事件循环的并发操作，同时主线程又不会被block。一共执行的时间大概在6s左右. ensure_future是asyncio封装好的创建Task的函数,它还支持一些参数,甚至指定loop. 可以使用asyncio.gather(*coros_or_futures, loop=None, return_exceptions=False)¶合并多个协程为一个期物 import asyncio async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.gather( factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4) )) loop.close() Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: Compute factorial(2)... Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task A: factorial(2) = 2 Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 coroutine asyncio.wait(futures, *, loop=None, timeout=None, return_when=ALL_COMPLETED) wait和gather的返回值不一样,wait也可以在第一个future完全或者出错时就返回. import asyncio async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.wait([ factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4)] )) loop.close() Task A: Compute factorial(2)... Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: factorial(2) = 2 Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 asyncio.as_completed(fs, *, loop=None, timeout=None)用于返回一个迭代器，其值等待是Future实例. import asyncio import datetime async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) await asyncio.sleep(1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) return f async def main(): for f in asyncio.as_completed([factorial(\"A\", 2),factorial(\"B\", 3),factorial(\"C\", 4)]): result = await f loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) # Blocking call which returns when the display_date() coroutine is done loop.run_until_complete(main()) loop.close() Task A: Compute factorial(2)... Task C: Compute factorial(2)... Task B: Compute factorial(2)... Task A: factorial(2) = 2 Task C: Compute factorial(3)... Task B: Compute factorial(3)... Task C: Compute factorial(4)... Task B: factorial(3) = 6 Task C: factorial(4) = 24 将耗时函数调用委托给一个线程池/进程池执行器 coroutine run_in_executor(executor, func, *args) 安排在指定的执行器中调用func. 执行器参数应该是Executor实例.如果执行程序为无,则使用默认执行程序. 通常我们用functools.partial来处理要执行的函数 set_default_executor(executor) 设置run_in_executor()使用的默认执行程序。 所谓执行器executor是指concurrent.futures模块下的ThreadPoolExecutor或者ProcessPoolExecutor,在目前python标准api几乎只支持同步方法的情况下,ThreadPoolExecutor可以作为临时方案使用解io密集型问题,而对于计算密集型任务,更加适合使用ProcessPoolExecutor. import asyncio import time async def factorial(name, number): f = 1 for i in range(2, number+1): print(\"Task %s: Compute factorial(%s)...\" % (name, i)) loop = asyncio.get_event_loop() await loop.run_in_executor(None,time.sleep,1) f *= i print(\"Task %s: factorial(%s) = %s\" % (name, number, f)) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(asyncio.wait([ factorial(\"A\", 2), factorial(\"B\", 3), factorial(\"C\", 4)] )) loop.close() Task B: Compute factorial(2)... Task C: Compute factorial(2)... Task A: Compute factorial(2)... Task B: Compute factorial(3)... Task C: Compute factorial(3)... Task A: factorial(2) = 2 Task B: factorial(3) = 6 Task C: Compute factorial(4)... Task C: factorial(4) = 24 协程错误处理 set_exception_handler(handler) 将处理程序设置为新的事件循环异常处理程序.如果处理程序为None,则将设置默认的异常处理程序.如果处理程序是可调用对象,它应该具有匹配的签名(循环,上下文),其中循环将是对活动事件循环的引用,上下文将是一个dict对象(有关上下文的详细信息,请参阅call_exception_handler()文档) get_exception_handler() 返回异常处理程序,如果使用默认处理程序,则返回None. default_exception_handler(context) 默认异常处理程序.当异常发生时调用,并且没有设置异常处理程序,并且可以由想要推迟到默认行为的自定义异常处理程序调用.context参数与call_exception_handler()中的含义相同. call_exception_handler(context) 调用当前的事件循环异常处理程序.上下文是一个包含以下键的dict对象(新键可以稍后介绍): ‘message’: Error message; ‘exception’ (optional): Exception object; ‘future’ (optional): asyncio.Future instance; ‘handle’ (optional): asyncio.Handle instance; ‘protocol’ (optional): Protocol instance; ‘transport’ (optional): Transport instance; ‘socket’ (optional): socket.socket instance. 例子: 生产者消费者模型 以下是一个生产者消费者模式的例子 import asyncio import random async def produce(queue, n): for x in range(1, n + 1): # produce an item print('producing {}/{}'.format(x, n)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) item = str(x) # put the item in the queue await queue.put(item) # indicate the producer is done await queue.put(None) async def consume(queue): while True: # wait for an item from the producer item = await queue.get() if item is None: # the producer emits None to indicate that it is done break # process the item print('consuming item {}...'.format(item)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) queue = asyncio.Queue(loop=loop) producer_coro = produce(queue, 10) consumer_coro = consume(queue) loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) loop.close() producing 1/10 producing 2/10 consuming item 1... producing 3/10 consuming item 2... producing 4/10 consuming item 3... producing 5/10 consuming item 4... producing 6/10 consuming item 5... producing 7/10 consuming item 6... producing 8/10 consuming item 7... producing 9/10 consuming item 8... producing 10/10 consuming item 9... consuming item 10... Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 09:42:23 "},"流程控制/多线程与GIL.html":{"url":"流程控制/多线程与GIL.html","title":"多线程与GIL","keywords":"","body":"多线程与GIL GIL CPython解释器本身就不是线程安全的,因此有全局解释器锁(GIL),一次只允许使用一个线程执行 Python 字节码。因此,一个 Python 进程通常不能同时使用多个 CPU 核心。 编写 Python 代码时无法控制 GIL;不过,执行耗时的任务时,可以使用一个内置的函数 或一个使用 C 语言编写的扩展释放 GIL。其实,有个使用 C 语言编写的 Python 库能管理 GIL,自行启动操作系统线程,利用全部可用的 CPU 核心。这样做会极大地增加库代码的 复杂度,因此大多数库的作者都不这么做。 然而,标准库中所有执行阻塞型 I/O 操作的函数,在等待操作系统返回结果时都会释放 GIL。这意味着在 Python 语言这个层次上可以使用多线程处理io阻塞问题,而 I/O 密集型 Python 程序能从中受益:一个 Python 线程等待网络响应时,阻塞型 I/O 函数会释放 GIL,再运行一个线程。 为什么需要GIL GIL是必须的，这是Python设计的问题：Python解释器是非线程安全的。这意味着当从线程内尝试安全的访问Python对象的时候将有一个全局的强制锁。在任何时候，仅仅一个单一的线程能够获取Python对象或者C API。每100个字节的Python指令解释器将重新获取锁，这（潜在的）阻塞了I/O操作。因此CPU密集型的代码使用线程库时，不会获得性能的提高. 使用concurrent.futures进行高层抽象的多线程操作 concurrent.futures提供两种编程模型: 并行任务模型 单独任务独立使用自己的过程和数据,多任务独立并行计算 MapReduce模型 为各个线程分发数据执行相同的过程 并行任务模型 这个模型使用submit提交任务到上下文管理器,之后使用返回对象的result()方法阻塞io等待任务完成 from concurrent.futures import ThreadPoolExecutor,as_completed from random import randrange from time import time def arcfour(key, in_bytes, loops=20): \"\"\"rc4算法\"\"\" kbox = bytearray(256) # create key box for i, car in enumerate(key): # copy key and vector kbox[i] = car j = len(key) for i in range(j, 256): # repeat until full kbox[i] = kbox[i-j] # [1] initialize sbox sbox = bytearray(range(256)) # repeat sbox mixing loop, as recommened in CipherSaber-2 # http://ciphersaber.gurus.com/faq.html#cs2 j = 0 for k in range(loops): for i in range(256): j = (j + sbox[i] + kbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # main loop i = 0 j = 0 out_bytes = bytearray() for car in in_bytes: i = (i + 1) % 256 # [2] shuffle sbox j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # [3] compute t t = (sbox[i] + sbox[j]) % 256 k = sbox[t] car = car ^ k out_bytes.append(car) return out_bytes clear = bytearray(b'1234567890' * 100000) t0 = time() cipher = arcfour(b'key', clear) print('elapsed time: %.2fs' % (time() - t0)) result = arcfour(b'key', cipher) assert result == clear, '%r != %r' % (result, clear) print('elapsed time: %.2fs' % (time() - t0)) print('OK') elapsed time: 0.86s elapsed time: 1.73s OK def crypto_process(size, key): in_text = bytearray(randrange(256) for i in range(size)) cypher_text = arcfour(key, in_text) out_text = arcfour(key, cypher_text) assert in_text == out_text, 'Failed arcfour_test' return size def main(workers=None): JOBS = 12 SIZE = 2**18 KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\" STATUS = '{} workers, elapsed time: {:.2f}s' if workers: workers = int(workers) t0 = time() with ThreadPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = [] for i in range(JOBS, 0, -1): size = SIZE + int(SIZE / JOBS * (i - JOBS/2)) job = executor.submit(crypto_process, size, KEY) to_do.append(job) for future in as_completed(to_do): res = future.result() print('{:.1f} KB'.format(res/2**10)) print(STATUS.format(actual_workers, time() - t0)) main(1) 384.0 KB 362.7 KB 341.3 KB 320.0 KB 298.7 KB 277.3 KB 256.0 KB 234.7 KB 213.3 KB 192.0 KB 170.7 KB 149.3 KB 1 workers, elapsed time: 10.66s main(2) 362.7 KB 384.0 KB 320.0 KB 341.3 KB 277.3 KB 298.7 KB 234.7 KB 256.0 KB 213.3 KB 192.0 KB 149.3 KB 170.7 KB 2 workers, elapsed time: 13.25s main(4) 320.0 KB 362.7 KB 341.3 KB 384.0 KB 256.0 KB 298.7 KB 277.3 KB 234.7 KB 149.3 KB 170.7 KB 213.3 KB 192.0 KB 4 workers, elapsed time: 12.75s MapReduce模型 这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理 import math PRIMES = [ 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419] def is_prime(n): if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return True [is_prime(i) for i in PRIMES] [True, True, True, True, True, False] def ProcessPool_prime(PRIMES= PRIMES ,workers=4): with ThreadPoolExecutor(max_workers=workers) as executor: total = [] for prime in executor.map(is_prime, PRIMES): #print('%d is prime: %s' % (number, prime)) total.append(prime) return total ProcessPool_prime() [True, True, True, True, True, False] *使用装饰器无痛多线程 Tomorrow模块模块是一个ThreadPoolExecutor模块的封装,虽然只是简单地接口变化,但带来的写法上的进化非常巨大,值得一试,我们可以使用pip安装这个模块 要使用多线程只需要使用装饰器threads并设置最大线程和断开时间timeout(默认为None)即可 from tomorrow import threads @threads(4) def is_prime_2(n): print(str(n)+\":start\") if n % 2 == 0: print(str(n)+\":end\") return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: print(str(n)+\":end\") return False print(str(n)+\":end\") return True responses = [is_prime_2(i) for i in PRIMES] 112272535095293:start112582705942171:start112272535095293:start115280095190773:start responses [, , , , , ] 112272535095293:end112582705942171:end 115797848077099:start1099726899285419:start 使用线程池进行相对底层的多进程操作 线程池的方式很适合批量创建子线程.线程池模块藏在多进程模块multiprocessing.pool下,ThreadPool 对ThreadPool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。 请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成p = Pool(5)就可以同时跑5个进程。 由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。 除了使用apply_async方法外,还有apply，map和map_async可以用于线程池的计算,编程模型也是如concurrent.futures一样分为两类 并行任务模型 apply 单一任务布置 apply_async 非阻塞单一任务布置 MapReduce模型 map 同系统的map方法 map_async 非阻塞的map apply_async from multiprocessing.pool import ThreadPool as Pool import os, time, random def long_time_task(name): print('运行任务 %s (%s)...' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start))) 112272535095293:end115280095190773:end 1099726899285419:end print('父线程 %s.' % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i,))#创建非阻塞子线程用这个 print('等待所有子线程完成...') p.close() p.join() print('所有子线程完成了.') 父线程 1328. 115797848077099:end 等待所有子线程完成...运行任务 1 (1328)...运行任务 0 (1328)... 运行任务 2 (1328)... 运行任务 3 (1328)... 任务 2 执行了 1.40 秒. 运行任务 4 (1328)... 任务 1 执行了 1.57 秒. 任务 3 执行了 1.97 秒. 任务 4 执行了 1.05 秒. 任务 0 执行了 2.83 秒. 所有子线程完成了. map_async from multiprocessing.pool import ThreadPool as Pool from time import sleep def f(x): return x*x # start 4 worker processes pool = Pool(processes=4) print(\"map: \",pool.map(f, range(10))) print(\"imap:\") for i in pool.imap_unordered(f, range(10)): print(i) # evaluate \"f(10)\" asynchronously res = pool.apply_async(f, [10]) print(\"apply:\",res.get(timeout=1)) # prints \"100\" # make worker sleep for 10 secs res = pool.apply_async(sleep, [10]) print(res.get(timeout=1)) # raises multiprocessing.TimeoutError map: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] imap: 0 1 4 9 16 25 36 49 64 81 apply: 100 --------------------------------------------------------------------------- TimeoutError Traceback (most recent call last) in () 18 # make worker sleep for 10 secs 19 res = pool.apply_async(sleep, [10]) ---> 20 print(res.get(timeout=1)) # raises multiprocessing.TimeoutError ~/LIB/CONDA/anaconda/lib/python3.6/multiprocessing/pool.py in get(self, timeout) 602 self.wait(timeout) 603 if not self.ready(): --> 604 raise TimeoutError 605 if self._success: 606 return self._value TimeoutError: 获取进程池中的运算结果 from multiprocessing.pool import ThreadPool as Pool import time def func(msg): print(\"msg:\", msg) time.sleep(1) print(\"end\") return \"done \" + msg pool = Pool(processes=4) result = [] for i in range(3): msg = \"hello %d\" %(i) result.append(pool.apply_async(func, (msg, ))) pool.close() pool.join() for res in result: print(\":::\", res.get()) print(\"Sub-process(es) done.\") msg:msg:msg: hello 1hello 2hello 0 end endend ::: done hello 0 ::: done hello 1 ::: done hello 2 Sub-process(es) done. 更底层的多线程编程 threading模块提供了一个高层的API来提供线程的并发性。这些线程并发运行并共享内存。 多线程看着多么美好的,但因为数据安全的问题被加了锁..所以永远是单核运行,不细说了看个简单的用法吧 下面来看threading模块的具体用法： import threading import time def worker(i): print(i) time.sleep(1) print(\"AWAKE\") for i in range(5): t = threading.Thread(target=worker,args=(i,)) t.start() print(\"closed\") 102 3 4 closed AWAKEAWAKEAWAKE AWAKE AWAKE 对比下不用多线程: def worker(i): print(i) import time time.sleep(1) print(\"AWAKE\") for i in range(5): worker(i) 0 AWAKE 1 AWAKE 2 AWAKE 3 AWAKE 4 AWAKE 一个相对复杂的例子 from threading import Thread import os #子线程要执行的代码 def run_proc(name): for i in range(3): print(u'子线程 %s (%s)...' % (name, os.getpid())) print(u'子线程结束.') print(u'父线程 {}.'.format(os.getpid())) p = Thread(target=run_proc, args=('test',)) print(u'子线程要开始啦.') p.start() for i in range(3): print(u'父线程{pid}进行中...'.format(pid = os.getpid())) p.join() print(u\"父线程结束啦\") 父线程 1328. 子线程要开始啦. 父线程1328进行中...子线程 test (1328)... 父线程1328进行中...子线程 test (1328)... 父线程1328进行中...子线程 test (1328)... 父线程结束啦子线程结束. 使用Thread作为父类自定义子线程 Thread的子类需要重写run方法 from threading import Thread from queue import Queue class Processor(Thread): def __init__(self, queue, idx): super(Processor, self).__init__() self.queue = queue self.idx = idx def return_name(self): ## NOTE: self.name is an attribute of multiprocessing.Process return \"Thread idx=%s is called '%s'\" % (self.idx, self.name) def run(self): self.queue.put(self.return_name()) processes = list() q = Queue() for i in range(0,5): p=Processor(queue=q, idx=i) processes.append(p) p.start() for proc in processes: proc.join() ## NOTE: You cannot depend on the results to queue / dequeue in the ## same order print(\"RESULT: {}\".format(q.get())) RESULT: Thread idx=0 is called 'Thread-31' RESULT: Thread idx=1 is called 'Thread-32' RESULT: Thread idx=2 is called 'Thread-33' RESULT: Thread idx=3 is called 'Thread-34' RESULT: Thread idx=4 is called 'Thread-35' 创建子线程时，只需要传入一个执行函数和函数的参数，创建一个Thread实例，用start()方法启动，这样创建进程比fork()简单。 join()方法可以等待子线程结束后再继续往下运行，通常用于线程间的同步。 可以看到我们的父线程进行完了子线程才进行.其实当执行start方法的时候我们就已经把线程创建好并给他任务了. 虽然线程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主线程),也就是起个等待结果的作用. 使用队列管理线程 线程安全是多线程编程中最不容易的事儿,线程间同步,互斥数据共享一直是要考虑的问题,而最常见的就是用队列实现管理线程了. 生产者消费者模型 队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子 import queue as Queue import threading import random class Producer(threading.Thread): \"\"\"生产者\"\"\" def __init__(self,q,con,name): super(Producer,self).__init__() self.q = q self.name = name self.con = con print(\"生产者{self.name}产生了\".format(self=self)) def run(self): count = 3 #只生产满3轮,要不然就会无限循环出不去了 while count>0: #global writelock self.con.acquire() if self.q.full(): print(\"队列满了,生产者等待\") count-=1 self.con.wait() else: value = random.randint(0,10) print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value)) self.q.put(\"{self.name}:{value}\".format(self=self,value=value)) self.con.notify() self.con.release() class Consumer(threading.Thread): \"\"\"消费者\"\"\" def __init__(self,q,con,name): super(Consumer,self).__init__() self.q = q self.name = name self.con = con print(\"消费者{self.name}产生了\".format(self=self)) def run(self): while True: #global writelock self.con.acquire() if self.q.empty(): print(\"队列空了,消费者等待\") self.con.wait() else: value = self.q.get() print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self, value=value)) self.con.notify() self.con.release() q = Queue.Queue(10) con = threading.Condition() p1 = Producer(q,con,\"P1\") p1.start() p2 = Producer(q,con,\"P2\") p2.start() c1 = Consumer(q,con,\"C1\") c1.start() 生产者P1产生了P1把值P1:5放入了队列 P1把值P1:8放入了队列生产者P2产生了 P1把值P1:8放入了队列消费者C1产生了 P1把值P1:7放入了队列 队列满了,生产者等待C1从队列中获取了C1:P1:5P1把值P1:3放入了队列 C1从队列中获取了C1:P1:8 P1把值P1:3放入了队列C1从队列中获取了C1:P1:8 P1把值P1:6放入了队列C1从队列中获取了C1:P1:7 P1把值P1:2放入了队列C1从队列中获取了C1:P1:3 P1把值P1:10放入了队列C1从队列中获取了C1:P1:3 P1把值P1:0放入了队列C1从队列中获取了C1:P1:6 队列满了,生产者等待队列满了,生产者等待C1从队列中获取了C1:P1:2 P1把值P1:8放入了队列C1从队列中获取了C1:P1:10 P1把值P1:7放入了队列C1从队列中获取了C1:P1:0 P1把值P1:0放入了队列队列空了,消费者等待 P1把值P1:3放入了队列C1从队列中获取了C1:P1:8 C1从队列中获取了C1:P1:7P1把值P1:4放入了队列 C1从队列中获取了C1:P1:0P1把值P1:7放入了队列 C1从队列中获取了C1:P1:3P1把值P1:2放入了队列P2把值P2:5放入了队列 C1从队列中获取了C1:P1:4P1把值P1:6放入了队列P2把值P2:6放入了队列 C1从队列中获取了C1:P1:7P1把值P1:10放入了队列P2把值P2:5放入了队列 C1从队列中获取了C1:P1:2P1把值P1:4放入了队列P2把值P2:5放入了队列 C1从队列中获取了C1:P1:6队列满了,生产者等待P2把值P2:2放入了队列 C1从队列中获取了C1:P1:10队列满了,生产者等待P2把值P2:9放入了队列 C1从队列中获取了C1:P1:4P2把值P2:10放入了队列 队列空了,消费者等待P2把值P2:0放入了队列 P2把值P2:4放入了队列 P2把值P2:10放入了队列 队列满了,生产者等待 queue模块说明 队列类型 queue.Queue(maxsize) 先进先出队列,maxsize是队列长度,其值为非正数时是无限循环队列 queue.LifoQueue(maxsize) 后进先出队列,也就是栈 queue.PriorityQueue(maxsize) 优先级队列 支持方法 qsize() 返回近似队列大小,,用近似二字因为当该值大于0时不能保证并发执行的时候get(),put()方法不被阻塞 empty() 判断是否为空,空返回True否则返回False full() 当设定了队列大小的时候,如果队列满了则返回True,否则False put(item[,block[,timeout]]) 向队列添加元素 当block设置为False时队列满则抛出异常 当block为True,timeout为None时则会等待直到有空位 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误 put_nowait(item) 相当于put(item,False) get([,block[,timeout]) 从队列中取出元素, 当block设置为False时队列空则抛出异常 当block为True,timeout为None时则会等待直到有+元素 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误 get_nowait() 等价于get(False) task_done() 发送信号表明入列任务已经完成,常在消费者线程里使用 join() 阻塞直到队列中所有元素处理完 Queue是线程安全的,而且支持in操作,因此用它的时候不用考虑锁的问题 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 21:38:41 "},"流程控制/多进程.html":{"url":"流程控制/多进程.html","title":"多进程","keywords":"","body":"python多进程编程 python受GIL限制,无法利用到多核,要使用多核提高cpu的利用率这种时候最简单的方式就是使用多进程实现突破GIL限制. 换言之python多进程的价值体现在CPU密集型作业上. 进程(Process)是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体. python调用系统fork Unix/Linux操作系统提供了一个fork()系统调用.普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。 子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。 pythonos模块封装了fork()(unix-like系统).事实上在类unix系统下,python的多进程都是基于fork的,而windows下情况就不一样了. windows下的多进程局限性 在windows下,由于没有fork,python的多进程模块multiprocessing必须要有if __name__=='__main__':也就是说它无法在非入口模块下使用 import os print('Process ({}) 开始...'.format(os.getpid())) # Only works on Unix/Linux/Mac: pid = os.fork() if pid == 0: print('子进程: ({}) 它的父进程是: ({}).'.format(os.getpid(), os.getppid())) else: print('父进程 ({}) 产生了子进程: ({}).'.format(os.getpid(), pid)) Process (1372) 开始... 父进程 (1372) 产生了子进程: (1377). 子进程: (1377) 它的父进程是: (1372). 使用concurrent.futures进行高层抽象的多进程操作 在python3中,模块concurrent.futures提供了一些更加简单易用的多进程操作,它主要利用进程池. 这个库支持多线程和多进程,接口一样,只是使用的对象不同而已. concurrent.futures提供两种编程模型: 并行任务模型 单独任务独立使用自己的过程和数据,多任务独立并行计算 MapReduce模型 为各个进程分发数据执行相同的过程 并行任务模型 这个模型使用submit提交任务到上下文管理器,之后使用返回对象的result()方法阻塞io等待任务完成 from concurrent.futures import ProcessPoolExecutor,as_completed from random import randrange from time import time def arcfour(key, in_bytes, loops=20): \"\"\"rc4算法\"\"\" kbox = bytearray(256) # create key box for i, car in enumerate(key): # copy key and vector kbox[i] = car j = len(key) for i in range(j, 256): # repeat until full kbox[i] = kbox[i-j] # [1] initialize sbox sbox = bytearray(range(256)) # repeat sbox mixing loop, as recommened in CipherSaber-2 # http://ciphersaber.gurus.com/faq.html#cs2 j = 0 for k in range(loops): for i in range(256): j = (j + sbox[i] + kbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # main loop i = 0 j = 0 out_bytes = bytearray() for car in in_bytes: i = (i + 1) % 256 # [2] shuffle sbox j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # [3] compute t t = (sbox[i] + sbox[j]) % 256 k = sbox[t] car = car ^ k out_bytes.append(car) return out_bytes clear = bytearray(b'1234567890' * 100000) t0 = time() cipher = arcfour(b'key', clear) print('elapsed time: %.2fs' % (time() - t0)) result = arcfour(b'key', cipher) assert result == clear, '%r != %r' % (result, clear) print('elapsed time: %.2fs' % (time() - t0)) print('OK') elapsed time: 1.60s elapsed time: 3.00s OK def crypto_process(size, key): in_text = bytearray(randrange(256) for i in range(size)) cypher_text = arcfour(key, in_text) out_text = arcfour(key, cypher_text) assert in_text == out_text, 'Failed arcfour_test' return size def main(workers=None): JOBS = 12 SIZE = 2**18 KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\" STATUS = '{} workers, elapsed time: {:.2f}s' if workers: workers = int(workers) t0 = time() with ProcessPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = [] for i in range(JOBS, 0, -1): size = SIZE + int(SIZE / JOBS * (i - JOBS/2)) job = executor.submit(crypto_process, size, KEY) to_do.append(job) for future in as_completed(to_do): res = future.result() print('{:.1f} KB'.format(res/2**10)) print(STATUS.format(actual_workers, time() - t0)) main(1) 384.0 KB 362.7 KB 341.3 KB 320.0 KB 298.7 KB 277.3 KB 256.0 KB 234.7 KB 213.3 KB 192.0 KB 170.7 KB 149.3 KB 1 workers, elapsed time: 18.30s main(2) 362.7 KB 384.0 KB 320.0 KB 341.3 KB 277.3 KB 298.7 KB 234.7 KB 256.0 KB 192.0 KB 213.3 KB 149.3 KB 170.7 KB 2 workers, elapsed time: 12.87s main(4) 320.0 KB 341.3 KB 362.7 KB 384.0 KB 234.7 KB 256.0 KB 277.3 KB 298.7 KB 149.3 KB 170.7 KB 192.0 KB 213.3 KB 4 workers, elapsed time: 10.09s MapReduce模型 这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理 import math PRIMES = [ 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419] def is_prime(n): if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return True [is_prime(i) for i in PRIMES] [True, True, True, True, True, False] %timeit [is_prime(i) for i in PRIMES] 9.35 s ± 870 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) def ProcessPool_prime(PRIMES= PRIMES ,workers=4): with ProcessPoolExecutor(max_workers=workers) as executor: total = [] for prime in executor.map(is_prime, PRIMES): #print('%d is prime: %s' % (number, prime)) total.append(prime) return total ProcessPool_prime() [True, True, True, True, True, False] %timeit ProcessPool_prime(workers=4) 4.82 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 使用进程池进行相对底层的多进程操作 进程池的方式很适合批量创建子进程. 对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。 请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成p = Pool(5)就可以同时跑5个进程。 由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。 除了使用apply_async方法外,还有apply，map和map_async可以用于线程池的计算,编程模型也是如concurrent.futures一样分为两类 并行任务模型 apply 单一任务布置 apply_async 非阻塞单一任务布置 MapReduce模型 map 同系统的map方法 map_async 非阻塞的map apply_async from multiprocessing import Pool import os, time, random def long_time_task(name): print('运行任务 %s (%s)...' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start))) print('父进程 %s.' % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i,))#创建非阻塞子进程用这个 print('等待所有子进程完成...') p.close() p.join() print('所有子进程完成了.') 父进程 1372. 运行任务 0 (1432)... 运行任务 1 (1433)... 运行任务 2 (1434)... 运行任务 3 (1435)... 等待所有子进程完成... 任务 3 执行了 0.69 秒. 运行任务 4 (1435)... 任务 1 执行了 1.39 秒. 任务 4 执行了 0.94 秒. 任务 0 执行了 1.81 秒. 任务 2 执行了 2.42 秒. 所有子进程完成了. map_async from multiprocessing import Pool from time import sleep def f(x): return x*x # start 4 worker processes pool = Pool(processes=4) print(\"map: \",pool.map(f, range(10))) print(\"imap:\") for i in pool.imap_unordered(f, range(10)): print(i) # evaluate \"f(10)\" asynchronously res = pool.apply_async(f, [10]) print(\"apply:\",res.get(timeout=1)) # prints \"100\" # make worker sleep for 10 secs res = pool.apply_async(sleep, [10]) print(res.get(timeout=1)) # raises multiprocessing.TimeoutError map: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] imap: 0 1 4 9 16 25 36 64 49 81 apply: 100 --------------------------------------------------------------------------- TimeoutError Traceback (most recent call last) in () 18 # make worker sleep for 10 secs 19 res = pool.apply_async(sleep, [10]) ---> 20 print(res.get(timeout=1)) # raises multiprocessing.TimeoutError ~/LIB/CONDA/anaconda/lib/python3.6/multiprocessing/pool.py in get(self, timeout) 602 self.wait(timeout) 603 if not self.ready(): --> 604 raise TimeoutError 605 if self._success: 606 return self._value TimeoutError: 获取进程池中的运算结果 import multiprocessing import time def func(msg): print(\"msg:\", msg) time.sleep(1) print(\"end\") return \"done \" + msg pool = multiprocessing.Pool(processes=4) result = [] for i in range(3): msg = \"hello %d\" %(i) result.append(pool.apply_async(func, (msg, ))) pool.close() pool.join() for res in result: print(\":::\", res.get()) print(\"Sub-process(es) done.\") msg: hello 0 msg: hello 1 msg: hello 2 end end end ::: done hello 0 ::: done hello 1 ::: done hello 2 Sub-process(es) done. 更底层的多进程编程 标准库中的multiprocessing模块就是跨平台版本的多进程模块。 multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束： from multiprocessing import Process import os #子进程要执行的代码 def run_proc(name): for i in range(3): print(u'子进程 %s (%s)...' % (name, os.getpid())) print(u'子进程结束.') print(u'父进程 {}.'.format(os.getpid())) p = Process(target=run_proc, args=('test',)) print(u'子进程要开始啦.') p.start() for i in range(3): print(u'父进程{pid}进行中...'.format(pid = os.getpid())) p.join() print(u\"父进程结束啦\") 父进程 1372. 子进程要开始啦. 子进程 test (1444)... 子进程 test (1444)... 子进程 test (1444)... 子进程结束. 父进程1372进行中... 父进程1372进行中... 父进程1372进行中... 父进程结束啦 使用Process作为父类自定义子进程 Process的子类需要重写run方法 from multiprocessing import Process, Queue class Processor(Process): def __init__(self, queue, idx): super(Processor, self).__init__() self.queue = queue self.idx = idx def return_name(self): ## NOTE: self.name is an attribute of multiprocessing.Process return \"Process idx=%s is called '%s'\" % (self.idx, self.name) def run(self): self.queue.put(self.return_name()) processes = list() q = Queue() for i in range(0,5): p=Processor(queue=q, idx=i) processes.append(p) p.start() for proc in processes: proc.join() ## NOTE: You cannot depend on the results to queue / dequeue in the ## same order print(\"RESULT: {}\".format(q.get())) RESULT: Process idx=0 is called 'Processor-57' RESULT: Process idx=1 is called 'Processor-58' RESULT: Process idx=2 is called 'Processor-59' RESULT: Process idx=3 is called 'Processor-60' RESULT: Process idx=4 is called 'Processor-61' 创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()简单。 join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。 可以看到我们的父进程进行完了子进程才进行.其实当执行start方法的时候我们就已经把进程创建好并给他任务了. 虽然进程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主进程),也就是起个等待结果的作用. 进程间通信 如何让进程间通信呢,其实原理上来讲就是构造一个独立的数据结构来存放结果来参与通信 有两种方式,最常用的一种是用队列 先进先出队列Queue from multiprocessing import Process, Queue def f(q): q.put([42, None, 'hello']) q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints \"[42, None, 'hello']\" p.join() [42, None, 'hello'] 个稍微复杂一点的例子: from multiprocessing import Process, Queue import os, time, random # 写数据进程执行的代码: def write(q): for value in ['A', 'B', 'C']: print('Put %s to queue...' % value) q.put(value) time.sleep(random.random()) # 读数据进程执行的代码: def read(q): # pr进程里是死循环，无法等待其结束，只能强行终止: while True: if not q.empty(): value = q.get(True) print('Get %s from queue.' % value) time.sleep(random.random()) else: q.put(\"Done!\") break # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() print(q.get()) print('\\n所有数据都写入并且读完') Put A to queue... Put B to queue... Put C to queue... Get A from queue. Get B from queue. Get C from queue. Done! 所有数据都写入并且读完 两个进程间,父进程创建一个队列给各个子进程,子进程接收父进程的队列作为参数运行. 运行过程中将结果存入队列最后运行完后将”done!”存入队列,由父进程接收. 生产者消费者模型 队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子 import random from multiprocessing import Process, Queue,Condition class Producer(Process): \"\"\"生产者\"\"\" def __init__(self,q,con,name): super(Producer,self).__init__() self.q = q self.name = name self.con = con print(\"生产者{self.name}产生了\".format(self=self)) def run(self): count = 3 #只生产满3轮,要不然就会无限循环出不去了 while count>0: #global writelock self.con.acquire() if self.q.full(): print(\"队列满了,生产者等待\") count-=1 self.con.wait() else: value = random.randint(0,10) print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value)) self.q.put(\"{self.name}:{value}\".format(self=self,value=value)) self.con.notify() self.con.release() class Consumer(Process): \"\"\"消费者\"\"\" def __init__(self,q,con,name): super(Consumer,self).__init__() self.q = q self.name = name self.con = con print(\"消费者{self.name}产生了\".format(self=self)) def run(self): while True: #global writelock self.con.acquire() if self.q.empty(): print(\"队列空了,消费者等待\") self.con.wait() else: value = self.q.get() print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self, value=value)) self.con.notify() self.con.release() q = Queue(10) con = Condition() p1 = Producer(q,con,\"P1\") p1.start() p2 = Producer(q,con,\"P2\") p2.start() c1 = Consumer(q,con,\"C1\") c1.start() 生产者P1产生了 生产者P2产生了 消费者C1产生了 P1把值P1:1放入了队列 P1把值P1:2放入了队列 P1把值P1:9放入了队列 P1把值P1:1放入了队列 P1把值P1:8放入了队列 P1把值P1:10放入了队列 P1把值P1:5放入了队列 P1把值P1:8放入了队列 P1把值P1:6放入了队列 P1把值P1:9放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:1 P1把值P1:2放入了队列 队列满了,生产者等待 C1从队列中获取了C1:P1:2 P2把值P2:7放入了队列 队列满了,生产者等待 队列满了,生产者等待 C1从队列中获取了C1:P1:9 P2把值P2:0放入了队列 队列满了,生产者等待 管道Pipes 既然是管道,那就肯定有两端,有方向,分成单向管道和双向管道了. 看一个最简单的双向管道 from multiprocessing import Process, Pipe def f(conn): conn.send([42, None, 'hello']) conn.close() parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) # prints \"[42, None, 'hello']\" p.join() [42, None, 'hello'] 稍微复杂的例子: from multiprocessing import Process, Pipe import os, time, random # 写数据进程执行的代码: def write(conn): value = [\"h1 reader~\"] print('Put %s to pip...' % value) conn.send(value) time.sleep(1) # 读数据进程执行的代码: def read(conn): # pr进程里是死循环，无法等待其结束，只能强行终止: value = conn.recv() print('Get %s from pip.' % value) conn.send(\"hi writer~~\") # 父进程创建Pipe，并传给各个子进程： parent_conn, child_conn = Pipe() pw = Process(target=write, args=(parent_conn,))#起点 pr = Process(target=read, args=(child_conn,))#终点 # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() print(parent_conn.recv()) print('\\n所有数据都写入并且读完') Put ['h1 reader~'] to pip... Get ['h1 reader~'] from pip. hi writer~~ 所有数据都写入并且读完 可以看出管道的限制相对多些,必须要建立连接才能交换数据,一出一进这样子,这也是为啥队列用的比较多. 静态数据共享 python里面的全局变量也只管到他自己的进程,如果要让一个静态的数据在每个子进程中都可以调用.那么需要用到模块中的几个方法: Value, Array 静态数据位共享,静态数组共享,本质就是在内存中开辟一块用于共享的空间,Value和Array都必须使用C类型保存数据 from multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] num = Value('d', 0.0) arr = Array('i', range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) 3.1415927 [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] 高级共享multiprocessing.Manager 之前介绍了queue,pipe,array和value,这些都太具体底层,有没有什么方法可以像处理python容器一样 简单地处理数据共享的问题呢?multiprocess提供一个manager模块. Manager()返回的manager对象控制了一个server进程，此进程包含的python对象可以被其他的进程通过proxies来访问。从而达到多进程间数据通信且安全。 Manager支持的类型有 list dict Namespace Lock RLock Semaphore BoundedSemaphore Condition Event Queue Value Array。 import multiprocessing import time def worker(d, key, value): d[key] = value mgr = multiprocessing.Manager() d = mgr.dict() jobs = [ multiprocessing.Process(target=worker, args=(d, i, i*2)) for i in range(10) ] for j in jobs: j.start() for j in jobs: j.join() print ('Results:' ) for key, value in enumerate(dict(d)): print(\"%s=%s\" % (key, value)) Results: 0=0 1=1 2=2 3=3 4=4 5=5 6=6 7=7 8=8 9=9 namespace对象没有公共的方法，但是有可写的属性 import multiprocessing manager = multiprocessing.Manager() Global = manager.Namespace() Global.x = 10 Global.y = 'hello' print(Global) Namespace(x=10, y='hello') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 21:45:30 "},"流程控制/并行编程的惯用法.html":{"url":"流程控制/并行编程的惯用法.html","title":"并行编程的惯用法","keywords":"","body":"并行方式如何选择 看起来多进程,多线程,协程都是以并行的方式运行的,那么我们该如何选择使用什么技术呢? 首先我们可以简单的通过分析目标功能来选择,如果我们的项目主要是计算密集型的,比如是并行计算多个数据是否是质数这类,那么没得选,只有多进程才可以做到最大化利用cpu资源,另外两个都只能跑满一个cpu核心. 接着就是主要是io操作的任务了,io密集型任务首选当然是协程,也只有协程可以搞定10k问题,但python的默认I/O多是同步I/O,因此在所需依赖无法满足的情况下只能使用多线程方式替代. 协程和多线程都最多跑满一个核心,但其机制是完全不一样的,协程是用户组织代码,因此是写成顺序执行的异步执行,说白了还是在顺序执行,只是线程运行哪段代码会在协程间跳转执行,打个比方有点像拉链,只要有一个齿坏了,整个过程就会卡住. 但多线程则完全不同,一个线程卡死了并不会影响其他线程. 并行编程的常用同步机制(原语) python包含多种同步机制,这些工具使用思路上是一致的,因此无论是协程,线程还是进程都可以使用,只是使用的模块会有些许不同,用途也会有写不同 信号量 Semaphore 在并行编程中，为了防止不同的过程(线程/进程/协程)同时对一个公用的资源进行修改，需要进行同时访问的数量（通常是1）。信号量同步基于内部计数器，每调用一次acquire()，计数器减1；每调用一次release()，计数器加1.计数器的值永远不会小于 0.当计数器为0时，acquire()调用被阻塞,直到其他线程来调用release(). Semaphore支持上下文管理协议 Semaphore的接口有两个: acquire() 获取一个信号量,协程中这个方法是一个协程 release() 释放一个信号量 *locked() 协程中独有,用来判断是否被锁定 信号量有两种: Semaphore 标准信号量 BoundedSemaphore 有界信号量,它会检查内部计数器的值,并保证它不会大于初始值,如果超了,就引发一个ValueError 多数情况下,semaphore用于守护限制访问(但不限于1)的资源，如果 semaphore 被 release() 过多次，这意味着存在 bug. 信号量在线程,进程,协程中的使用的模块并不一样: 协程--asynico.Semaphore(value=1, *, loop=None) 线程--threading.Semaphore(value=1) 进程--multiprocessing.Semaphore([value]) 协程版本 import aiohttp import asyncio NUMBERS = range(12) URL = 'http://httpbin.org/get?a={}' sema = asyncio.Semaphore(3) async def fetch_async(a): async with aiohttp.request('GET', URL.format(a)) as r: data = await r.json() return data['args']['a'] async def print_result(a): async with sema: r = await fetch_async(a) print('fetch({}) = {}'.format(a, r)) #loop = asyncio.new_event_loop() #asyncio.set_event_loop(loop) loop = asyncio.get_event_loop() f = asyncio.wait([print_result(num) for num in NUMBERS]) loop.run_until_complete(f) fetch(11) = 11 fetch(7) = 7 fetch(8) = 8 fetch(1) = 1 fetch(9) = 9 fetch(3) = 3 fetch(2) = 2 fetch(5) = 5 fetch(4) = 4 fetch(0) = 0 fetch(6) = 6 fetch(10) = 10 ({:11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>, :11> result=None>}, set()) 多线程版本 import time from random import random from threading import Thread, Semaphore sema = Semaphore(3) def foo(tid): with sema: print('{} acquire sema'.format(tid)) wt = random() * 2 time.sleep(wt) print('{} release sema'.format(tid)) threads = [] for i in range(5): t = Thread(target=foo, args=(i,)) threads.append(t) t.start() for t in threads: t.join() 0 acquire sema 1 acquire sema 2 acquire sema 2 release sema3 acquire sema 1 release sema4 acquire sema 3 release sema 0 release sema 4 release sema 多进程 %%writefile src/semaphore.py from multiprocessing import Process, Semaphore def foo(tid,sema): import time from random import random with sema: print('{} acquire sema'.format(tid)) wt = random() * 2 time.sleep(wt) print('{} release sema'.format(tid)) if __name__ == \"__main__\": sema = Semaphore(3) processes = [] for i in range(5): t = Process(target=foo, args=(i,sema)) processes.append(t) for t in processes: t.start() for t in processes: t.join() Writing src/semaphore.py !python src/semaphore.py 0 acquire sema 1 acquire sema 2 acquire sema 2 release sema 3 acquire sema 1 release sema 4 acquire sema 4 release sema 3 release sema 0 release sema 锁Lock Lock也可以叫做互斥锁，其实相当于信号量为1。 在多线程中锁的作用是用于锁定读写,以确认同一个资源同一时间只能被一个操作访问. python中锁有两种 Lock 标准锁 RLock 可重入锁,可以由同一个过程多次获取.在内部,除了原始锁使用的锁定/解锁状态之外,它还使用\"拥有过程\"和\"递归级别\"的概念.在锁定状态下,某些过程拥有锁;在解锁状态下,没有线程拥有它. 我们先看一个不加锁的例子: import time from threading import Thread value = 0 def getlock(): global value new = value + 1 time.sleep(0.001) # 使用sleep让线程有机会切换 value = new threads = [] for i in range(100): t = Thread(target=getlock) t.start() threads.append(t) for t in threads: t.join() print(value) 22 不加锁的情况下，结果会远远的小于100。那我们加上互斥锁看看 import time from threading import Thread, Lock value = 0 lock = Lock() def getlock(): global value with lock: new = value + 1 time.sleep(0.001) value = new threads = [] for i in range(100): t = Thread(target=getlock) t.start() threads.append(t) for t in threads: t.join() print(value) 100 锁作为一种特殊信号量,它的接口与Semaphore一致.在线程,进程,协程中的使用的模块分别为: 协程--asynico.Lock(*,loop=None) 线程--threading.Lock(value=1) 进程--multiprocessing.Lock([value]) 在协程中,实际上协程并没有抢占资源的情况,因此此处的锁更多的是用来作为一个全局的变量锁定一些流程用 import asyncio import functools def unlock(lock): print('callback releasing lock') lock.release() async def test(locker, lock): print('{} waiting for the lock'.format(locker)) with await lock: print('{} acquired lock'.format(locker)) print('{} released lock'.format(locker)) async def main(loop): lock = asyncio.Lock() await lock.acquire() loop.call_later(0.1, functools.partial(unlock, lock)) await asyncio.wait([test('l1', lock), test('l2', lock)]) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main(loop)) loop.close() l1 waiting for the lock l2 waiting for the lock callback releasing lock l1 acquired lock l1 released lock l2 acquired lock l2 released lock 而针对于多进程,锁同样起到一个全局信号的作用,比如多个进程处理同一个文件,就需要加锁来限制 %%writefile src/lock.py import multiprocessing import sys def worker_with(lock, f): with lock: with open(f,\"a+\") as fs: fs.write('Lock acquired via with\\n') if __name__ == '__main__': f = \"source/file.txt\" lock = multiprocessing.Lock() w = multiprocessing.Process(target=worker_with, args=(lock, f)) w.start() w.join() Writing src/lock.py !python src/lock.py 事件 一个过程发送/传递事件，所谓事件是指的一个保存标记状态的对象,如果内部标记为True则表示事件发生了,反之就是没发生 事件的接口包括: clear() 事件内部标记为False is_set() 返回事件的内部标记 set() 调用则设置内部标记为True wait() 等待事件被标记为True,协程中该接口为协程 另外的过程等待事件的触发。我们用「生产者/消费者」模型的例子. 协程 import asyncio import random async def produce(event, n): for x in range(1, n + 1): # produce an item print('producing {}/{}'.format(x, n)) # simulate i/o operation using sleep await asyncio.sleep(random.random()) l.append(x) event.set() async def consume(event): while True: item = await event.wait() if item == False: break integer = l.pop() print('{} popped from list '.format(integer)) event.clear() await asyncio.sleep(random.random()) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) l = [] event = asyncio.Event(loop=loop) producer_coro = produce(event, 10) consumer_coro = consume(event) loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) loop.close() producing 1/10 producing 2/10 1 popped from list producing 3/10 2 popped from list producing 4/10 3 popped from list producing 5/10 4 popped from list producing 6/10 5 popped from list producing 7/10 6 popped from list producing 8/10 7 popped from list producing 9/10 8 popped from list producing 10/10 10 popped from list --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) in () 33 producer_coro = produce(event, 10) 34 consumer_coro = consume(event) ---> 35 loop.run_until_complete(asyncio.gather(producer_coro, consumer_coro)) 36 loop.close() ~/LIB/CONDA/anaconda/lib/python3.6/asyncio/base_events.py in run_until_complete(self, future) 452 future.add_done_callback(_run_until_complete_cb) 453 try: --> 454 self.run_forever() 455 except: 456 if new_task and future.done() and not future.cancelled(): ~/LIB/CONDA/anaconda/lib/python3.6/asyncio/base_events.py in run_forever(self) 419 events._set_running_loop(self) 420 while True: --> 421 self._run_once() 422 if self._stopping: 423 break ~/LIB/CONDA/anaconda/lib/python3.6/asyncio/base_events.py in _run_once(self) 1387 timeout * 1e3, dt * 1e3) 1388 else: -> 1389 event_list = self._selector.select(timeout) 1390 self._process_events(event_list) 1391 ~/LIB/CONDA/anaconda/lib/python3.6/selectors.py in select(self, timeout) 575 ready = [] 576 try: --> 577 kev_list = self._kqueue.control(None, max_ev, timeout) 578 except InterruptedError: 579 return ready KeyboardInterrupt: import time import asyncio from random import randint,choice TIMEOUT = 2 async def consumer(name,event, l): if await event.wait(): try: integer = l.pop() print('{} popped from list by {}'.format(integer, name)) event.clear() # 重置事件状态 except IndexError: # 为了让刚启动时容错 pass async def producer(): for i in range(1,10): interger = randint(10, 100) yield interger async def main(): event = asyncio.Event() l = [] async for i in producer(): l.append(i) print('{} appended to list '.format(i)) event.set() # 设置事件 consumers = [consumer( name,event ,l) for _, name in enumerate(('c1', 'c2'))] await choice(consumers) await asyncio.sleep(1) loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main()) loop.close() 17 appended to list 17 popped from list by c1 11 appended to list 11 popped from list by c2 /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:29: RuntimeWarning: coroutine 'consumer' was never awaited 40 appended to list 40 popped from list by c2 79 appended to list 79 popped from list by c1 99 appended to list 99 popped from list by c1 98 appended to list 98 popped from list by c2 86 appended to list 86 popped from list by c1 16 appended to list 16 popped from list by c2 77 appended to list 77 popped from list by c1 /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/asyncio/events.py:126: RuntimeWarning: coroutine 'consumer' was never awaited self._callback(*self._args) 线程 import time import threading from random import randint TIMEOUT = 2 def consumer(event, l): t = threading.currentThread() while 1: try: event_is_set = event.wait(TIMEOUT) except Exception as e: print(e) break if event_is_set: try: integer = l.pop() print('{} popped from list by {}'.format(integer, t.name)) event.clear() # 重置事件状态 except IndexError: # 为了让刚启动时容错 pass else: break def producer(event, l): t = threading.currentThread() for i in range(10): integer = randint(10, 100) l.append(integer) print('{} appended to list by {}'.format(integer, t.name)) event.set() # 设置事件 time.sleep(1) event = threading.Event() l = [] threads = [] for name in ('consumer1', 'consumer2'): t = threading.Thread(name=name, target=consumer, args=(event, l)) t.start() threads.append(t) p = threading.Thread(name='producer1', target=producer, args=(event, l)) p.start() threads.append(p) for t in threads: t.join() 64 appended to list by producer1 64 popped from list by consumer1 86 appended to list by producer1 86 popped from list by consumer2 82 appended to list by producer1 82 popped from list by consumer1 63 appended to list by producer1 63 popped from list by consumer2 15 appended to list by producer1 15 popped from list by consumer1 77 appended to list by producer1 77 popped from list by consumer2 96 appended to list by producer1 96 popped from list by consumer1 60 appended to list by producer1 60 popped from list by consumer2 20 appended to list by producer1 20 popped from list by consumer1 15 appended to list by producer1 15 popped from list by consumer2 条件Condition 条件用于信号通信,它的除了拥有锁的所有接口外,还有接口: notify(n=1) 释放出通知,让使用相同Condition对象的几个过程知道这个条件已被激活 notify_all() 释放出通知,让使用相同Condition对象的所有过程知道这个条件已被激活 wait() 等待使用相同Condition对象的过程的通知. wait_for(predicate) 相当于 while not predicate(): cv.wait() 一个过程等待特定条件，而另一个过程发出特定条件满足的信号。最好说明的例子就是「生产者/消费者」模型： 协程方式 import asyncio import functools async def consumer(cond, name, second): await asyncio.sleep(second) async with cond: await cond.wait() print('{}: Resource is available to consumer'.format(name)) async def producer(cond): await asyncio.sleep(2) async with cond: print('Making resource available') cond.notify_all() async def main(loop): condition = asyncio.Condition() task = loop.create_task(producer(condition)) consumers = [consumer(condition, name, index) for index, name in enumerate(('c1', 'c2'))] await asyncio.wait(consumers) task.cancel() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(main(loop)) loop.close() Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 线程方式 import time import threading def consumer(cond): t = threading.currentThread() with cond: cond.wait() # wait()方法创建了一个名为waiter的锁， #并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 print('{}: Resource is available to consumer'.format(t.name)) def producer(cond): t = threading.currentThread() with cond: print('{}: Making resource available'.format(t.name)) cond.notify_all() # 释放waiter锁，唤醒消费者 condition = threading.Condition() c1 = threading.Thread(name='c1', target=consumer, args=(condition,)) c2 = threading.Thread(name='c2', target=consumer, args=(condition,)) p = threading.Thread(name='p', target=producer, args=(condition,)) c1.start() time.sleep(1) c2.start() time.sleep(1) p.start() p: Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 进程方式 %%writefile src/cond.py import time import multiprocessing def consumer(cond): t = multiprocessing.current_process() with cond: cond.wait() # wait()方法创建了一个名为waiter的锁， #并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 print('{}: Resource is available to consumer'.format(t.name)) def producer(cond): t = multiprocessing.current_process() with cond: print('{}: Making resource available'.format(t.name)) cond.notify_all() # 释放waiter锁，唤醒消费者 if __name__=='__main__': condition = multiprocessing.Condition() c1 = multiprocessing.Process(name='c1', target=consumer, args=(condition,)) c2 = multiprocessing.Process(name='c2', target=consumer, args=(condition,)) p = multiprocessing.Process(name='p', target=producer, args=(condition,)) c1.start() time.sleep(1) c2.start() time.sleep(1) p.start() Writing src/cond.py !python src/cond.py p: Making resource available c1: Resource is available to consumer c2: Resource is available to consumer 队列 使用队列是最常见的同步方式.也是生产者消费者模式最常见使用的工具 队列的接口有: qsize() 返回队列的大致大小 empty() 如果队列为空返回True full() 如果队列满了,则返回空 put(item, block=True, timeout=None) 将元素放入队列,协程中是协程 put_nowait(item) 立即将元素放入队列 get(block=True, timeout=None) 获取元素,并且在队列中删除该元素,协程中是协程 get_nowait() 立即获取元素,并且在队列中删除该元素 task_done() 表明以前入队的任务是否已经完成。 join() 阻塞直到队列中的所有项目都被获取和处理.协程中是协程 常见的队列有两种: queue 先进先出队列 LifoQueue 先进后出队列 PriorityQueue 优先权队列,放入的元素必须是Tuple[int,Any],第一位就是权重 对不同方式使用的队列为: 协程--asyncio.Queue(maxsize) 线程--queue.Queue(maxsize) 进程--multiprocessing.Queue(maxsize) 依然用生产消费模式做例子 协程 import asyncio import random def double(n): return n * 2 async def producer(queue, n): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) await queue.put((pri, double, pri)) # (priority, func, args) count += 1 async def consumer(queue): while True: pri, task, arg = await queue.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) await asyncio.sleep(random.random()) queue.task_done() async def run(n): queue = asyncio.PriorityQueue(10) # schedule the consumer consume = asyncio.ensure_future(consumer(queue)) # run the producer and wait for completion await producer(queue, n) # wait until the consumer has processed all items await queue.join() # the consumer is still awaiting for an item, cancel it consume.cancel() loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_until_complete(run(10)) loop.close() put :44 put :9 put :74 put :95 put :48 put :76 [PRI:9] 9 * 2 = 18 [PRI:44] 44 * 2 = 88 [PRI:48] 48 * 2 = 96 [PRI:74] 74 * 2 = 148 [PRI:76] 76 * 2 = 152 [PRI:95] 95 * 2 = 190 线程 import time import threading from random import randint from queue import PriorityQueue q = PriorityQueue(10) def double(n): return n * 2 def producer(): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) q.put((pri, double, pri)) # (priority, func, args) count += 1 def consumer(): while True: if q.empty(): break pri, task, arg = q.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) q.task_done() time.sleep(0.1) t = threading.Thread(target=producer) t.start() time.sleep(1) t = threading.Thread(target=consumer) t.start() put :88 put :93 put :87 put :51 put :92 put :44 [PRI:44] 44 * 2 = 88 [PRI:51] 51 * 2 = 102 [PRI:87] 87 * 2 = 174 [PRI:88] 88 * 2 = 176 [PRI:92] 92 * 2 = 184 [PRI:93] 93 * 2 = 186 进程 import time from multiprocessing import Process from random import randint from multiprocessing import JoinableQueue q = JoinableQueue(10) def double(n): return n * 2 def producer(): count = 0 while True: if count > 5: break pri = randint(0, 100) print('put :{}'.format(pri)) q.put((pri, double, pri)) # (priority, func, args) count += 1 def consumer(): while True: if q.empty(): break pri, task, arg = q.get() print('[PRI:{}] {} * 2 = {}'.format(pri, arg, task(arg))) q.task_done() time.sleep(0.1) t = Process(target=producer) t.start() time.sleep(1) t = Process(target=consumer) t.start() put :86 put :5 put :99 put :96 put :86 put :16 [PRI:86] 86 * 2 = 172 [PRI:5] 5 * 2 = 10 [PRI:99] 99 * 2 = 198 [PRI:96] 96 * 2 = 192 [PRI:86] 86 * 2 = 172 [PRI:16] 16 * 2 = 32 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 21:53:25 "},"流程控制/使用sqlite3共享内存.html":{"url":"流程控制/使用sqlite3共享内存.html","title":"使用sqlite3共享内存","keywords":"","body":"使用sqlite3共享内存 多进程程序往往碰到一个问题:数据共享问题.这也是本文的主题. 简单介绍sqlite3 sqlite3是一个非常伟大的关系型数据库,可能很多人不太熟悉.人言关系型数据库一般都是mysql,MS Sqlserver,Oracle,但其实sqlite同样是非常出色的关系型数据库. 从代码的角度讲,sqlite堪称教科书般的C语言编程示例(一般也是作为学习C语言的参考代码). 从性能角度讲,sqlite因为是基于磁盘io的,所以基于socket的数据库性能与他完全不能相比.它更有内存模式,比起磁盘模式更加快速. 从用途来讲,sqlite3编译后非常小,可以放入资源十分有限的嵌入式设备中,光这一点其他数据库就无法做到.在追求高时效性的任务中可以使用内存模式当作内存数据库使用. 从使用范围来讲,只要是嵌入式设备,包括手机,一些物联网终端在内,都有使用.它不光可以用在服务器上也可以用在客户端作为缓存.连html5都有对其的阉割支持(虽然已经被废弃). sqlite最大的缺点同样来自于它基于磁盘而非socket.这一特点让它不适合作为数据存储的中心节点.不过sqlite3非常适合微服务架构,因为它是自治的,并且利于迁移(一个文件拷贝走就是了),如果项目的数据增量比较可控,并且对实时性有较高要求完全可以使用sqlite3. python的标准库中内置了sqlite3支持.基本上只要装了python就可以使用sqlite3.并且,sqlite3使用的是python通用的数据库接口设计,一通百通,会用它就会用其他的数据库接口 连接数据库 import sqlite3 conn = sqlite3.connect('test.db') 创建表格 数据库的操作使用游标(cursor)实现.游标对象有execute方法用来将sql语句输入到连接中,之后再调用连接的commit方法将sql语句上传到数据库进行操作. c = conn.cursor() c.execute('''CREATE TABLE COMPANY (ID INT PRIMARY KEY NOT NULL, NAME TEXT NOT NULL, AGE INT NOT NULL, ADDRESS CHAR(50), SALARY REAL);''') conn.commit() 插入数据 c = conn.cursor() c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (1, 'Paul', 32, 'California', 20000.00 )\"); c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (2, 'Allen', 25, 'Texas', 15000.00 )\"); c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (3, 'Teddy', 23, 'Norway', 20000.00 )\"); c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (4, 'Mark', 25, 'Rich-Mond ', 65000.00 )\"); conn.commit() 查询 c = conn.cursor() cursor = c.execute(\"SELECT id, name, address, salary from COMPANY\") for row in cursor: print(\"ID = \", row[0]) print(\"NAME = \", row[1]) print(\"ADDRESS = \", row[2]) print(\"SALARY = \", row[3], \"\\n\") ID = 1 NAME = Paul ADDRESS = California SALARY = 20000.0 ID = 2 NAME = Allen ADDRESS = Texas SALARY = 15000.0 ID = 3 NAME = Teddy ADDRESS = Norway SALARY = 20000.0 ID = 4 NAME = Mark ADDRESS = Rich-Mond SALARY = 65000.0 更新 c = conn.cursor() c.execute(\"UPDATE COMPANY set SALARY = 25000.00 where ID=1\") conn.commit() print(\"Total number of rows updated :\", conn.total_changes) cursor = conn.execute(\"SELECT id, name, address, salary from COMPANY\") for row in cursor: print(\"ID = \", row[0]) print(\"NAME = \", row[1]) print(\"ADDRESS = \", row[2]) print(\"SALARY = \", row[3], \"\\n\") Total number of rows updated : 5 ID = 1 NAME = Paul ADDRESS = California SALARY = 25000.0 ID = 2 NAME = Allen ADDRESS = Texas SALARY = 15000.0 ID = 3 NAME = Teddy ADDRESS = Norway SALARY = 20000.0 ID = 4 NAME = Mark ADDRESS = Rich-Mond SALARY = 65000.0 替换 c = conn.cursor() c.execute(\"REPLACE INTO COMPANY (ID, NAME, AGE, ADDRESS, SALARY) VALUES ('2', 'Allen', 'Texas', '123456@qq.com', 16000.0 );\") conn.commit() print(\"Total number of rows updated :\", conn.total_changes) cursor = conn.execute(\"SELECT id, name, address, salary from COMPANY\") for row in cursor: print(\"ID = \", row[0]) print(\"NAME = \", row[1]) print(\"ADDRESS = \", row[2]) print(\"SALARY = \", row[3], \"\\n\") Total number of rows updated : 6 ID = 1 NAME = Paul ADDRESS = California SALARY = 25000.0 ID = 3 NAME = Teddy ADDRESS = Norway SALARY = 20000.0 ID = 4 NAME = Mark ADDRESS = Rich-Mond SALARY = 65000.0 ID = 2 NAME = Allen ADDRESS = 123456@qq.com SALARY = 16000.0 删除 c = conn.cursor() c.execute(\"DELETE from COMPANY where ID=2;\") conn.commit() print(\"Total number of rows deleted :\", conn.total_changes) cursor = conn.execute(\"SELECT id, name, address, salary from COMPANY\") for row in cursor: print(\"ID = \", row[0]) print(\"NAME = \", row[1]) print(\"ADDRESS = \", row[2]) print(\"SALARY = \", row[3], \"\\n\") Total number of rows deleted : 7 ID = 1 NAME = Paul ADDRESS = California SALARY = 25000.0 ID = 3 NAME = Teddy ADDRESS = Norway SALARY = 20000.0 ID = 4 NAME = Mark ADDRESS = Rich-Mond SALARY = 65000.0 断开连接 conn.close() 内存模式 sqlite可以使用缓存模式,用法很简单,就是把db文件位置的字符串改为\":memory:\".不过注意这种方式并不能共享内存,它相当于每个连接独立在内存中存储数据.一旦断开数据就被释放了. 线程安全问题 sqlite默认是线程安全的,它在同一个时间只会有一次commit在访问数据.而其他的commit则在外面被阻塞着.如果要去掉阻塞,可以在连接时指定check_same_thread为False.当然了,这样的话线程安全就得手工管理了. 缓存模式用于多线程 如果要让内存用于多线程,那么就要共享缓存.python的sqlite3接口没有对应的参数.但3.4新增的参数uri可以实现这个功能 不同连接使用内存数据库的示例 (来自stack overflow) 可以看到db1和db2连接的是同一个名字的数据库foobar_database.他们一个创建表一个插入数据.最终都可以访问到.这就为多个进程访问共同的内存数据提供了支持 import sqlite3 foobar_uri = 'file:foobar_database?mode=memory&cache=shared' not_really_foobar_uri = 'file:not_really_foobar?mode=memory&cache=shared' # connect to databases in no particular order db2 = sqlite3.connect(foobar_uri, uri=True) db_lol = sqlite3.connect(not_really_foobar_uri, uri=True) db1 = sqlite3.connect(foobar_uri, uri=True) # create cursor as db2 cur2 = db2.cursor() cur1 = db1.cursor() # create table as db2 db2.execute('CREATE TABLE foo (NUMBER bar)') # insert values as db1 db1.execute('INSERT INTO foo VALUES (42)') db1.commit() # and fetch them from db2 through cur2 cur2.execute('SELECT * FROM foo') print(cur2.fetchone()[0]) # 42 cur1.execute('SELECT * FROM foo') print(cur1.fetchone()[0]) # 42 # test that db_lol is not shared with db1 and db2 try: db_lol.cursor().execute('SELECT * FROM foo') except sqlite3.OperationalError as exc: print(exc) # just as expected db2.close() db1.close() 42 42 no such table: foo sqlite3.sqlite_version_info (3, 14, 2) 多线程共享内存数据库 import os, time import sqlite3 import threading def write(name): print(\"write db in\",name) import sqlite3 foobar_uri = 'file:foobar_database?mode=memory&cache=shared' conn = sqlite3.connect(foobar_uri, uri=True) c = conn.cursor() c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (3, 'Teddy', 23, 'Norway', 20000.00 )\"); c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (4, 'Mark', 25, 'Rich-Mond ', 65000.00 )\"); conn.commit() conn.close() print(\"write db done\") def main(): foobar_uri = 'file:foobar_database?mode=memory&cache=shared' conn = sqlite3.connect(foobar_uri, uri=True) c = conn.cursor() c.execute('''CREATE TABLE COMPANY (ID INT PRIMARY KEY NOT NULL, NAME TEXT NOT NULL, AGE INT NOT NULL, ADDRESS CHAR(50), SALARY REAL);''') conn.commit() c = conn.cursor() c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (1, 'Paul', 32, 'California', 20000.00 )\"); c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\ VALUES (2, 'Allen', 25, 'Texas', 15000.00 )\"); conn.commit() pr = threading.Thread(target=write,args=(\"write Thread\",)) pr.start() pr.join() print(\"read db\") c = conn.cursor() cursor = conn.execute(\"SELECT id, name, address, salary from COMPANY\") for row in cursor: print(\"ID = \", row[0]) print(\"NAME = \", row[1]) print(\"ADDRESS = \", row[2]) print(\"SALARY = \", row[3], \"\\n\") conn.close() main() write db in write Thread write db done read db ID = 1 NAME = Paul ADDRESS = California SALARY = 20000.0 ID = 2 NAME = Allen ADDRESS = Texas SALARY = 15000.0 ID = 3 NAME = Teddy ADDRESS = Norway SALARY = 20000.0 ID = 4 NAME = Mark ADDRESS = Rich-Mond SALARY = 65000.0 sqlite3用于多进程 sqlite3的内存模式并不支持多进程,不过如果使用linux,那么就可以简单的让sqlite3直接使用RAM而不用通过文件io. 这种方式比较鸡贼.不光是sqlite,其他的文件也可以这样使用. linux中有/dev/shm目录,这个目录不在硬盘上而在内存上,所以如果将sqlite3的数据库文件放在这上面,那就可以像正常那样多进程使用内存中的sqlite数据库了. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-10-23 21:29:04 "},"流程控制/结语.html":{"url":"流程控制/结语.html","title":"结语","keywords":"","body":"结语 python协程的现状 有很长一段时间,大多数Python高手开发网络应用时喜欢使用异步编程,但是总会遇到一个问题——挑选的库之间不兼容。 Twisted 是 Node.js 的灵感来源之一;而在 Python 中,Tornado 拥护使用协程做面向事件编程;同时第三方的协程库gevent,eventlet,greenlet等由于简单好用也长期存在并发展迅速.直到python3.5之前我都是gevent的忠实用户. 在 JavaScript 社区里还有争论,有些人推崇使用简单的回调,而有些人提倡使用与回调处于竞争地位的各种高层抽象方式.Node.js早期版本的API使用的是Promise对象(类似于Python中的期物),但是后来Ryan Dahl决定统一只用回调. Python社区的争论已经结束: asyncio包添加到标准库中之后,协程和期物被确定为符合 Python 风格的异步代码编写方式。此外,asyncio包为异步期物和事件循环定义了标准接口,为二者提供了实现参考。 正如\"Python 之禅\"所说: 肯定有一种——通常也是唯一一种——最佳的解决方案 python的协程工具一开始并不易于理解,不过一段时间之后我理解了。 更重要的是,设计asyncio包时考虑到了使用外部包替换自身的事件循环,因此才有 asyncio.get_event_loop 和 set_event_loop 函数——二者是抽象的事件循环策略. Tornado 已经有实现 asyncio.AbstractEventLoop 接口的类——AsyncIOMainLoop,因此在同一个事件循环中可以使用这两 个库运行异步代码。此外,Quamash项目也很有趣,它把asyncio包集成到Qt事件循环中,以便使用PyQt或PySide开发GUI应用.我只是举两个例子,说明asyncio包能把面向事件的包集成在一起。 智能的HTTP客户端,例如单页Web应用(如Gmail)或智能手机应用,需要快速、轻量级的响应和推送更新。鉴于这样的需求,服务器端最好使用异步框架,不要使用传统的Web框架(如Django).传统框架的目的是渲染完整的 HTML 网页,而且不支持异步访问数据库。 WebSockets协议的作用是为始终连接的客户端(例如游戏和流式应用)提供实时更新,因此,高并发的异步服务器要不间断地与成百上千个客户端交互.asyncio包的 架构能很好地支持WebSockets,而且至少有两个库已经在asyncio包的基础上实现了WebSockets协议: Autobahn|Python WebSockets '实时 Web'的整体发展趋势迅猛,这是Node.js需求量不断攀升的主要因素,也是 Python 生态系统积极向asyncio靠拢的重要原因.不过,要做的事还有很多.为了便于入门,我们要在标准库中提供异步HTTP服务器和客户端API,异步数据库API 3.0,以及使用asyncio包构建的新数据库驱动. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-13 23:06:35 "},"数据结构与算法/":{"url":"数据结构与算法/","title":"数据结构与算法","keywords":"","body":"数据结构预算法 python是重视用户体验的语言,它提供了简单好用的数据结构而忽视了数据结构的效率. 然而这并不代表它们就不好用,恰恰相反,这提高了开发效率,python语言的一致性也给更加高效的用c 语言写的数据结构可以方便的替代默认的数据结构. 序列对象 映射对象 可迭代对象与生成器 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 00:39:00 "},"数据结构与算法/序列对象.html":{"url":"数据结构与算法/序列对象.html","title":"序列对象","keywords":"","body":"序列对象的范畴 Python标准库用C语言实现了丰富的序列类型,从底层实现的角度来分类,可以分为容器序列和扁平序列.列举如下. 容器序列 list、tuple 和 collections.deque这些序列能存放异构(不同类型的)数据.本质上存储的内容是引用,关于引用,可以看python数据模型部分的相关介绍. 扁平序列 str、bytes、bytearray、memoryview ,array.array 以及准标准库numpy.array.这类序列只能容纳同构(同一种类型的)数据. 容器序列存放的是它们所包含的任意类型的对象的引用,而扁平序列里存放的是值而不是引用.换句话说,扁平序列其实是一段连续的内存空间. 由此可见扁平序列其实更加紧凑,但是它里面只能存放诸如字符、字节和数值这种基础类型. 序列类型还能按照能否被修改来分类: 可变序列MutableSequence list、bytearray、array.array、collections.deque和memoryview. 不可变序列Sequence tuple、str、bytes和numpy.ndarray 下图显示了可变序列和不可变序列的差异,同时也 能看出前者从后者那里继承了一些方法.虽然内置的序列类型并不是直接从Sequence和 MutableSequence这两个抽象基类继承而来的.但是了解这些基类可以帮助我们总结出那些完整的序列类型包含了哪些功能: 扁平序列内置类型相关的操作可以看文本文件与字节序相关的内容. 而numpy数组可以看我的这篇文章 序列操作 python是高度一致性理念下的产物,它的序列很能够体现这一特点.不同类型的序列虽然特性不同,但都满足一致的接口协议,因此有着一致的行为.了解序列操作只要了解这些接口协议即可 只要满足Iterable,我们的序列就可以使用for循环遍历 for i in (1,2,3,4,5): print(i) 1 2 3 4 5 只要满足Sized我们的序列就可以使用len内置方法求取序列的长度 len((1,2,3,4,5)) 5 只要满足Container我们的序列就可以使用in语句判断元素是否在序列中 1 in (1,2,3,4,5) True 只要满足Sequence我们就可以使用切片操作,翻转序列,使用count方法和index方法 切片操作 python用[]来取值和切片,它对应的魔术方法是__getitem__. python内置类型有一套非常便捷的切片逻辑 取位 比如[1]代表取第一位的值(序列中为第2个元素).[-1]代表最后一个元素 (1,2,3,4,5)[0] 1 切片 而当[]中有两个被:分割开得数时就成了切片,比如[2:4]代表取从第2位到第3位的元素组成一个与原来序列相同类型的新序列,:分隔的两边可以没有指定,意味头尾元素,后一位可以为负数,意为倒着数 (1,2,3,4,5)[:-2] (1, 2, 3) 按步长切片 而当[]中有三个被:分割开得数时就成了切片,比如[0:4:2]代表每2个元素从第0位到第3位取出组成一个与原来序列相同类型的新序列,第二位可以为负数,意为倒着数,最后一位可以为负数,意味从尾到头获取. (1,2,3,4,5)[:-4:-2] (5, 3) count计算元素在序列中出现的次数 (1,2,3,4,5,2).count(2) 2 reversed翻转序列 翻转序列操作返回的是一个可迭代对象并非序列 tuple(reversed((1,2,3,4,5,2))) (2, 5, 4, 3, 2, 1) 只要满足MutableSequence我们就可以使用insert,append,pop,extend,remove操作 list.append(obj) 在列表末尾添加新的对象 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） list.insert(index, obj) 将对象插入列表 list.pop(obj=list[-1]) 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 list.remove(obj) 移除列表中某个值的第一个匹配项 对序列使用+,*,+=,*= Python的内置序列类型会默认支持+ 和* 操作的.+和*分别对应特殊方法__add__和__mul__ 通常+号两侧的序列由相同类型的数据所构成,在拼接的过程中,两个被操作的序列都不会被修改,Python 会新建一个包含同样类型数据的序列来作为拼接的结果. 如果想要把一个序列复制几份然后再拼接起来,更快捷的做法是把这个序列乘以一个整数.同样,这个操作会产生一个新序列： +和*都遵循这个规律，不修改原有的操作对象，而是构建一个全新的序列。 l = (1, 2, 3) l * 5 (1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3) 5 * 'abcd' 'abcdabcdabcdabcdabcd' 增量赋值运算符+= 和*= 的表现取决于它们的第一个操作对象.简单起见，我们把讨论集中在增量加法（+=）上，但是这些概念对*= 和其他增量运算符来说都是一样的.+= 背后的特殊方法是__iadd__（用于“就地加法”）.但是如果一个类没有实现这个方法的话，Python 会退一步调用__add__。考虑下面这个简单的表达式： a += b 如果a 实现了__iadd__ 方法， 就会调用这个方法。同时对可变序列（例如list、bytearray 和array.array）来说,a会就地改动，就像调用了a.extend(b)一样。但是如果a没有实现__iadd__的话，a += b 这个表达式的效果就变得跟a = a + b 一样了： 首先计算a + b，得到一个新的对象 然后赋值给a 也就是说，在这个表达式中，变量名会不会被关联到新的对象，完全取决于这个类型有没有实现__iadd__ 这个方法。 总体来讲，可变序列一般都实现了__iadd__ 方法，因此+= 是就地加法.而不可变序列根本就不支持这个操作,对这个方法的实现也就无从谈起. 上面所说的这些关于+= 的概念也适用于*=，不同的是，后者相对应的是__imul__. 列表list 最重要也最基础的序列类型应该就是列表(list)了.list是一个可变序列,并且能同时存放不同类型的元素.本质上list就是类似c++中vector的数据结构.因此它的效率并不高.list是单向序列,因此使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了. list是线性存储，数据量大的时候，插入和删除效率很低. 列表的构造函数是list(*items),python中也可以使用[]来构造 列表推导 所谓列表解析就是在列表中写入代码段,吧代码段生成的结果放入列表中.列表解析除了支持使用for循环构建列表,也支持使用if筛选数据 [i for i in range(10)] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [i for i in range(10) if i%2==0] [0, 2, 4, 6, 8] 双向队列deque collections.deque是一个是一个线程安全,高效实现插入和删除操作的双向列表，适合用于队列和栈 deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素. from collections import deque q = deque(['a', 'b', 'c']) q.append('x') q.appendleft('y') q deque(['y', 'a', 'b', 'c', 'x']) 如果想要有一种数据类型来存放“最近用到的几个元素”，deque 也是一个很好的选择。这是因为在新建一个双向队列的时候，你可以指定这个队列的大小，如果这个队列满员了，还可以从反向端删除过期的元素，然后在尾端添加新的元素. 双向队列也付出了一些代价，从队列中间删除元素的操作会慢一些，因为它只对在头尾的操作进行了优化 dq = deque(range(10), maxlen=10) dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) q.rotate(3)#队列的旋转操作接受一个参数n，当n > 0 时， #队列的最右边的n 个元素会被移动到队列的左边。当n dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) dq.rotate(-4) dq deque([4, 5, 6, 7, 8, 9, 0, 1, 2, 3]) dq.extend([11, 22, 33]) dq deque([7, 8, 9, 0, 1, 2, 3, 11, 22, 33]) dq.extendleft([10, 20, 30, 40]) dq deque([40, 30, 20, 10, 7, 8, 9, 0, 1, 2]) 除了deque之外，还有些其他的Python 标准库也有对队列的实现。 queue 提供了同步（线程安全）类Queue、LifoQueue 和PriorityQueue，不同的线程可以利用这些数据类型来交换信息。这三个类的构造方法都有一个可选参数maxsize，它接收正整数作为输入值，用来限定队列的大小。但是在满员的时候，这些类不会扔掉旧的元素来腾出位置。相反，如果队列满了，它就会被锁住，直到另外的线程移除了某个元素而腾出了位置。这一特性让这些类很适合用来控制活跃线程的数量。 multiprocessing.Queue 这个包实现了自己的Queue，它跟queue.Queue 类似，是设计给进程间通信用的。同时还有一个专门的multiprocessing.JoinableQueue 类型，可以让任务管理变得更方便。 asyncio.Queue Python 3.4 新提供的包，里面有Queue、LifoQueue、PriorityQueue 和JoinableQueue，这些类受到queue 和multiprocessing 模块的影响，但是为异步编程里的任务管理提供了专门的便利。 以上的队列基本都是为并行计算设计的,会在流程控制部分细讲 heapq堆 跟上面三个模块不同的是，heapq 没有队列类，而是提供了heappush 和heappop 方法，让用户可以把可变序列当作堆队列或者优先队列来使用。 import heapq import heapq class PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1] class Item: def __init__(self, name): self.name = name def __repr__(self): return 'Item({!r})'.format(self.name) q = PriorityQueue() q.push(Item('foo'), 1) q.push(Item('bar'), 5) q.push(Item('spam'), 4) q.push(Item('grok'), 1) q.pop() Item('bar') q.pop() Item('spam') 元组tuple 元组是不可变序列,构造函数为tuple(seq),也可以使用(,)来快速构建. 元组如果保存元素都不是容器,那么元组就是真正的不可变的,否则还是会根据内部元素的改变而改变. 具名元组 collections.namedtuple是一个工厂函数，它可以用来构建一个带字段名的元组和一个有名字的类——这个带名字的类对调试程序有很大帮助. 用namedtuple构建的类的实例所消耗的内存跟元组是一样的,因为字段名都被存在对应的类里面.这个实例跟普通的对象实例比起来也要小一些，因为Python不会用__dict__来存放这些实例的属性。 from collections import namedtuple City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) tokyo City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139.691667)) tokyo.population 36.933 除了从普通元组那里继承来的属性之外，具名元组还有一些自己专有的属性。下面的例子展示了几个最有用的： _fields 类属性 _fields属性是一个包含这个类所有字段名称的元组。 City._fields ('name', 'country', 'population', 'coordinates') 类方法_make(iterable) _make()通过接受一个可迭代对象来生成这个类的一个实例 LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889)) delhi = City._make(delhi_data) 实例方法_asdict() _asdict()把具名元组以collections.OrderedDict 的形式返回，我们可以利用它来把元组里的信息友好地呈现出来 delhi._asdict() OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))]) for key, value in delhi._asdict().items(): print(key + ':', value) name: Delhi NCR country: IN population: 21.935 coordinates: LatLong(lat=28.613889, long=77.208889) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 00:31:30 "},"数据结构与算法/映射对象.html":{"url":"数据结构与算法/映射对象.html","title":"映射对象","keywords":"","body":"映射和集合对象的范畴 python中的映射类型分为两类: 可变映射 不可变映射 python目前的内建映射包括dict,defaultdict ,OrderedDict,集合包括set和frozenset,其中都是可变映射 字典类型不但在各种程序里广泛使用，它也是Python语言的基石。模块的命名空间、实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在__builtins__.__dict__模块中. 正是因为字典至关重要，Python对它的实现做了高度优化，而散列表则是字典类型性能出众的根本原因. 集合(set)的实现其实也依赖于散列表,因此映射类型的关键就在于理解散列表的原理。 dict的实现的优缺点 下面的内容会讨论使用散列表给dict 带来的优势和限制都有哪些。 键必须是可散列的 一个可散列的对象必须满足以下要求。 支持hash()函数，并且通过__hash__()方法所得到的散列值是不变的。 支持通过__eq__()方法来检测相等性。 若a == b为真，则hash(a) == hash(b)也为真. 键的次序取决于添加顺序 当往dict 里添加新键而又发生散列冲突的时候，新键可能会被安排存放到另一个位置。于是下面这种情况就会发生：由dict([key1, value1), (key2, value2)] 和dict([key2,value2], [key1, value1]) 得到的两个字典，在进行比较的时候，它们是相等的；但是如果在key1 和key2被添加到字典里的过程中有冲突发生的话，这两个键出现在字典里的顺序是不一样的. 往字典里添加新键可能会改变已有键的顺序 无论何时往字典里添加新的键，Python 解释器都可能做出为字典扩容的决定。扩容导致的结果就是要新建一个更大的散列表，并把字典里已有的元素添加到新表里。这个过程中可能会发生新的散列冲突，导致新散列表中键的次序变化。要注意的是，上面提到的这些变化是否会发生以及如何发生，都依赖于字典背后的具体实现，因此你不能很自信地说自己知道背后发生了什么。如果你在迭代一个字典的所有键的过程中同时对字典进行修改，那么这个循环很有可能会跳过一些键——甚至是跳过那些字典中已经有的键。由此可知，不要对字典同时进行迭代和修改。如果想扫描并修改一个字典，最好分成两步来进行：首先对字典迭代，以得出需要添加的内容，把这些内容放在一个新字典里；迭代结束之后再对原有字典进行更新。 键查询很快 dict 的实现是典型的空间换时间：字典类型有着巨大的内存开销，但它们提供了无视数据量大小的快速访问——只要字典能被装在内存里 字典在内存上的开销巨大 由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。举例而言，如果你需要存放数量巨大的记录，那么放在由元组或是具名元组构成的列表中会是比较好的选择；最好不要根据JSON 的风格，用由字典组成的列表来存放这些记录。用元组取代字典就能节省空间的原因有两个： 避免了散列表所耗费的空间， 无需把记录中字段的名字在每个元素里都存一遍 在用户自定义的类型中，__slots__属性可以改变实例属性的存储方式，由dict变成tuple 集合和字典使用的实现类似,因此字典的特点也可以套用在集合中. 常见的映射方法 从UML图中可以看出,与序列对象也是Contaner,也是Sized也是Iterable,而不同之处就是在于Mapping和MutableMapping. 这些接口为字典对象带来了很多实用接口 字典 字典的方法: adict.clear() 删除字典中的所有项或元素； adict.copy() 返回一个字典浅拷贝的副本； adict.fromkeys(seq, val=None) 创建并返回一个新字典，以seq中的元素做该字典的键，val做该字典中所有键对应的初始值（默认为None）； adict.get(key, default = None) 返回字典中key对应的值，若key不存在字典中，则返回default的值（default默认为None）； adict.has_key(key) 如果key在字典中，返回True，否则返回False。 现在用 in 、 not in； adict.items() 返回一个包含所有（键，值）元祖的列表； adict.keys() 返回所有的keys形成的列表 adict.pop(key[,default]) 和get方法相似。如果字典中存在key，删除并返回key对应的vuale；如果key不存在，且没有给出default的值，则引发keyerror异常； adict.popitem() 和pop类似,只是返回一个(key,value)的元组 adict.setdefault(key, default=None) 和set()方法相似，但如果字典中不存在Key键，由 adict[key] = default 为它赋值； adict.update(bdict) 将字典bdict的键值对添加到字典adict中。 adict.values() 返回一个包含字典所有value的列表； 而defaultdict的额外接口为: adict.defaultfactory() 在`_missing `函数中被调用的函数，用以给未找到的元素设置值 d.__missing__(k) 当__getitem__找不到对应键的时候，这个方法会被调用.所有的映射类型在处理找不到的键的时候，都会牵扯到__missing__方法。这也是这个方法称作“missing”的原因。虽然基类dict并没有定义这个方法，但是dict是知道有这么个东西存在的.也就是说,如果有一个类继承了dict，然后这个继承类提供了__missing__方法，那么在__getitem__碰到找不到的键的时候，Python 就会自动调用它，而不是抛出一个KeyError异常。 而OrderedDict与一般字典一样,只是它内部的元素有顺序 字典推导 字典也可以通过字典推导来构建,它需要一个可迭代对象来创建,同样也支持if语句做筛选 {i[0]:i[1] for i in ((\"a\",1),(\"b\",2),(\"c\",3),(\"d\",3))} {'a': 1, 'b': 2, 'c': 3, 'd': 3} 字典的变种 collections标准库中包含两种字典变种 collections.ChainMap 该类型可以容纳数个不同的映射对象，然后在进行键查找操作的时候，这些对象会被当作一个整体被逐个查找，直到键被找到为止。这个功能在给有嵌套作用域的语言做解释器的时候很有用，可以用一个映射对象来代表一个作用域的上下文。 from collections import ChainMap a = {\"a\":1,\"b\":2,\"c\":3} b= {\"q\":1,\"w\":2,\"e\":3} c = ChainMap(a,b) c ChainMap({'a': 1, 'b': 2, 'c': 3}, {'q': 1, 'w': 2, 'e': 3}) for i,k in c.items(): print(i,k) a 1 w 2 q 1 c 3 b 2 e 3 collections.Counter 这个映射类型会给键准备一个整数计数器.每次更新一个键的时候都会增加这个计数器.所以这个类型可以用来给可散列表对象计数,或者是当成多重集来用——多重集合就是集合里的元素可以出现不止一次.Counter实现了+ 和- 运算符用来合并记录，还有像most_common([n])这类很有用的方法most_common([n]) 会按照次序返回映射里最常见的n个键和它们的计数 from collections import Counter a_count = Counter('abracadabra') a_count Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2}) b_count = Counter('abracadabra') b_count Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2}) a_count+b_count Counter({'a': 10, 'b': 4, 'c': 2, 'd': 2, 'r': 4}) 映射的弹性建查询 有时候为了方便起见，就算某个键在映射里不存在，我们也希望在通过这个键读取值的时候能得到一个默认值。有两个途径能帮我们达到这个目的，一个是通过defaultdict 这个类型而不是普通的dict，另一个是给自己定义一个dict 的子类，然后在子类中实现__missing__方法。下面将介绍这两种方法 defaultdict 在用户创建defaultdict 对象的时候，就需要给它配置一个为找不到的键创造默认值的方法。 具体而言，在实例化一个defaultdict的时候，需要给构造方法提供一个可调用对象，这个可调用对象会在__getitem__碰到找不到的键的时候被调用，让__getitem__ 返回某种默认值. 比如，我们新建了这样一个字典：dd = defaultdict(list)，如果键'new-key' 在dd 中还不存在的话，表达式dd['new-key'] 会按照以下的步骤来行事。 调用list() 来建立一个新列表。 把这个新列表作为值，'new-key' 作为它的键，放到dd 中。 返回这个列表的引用。 而这个用来生成默认值的可调用对象存放在名为default_factory 的实例属性里。 创建一个从单词到其出现情况的映射 from collections import defaultdict import re WORD_RE = re.compile(r'\\w+') # 把list 构造方法作为default_factory 来创建一个defaultdict # 如果index 并没有word 的记录，那么default_factory 会被调用，为查询不到的键创造 #一个值。这个值在这里是一个空的列表，然后这个空列表被赋值给index[word]，继而 # 被当作返回值返回，因此.append(location) 操作总能成功。 index = defaultdict(list) line = input(\"输入一句话:\") for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = column_no index[word].append(location) for word in sorted(index, key=str.upper): print(word, index[word]) 输入一句话: 如果在创建defaultdict 的时候没有指定default_factory， 查询不存在的键会触发KeyError defaultdict 里的default_factory只会在__getitem__ 里被调用，在其他的方法里完全不会发挥作用。比如，dd 是个defaultdict，k 是个找不到的键，dd[k] 这个表达式会调用default_factory 创造某个默认值，而dd.get(k)则会返回None 所有这一切背后的功臣其实是特殊方法__missing__。它会在defaultdict 遇到找不到的键的时候调用default_factory，而实际上这个特性是所有映射类型都可以选择去支持的. 特殊方法__missing__ 所有的映射类型在处理找不到的键的时候，都会牵扯到__missing__ 方法。这也是这个方法称作“missing”的原因。虽然基类dict 并没有定义这个方法，但是dict 是知道有这么个东西存在的。也就是说，如果有一个类继承了dict，然后这个继承类提供了__missing__ 方法，那么在__getitem__ 碰到找不到的键的时候，Python 就会自动调用它，而不是抛出一个KeyError 异常。 自定义映射类型 如果要自定义一个映射类型， 更合适的策略其实是继承collections.UserDict 类.这里我们从dict继承.下面一个例子我们自定义一个在查询的时候把非字符串的键转换为字符串的字典子类 from collections import UserDict class StrKeyDict(UserDict): def __missing__(self, key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def __setitem__(self, key, item): self.data[str(key)] = item def __contains__(self, key): return str(key) in self.data 不可变映射类型MappingProxyType 标准库里所有的映射类型都是可变的，但有时候你会有这样的需求，比如不能让用户错误地修改某个映射. 从Python 3.3 开始，types 模块中引入了一个封装类名叫MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。下面的简短地对这个类的用法做了个演示。 from types import MappingProxyType d = {1:'A'} d_proxy = MappingProxyType(d) d_proxy mappingproxy({1: 'A'}) d_proxy[1] 'A' d_proxy[2] = 'x' --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 d_proxy[2] = 'x' TypeError: 'mappingproxy' object does not support item assignment d[2] = 'B' d_proxy mappingproxy({1: 'A', 2: 'B'}) d_proxy[2] 'B' 集合 python中的集合有两种类型: set 标准集合 frozenset 可散列集合 集合的本质是许多唯一对象的聚集。因此，集合可以用于去重. 集合中的元素必须是可散列的，set类型本身是不可散列的，但是frozenset可以。因此可以创建一个包含不同frozenset 的set。 l = ['spam', 'spam', 'eggs', 'spam'] set(l) {'eggs', 'spam'} frozenset(l) frozenset({'eggs', 'spam'}) 除了保证唯一性，集合还实现了很多基础的中缀运算符.给定两个集合a 和b: a | b ,a |= b,a.union(b,c,d...) 返回的是它们的合集 a & b,a &= b,a.intersection(b,c,d...),a.intersection_update(b,c,d...) 得到的是交集 a - b ,a -= b,a.difference(b,c,d...),a.difference_update(b,c,d...)得到的是差集 a ^ b,s ^= z,a.symmetric_difference_update(b,c,d...)得到的是对称差集 s.__contains__(e) 元素e 是否属于s s s 是否为z 的子集 s.issubset(it) 把可迭代的it 转化为集合，然后查看s 是否为它的子集 s s 是否为z 的真子集 s >= z s 是否为z 的父集 s.issuperset(it) 把可迭代的it 转化为集合，然后查看s 是否为它的父集 s > z s 是否为z 的真父集 合理地利用这些操作,不仅能够让代码的行数变少,还能减少Python程序的运行时间.这样做同时也是为了让代码更易读,从而更容易判断程序的正确性,因为利用这些运算符可以省去不必要的循环和逻辑操作. 例如:我们有一个电子邮件地址的集合haystack,还要维护一个较小的电子邮件地址集合needles,然后求出needles中有多少地址同时也出现在了heystack 里.借助集合操作，我们只需要一行代码就可以了 found = len(needles & haystack) 集合字面量 除空集之外，集合的字面量——{1}、{1, 2}，等等——看起来跟它的数学形式一模一样。' 如果是空集，那么必须写成set()的形式. 在Python 3里面,除了空集，集合的字符串表示形式总是以{...}的形式出现 s = {1} type(s) set s {1} s.pop() 1 s set() 像{1, 2, 3}这种字面量句法相比于构造方法(set([1, 2, 3]))要更快且更易读。后者的速度要慢一些，因为Python 必须先从set 这个名字来查询构造方法，然后新建一个列表，最后再把这个列表传入到构造方法里。但是如果是像{1, 2, 3}这样的字面量，Python 会利用一个专门的叫作BUILD_SET 的字节码来创建集合. 由于Python 里没有针对frozenset 的特殊字面量句法，我们只能采用构造方法。 集合推导 Python 2.7带来了集合推导(setcomps)和之前在3.2 节里讲到过的字典推导类似 例子:把编码在32~255 之间的字符的名字里有“SIGN”单词的挑出来，放到一个集合里。 from unicodedata import name {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')} {'#', '$', '%', '+', '', '¢', '£', '¤', '¥', '§', '©', '¬', '®', '°', '±', 'µ', '¶', '×', '÷'} 可散列对象 在Python 词汇表中，关于可散列类型的定义有这样一段话: 如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现__hash__()方法。另外可散列对象还要有__qe__() 方法,这样才能跟其他键做比较.如果两个可散列对象是相等的，那么它们的散列值一定是一样的. 原子不可变数据类型(str、bytes 和数值类型)都是可散列类型,frozenset也是可散列的，因为根据其定义,frozenset里只能容纳可散列类型.元组的话,只有当一个元组包含的所有元素都是可散列类型的情况下,它才是可散列的. 一般来讲用户自定义的类型的对象都是可散列的，散列值就是它们的id()函数的返回值，所以所有这些对象在比较的时候都是不相等的。如果一个对象实现了__eq__方法，并且在方法中用到了这个对象的内部状态的话，那么只有当所有这些内部状态都是不可变的情况下，这个对象才是可散列的. 散列表 散列表其实是一个稀疏数组（总是有空白元素的数组称为稀疏数组）.在一般的数据结构教材中，散列表里的单元通常叫作表元（bucket）.在dict 的散列表当中，每个键值对都占用一个表元，每个表元都有两个部分，一个是对键的引用，另一个是对值的引用。因为所有表元的大小一致，所以可以通过偏移量来读取某个表元。 因为Python 会设法保证大概还有三分之一的表元是空的，所以在快要达到这个阈值的时候，原有的散列表会被复制到一个更大的空间里面.如果要把一个对象放入散列表，那么首先要计算这个元素键的散列值。Python 中可以用hash()方法来做这件事情，接下来会介绍这一点。 散列值和相等性 内置的hash()方法可以用于所有的内置类型对象。如果是自定义对象调用hash()的话，实际上运行的是自定义的__hash__。如果两个对象在比较的时候是相等的，那它们的散列值必须相等，否则散列表就不能正常运行了。例如，如果1 == 1.0 为真，那么hash(1) ==hash(1.0) 也必须为真，但其实这两个数(整型和浮点)的内部结构是完全不一样的.为了让散列值能够胜任散列表索引这一角色，它们必须在索引空间中尽量分散开来.这意味着在最理想的状况下，越是相似但不相等的对象，它们散列值的差别应该越大. 从Python 3.3开始，str、bytes 和datetime对象的散列值计算过程中多了随机的“加盐”这一步。所加盐值是Python进程内的一个常量，但是每次启动 Python 解释器都会生成一个不同的盐值。随机盐值的加入是为了防止DOS 攻击而采取的一种安全措施. 散列表算法 在映射中,为了获取my_dict[search_key] 背后的值，Python 首先会调用hash(search_key) 来计算search_key 的散列值，把这个值最低的几位数字当作偏移量，在散列表里查找表元（具体取几位，得看当前散列表的大小）.若找到的表元是空的，则抛出KeyError异常。若不是空的，则表元里会有一对found_key:found_value。这时候Python 会检验search_key ==found_key 是否为真，如果它们相等的话，就会返回found_value.如果search_key和found_key不匹配的话，这种情况称为散列冲突.发生这种情况是因为，散列表所做的其实是把随机的元素映射到只有几位的数字上，而散列表本身的索引又 只依赖于这个数字的一部分。为了解决散列冲突，算法会在散列值中另外再取几位，然后用特殊的方法处理一下，把新得到的数字再当作索引来寻找表元. 若这次找到的表元是空的，则同样抛出KeyError； 若非空，或者键匹配，则返回这个值； 或者又发现了散列冲突，则重复以上的步骤。 添加新元素和更新现有键值的操作几乎跟上面一样。只不过对于前者，在发现空表元的时候会放入一个新元素；对于后者，在找到相对应的表元后，原表里的值对象会被替换成新值。另外在插入新值时，Python 可能会按照散列表的拥挤程度来决定是否要重新分配内存为它扩容。如果增加了散列表的大小，那散列值所占的位数和用作索引的位数都会随之增加，这样做的目的是为了减少发生散列冲突的概率. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 00:32:14 "},"数据结构与算法/可迭代对象与生成器.html":{"url":"数据结构与算法/可迭代对象与生成器.html","title":"可迭代对象与生成器","keywords":"","body":"可迭代对象,迭代器的范畴 凡是满足Iterable协议的都是可迭代对象.因此所有的容器都是可迭代对象,可迭代对象不管容量的大小,只要每次for循环都可以取出对象即可,因此迭代是数据处理的基石.扫描内存中放不下的数据集时，我们要找到一种惰性获取数据项的方式，即按需一次获取一个数据项.这就是迭代器模式（Iterator pattern）.而符合这一特征的数据类型就是Iterator迭代器.Iterator除了有__iter__外还要实现next方法. 生成器 生成器是python中最中要的数据模型之一,由它衍生而来的协程可以看这篇文章了解. 生成器实现需要实现接口__iter__,__next__,send,throw这4个方法,但也有更加简单的方式实现就是使用生成器函数 生成器函数就是带有yield的函数,它停止需要抛出StopIteration异常 最简单的可迭代对象--生成器表达式 列表解析通过一定的操作可以产生一个列表,而如果去掉[],那就是惰性的生成器表达式了 何时使用生成器表达式 根据我的经验，选择使用哪种句法很容易判断：如果生成器表达式要分成多行写，我倾向 于定义生成器函数，以便提高可读性。此外，生成器函数有名称，因此可以重用。 a = (i for i in range(10)) type(a) generator for i in a: print(i) 0 1 2 3 4 5 6 7 8 9 iter函数 用于创建迭代器 iter函数可以将一个可迭代对象转换为一个迭代器 a = iter([i for i in range(10)]) 序列可以迭代的原因在于解释器需要迭代对象时，会自动调用iter. 内置的iter 函数有以下作用: 检查对象是否实现了__iter__ 方法，如果实现了就调用它，获取一个迭代器。 如果没有实现__iter__ 方法，但是实现了__getitem__ 方法，Python 会创建一个迭代器，尝试按顺序（从索引0 开始）获取元素。 如果尝试失败，Python 抛出TypeError异常，通常会提示'xxx object is not iterable' 当iter有第二个参数的时候,iter的作用是使用常规的函数或任何可调用的对象创建迭代器.这样使用时， 第一个参数必须是可调用的对象，用于不断调用（没有参数），产出各个值 第二个值是哨符，这是个标记值，当可调用的对象返回这个值时，触发迭代器抛出StopIteration 异常，而不产出哨符。 from random import randint b = iter(lambda : randint(1,10),5) for i in b: print(i) 3 6 7 1 10 3 3 8 9 1 1 7 6 4 3 1 可迭代对象的操作 拆包操作 python3支持可迭代对象的拆包操作,并且可以结合通配符达到一些很酷的效果 _,x,*last=range(10) x 1 last [2, 3, 4, 5, 6, 7, 8, 9] 排序操作 内置函数sorted(iterable,key,reverse=False,)会新建一个列表作为返回值.这个方法可以接受任何形式的可迭代对象作为参数，而不管sorted 接受的是怎样的参数，它最后都会返回一个列表. 其中参数reverse如果被设定为True，被排序的序列里的元素会以降序输出(也就是说把最大值当作最小值来排序). 参数key则为一个只有一个参数的函数，这个函数会被用在序列里的每一个元素上，所产生的结果将是排序算法依赖的对比关键字.比如说，在对一些字符串排序时，可以用key=str.lower 来实现忽略大小写的排序，或者是用key=len 进行基于字符串长度的排序.这个参数的默认值是恒等函数identity function，也就是默认用元素自己的值来排序 sorted([11,3,4,2,5]) [2, 3, 4, 5, 11] 堆排序 python的标准库heapq提供了将列表转换为堆的算法支持 堆是二叉树，每个父节点具有小于或等于其任何子节点的值。该实现使用数组，对于所有k，从零开始计数元素， heap [k] 和heap [k] 为了比较，不存在的元素被认为是无限的.堆的有趣属性是它的最小元素总是根heap[0]. 方法有: heapq.heappush(heap, item) 向堆中插入元素 heapq.heappop(heap) 从堆中取出最小元素 heapq.heappushpop(heap, item) 插入元素在取出最小元素 heapq.heapify(x) 将一个列表注册为堆 heapq.heapreplace(heap, item) 移除堆中的某个元素 heapq.merge(*iterables, key=None, reverse=False) 将多个排序输入合并到单个排序的输出（例如，从多个日志文件中合并时间戳条目）。返回排序值的迭代器。 heapq.nlargest(n, iterable, key=None) 取可迭代对象中最大的n个元素 heapq.nsmallest(n, iterable, key=None) 取可迭代对象中最大的n个元素 import heapq def heapsort(iterable): h = [] for value in iterable: heapq.heappush(h, value) return [heapq.heappop(h) for i in range(len(h))] heapsort([11,3,4,2,5]) [2, 3, 4, 5, 11] c = [11,3,4,2,5] heapq.heapify(c) c [2, 3, 4, 11, 5] [heapq.heappop(c) for i in range(len(c))] [2, 3, 4, 5, 11] 排序性能测试 from random import randint,random a = [randint(1,100) for i in range(50)] aa = [randint(1,10000) for i in range(5000)] aaa = [randint(1,1000000) for i in range(5000000)] b = [random() for i in range(50)] bb = [random() for i in range(5000)] bbb = [random() for i in range(5000000)] %timeit heapsort(a) 37.2 µs ± 3.98 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) %timeit sorted(a) 6.64 µs ± 237 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit heapsort(aa) 4.91 ms ± 898 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit sorted(aa) 1.77 ms ± 76 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit heapsort(aaa) 21.6 s ± 1.25 s per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit sorted(aaa) 7.46 s ± 561 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit heapsort(b) 48.5 µs ± 7.41 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) %timeit sorted(b) 7.11 µs ± 240 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit heapsort(bb) 4.45 ms ± 174 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit sorted(bb) 1.82 ms ± 94.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) %timeit heapsort(bbb) 23.8 s ± 1.33 s per loop (mean ± std. dev. of 7 runs, 1 loop each) %timeit sorted(bbb) 7.78 s ± 794 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 可以看出,堆排序效率并不如自带的排序算法效率高,那么堆有什么作用呢?简单来说就是插入和查找方便,堆会在每次都将数据存入与自己大小匹配的 用bisect来管理已排序的序列 bisect模块的主要作用是管理有序序列. bisect模块包含两个主要函数bisect 和insort，两个函数都利用二分查找算法来在有序序列中查找或插入元素. bisect(a, x[, lo[, hi]]) bisect的作用是查找x元素在a序列中的位置.它的表现可以从两个方面来调教: 首先可以用它的两个可选参数——lo 和hi——来缩小搜寻的范围,lo 的默认值是0，hi的默认值是序列的长度，即len() 作用于该序列的返回值。 bisect 函数其实是bisect_right 函数的别名，后者还有个姊妹函数叫bisect_left.的区别在于，bisect_left 返回的插入位置是原序列中跟被插入元素相等的元素的位置，也就是新元素会被放置于它相等的元素的前面，而bisect_right 返回的则是跟它相等的元素之后的位置.这个细微的差别可能对于整数序列来讲没什么用，但是对于那些值相等但是形式不同的数据类型来讲，结果就不一样了. insort(a, x[, lo[, hi]]) 排序很耗时，因此在得到一个有序序列之后，我们最好能够保持它的有序.bisect.insort就是为了这个而存在的.insort(seq, item) 把变量item 插入到序列seq 中，并能保持seq 的升序顺序. 例子:用bisect来搜索 bisect(haystack, needle)|bisect_left(haystack, needle) 在haystack（干草垛）里搜索needle（针）的位置，该位置满足的条件是，把needle 插入这个位置之后，haystack 还能保持升序。也就是在说这个函数返回的位置前面的值，都小于或等于needle 的值。其中haystack 必须是一个有序的序列。 你可以先用bisect(haystack, needle) 查找位置index，再用haystack.insert(index,needle)来插入新值。但你也可用insort来一步到位，并且后者的速度更快一些。 import bisect import sys HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30] NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31] ROW_FMT = '{0:2d} @ {1:2d} {2}{0: def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) offset = position * ' |' print(ROW_FMT.format(needle, position, offset)) bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) DEMO: bisect haystack -> 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 14 | | | | | | | | | | | | | |30 29 @ 13 | | | | | | | | | | | | |29 23 @ 11 | | | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 5 | | | | |8 5 @ 3 | | |5 2 @ 1 |2 1 @ 1 |1 0 @ 0 0 bisect_fn = bisect.bisect_left print('DEMO:', bisect_fn.__name__) print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) DEMO: bisect_left haystack -> 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 13 | | | | | | | | | | | | |30 29 @ 12 | | | | | | | | | | | |29 23 @ 9 | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 4 | | | |8 5 @ 2 | |5 2 @ 1 |2 1 @ 0 1 0 @ 0 0 例:用bisect.insort插入新元素 import bisect import random SIZE=7 random.seed(1729) my_list = [] for i in range(SIZE): new_item = random.randrange(SIZE*2) bisect.insort(my_list, new_item) print('%2d ->' % new_item, my_list) 10 -> [10] 0 -> [0, 10] 6 -> [0, 6, 10] 8 -> [0, 6, 8, 10] 7 -> [0, 6, 7, 8, 10] 2 -> [0, 2, 6, 7, 8, 10] 10 -> [0, 2, 6, 7, 8, 10, 10] 内置的可迭代对象 可迭代对象作为python最中要的特性之一,已经被很多语言借鉴吸收,比如javascript在ES6标准中实现了生成器. python3有大量的内置可迭代对象 range(start,end,step) 生成整数等差数列对象 [i for i in range(1,10,3)] [1, 4, 7] 更多的可迭代对象可以则包括在标准库itertools中 itertools.count(start,step) 生成无穷等差数列 from itertools import count gen = count(1,0.5) for i in range(5): print(next(gen)) 1 1.5 2.0 2.5 3.0 itertools.cycle(it) 从it 中产出各个元素，存储各个元素的副本，然后按顺序重复不断地产出各个元素 from itertools import cycle gen = cycle([1,2,3]) for i in range(5): print(next(gen)) 1 2 3 1 2 itertools.repeat(item, [times]) 重复不断地产出指定的元素，除非提供times，指定次数 from itertools import repeat gen = repeat(1) for i in range(5): print(next(gen)) 1 1 1 1 1 itertools.permutations(it,out_len=None) 把out_len 个it 产出的元素排列在一起，然后产出这些排列；out_len 的默认值等于len(list(it)) from itertools import permutations gen = permutations([1,2,3],2) for i in gen: print(i) (1, 2) (1, 3) (2, 1) (2, 3) (3, 1) (3, 2) itertools.combinations(it,out_len) 把it 产出的out_len 个元素组合在一起，然后产出 from itertools import combinations gen = combinations([1,2,3],2) for i in gen: print(i) (1, 2) (1, 3) (2, 3) itertools.combinations_with_replacement(it, out_len) 把it产出的out_len个元素组合在一起，然后产出，包含相同元素的组合 from itertools import combinations_with_replacement gen = combinations_with_replacement([1,2,3],2) for i in gen: print(i) (1, 1) (1, 2) (1, 3) (2, 2) (2, 3) (3, 3) 内置的的迭代器函数 迭代器函数是用来处理迭代器的函数,主要功能包括 过滤迭代器--用于从迭代器中剔除部分元素 映射迭代器--用于对迭代器中的元素做同样的处理 合并迭代器--用于合并多个可迭代对象从而生成一个新迭代器对象 重排迭代器--用于重新排列元素 过滤迭代器 filter(predicate, it) 把it 中的各个元素传给predicate，如果predicate(item)返回真值，那么产出对应的元素；如果predicate 是None，那么只产出真值元素 itertools.compress(it, selector_it) 并行处理两个可迭代的对象；如果selector_it 中的元素是真值，产出it中对应的元素 itertools.dropwhile(predicate, it) 处理it，跳过predicate 的计算结果为真值的元素，然后产出剩下的各个元素（不再进一步检查） itertools.filterfalse(predicate, it) 与filter 函数的作用类似，不过predicate 的逻辑是相反的：predicate 返回假值时产出对应的元素 itertools.islice(it, stop) 或islice(it,start, stop, step=1) 产出it的切片，作用类似于s[:stop] 或s[start:stop:step]，不过it可以是任何可迭代的对象，而且这个函数实现的是惰性操作 itertools takewhile(predicate, it) predicate 返回真值时产出对应的元素，然后立即停止，不再继续检查 映射迭代器 enumerate(iterable, start=0) 产出由两个元素组成的元组，结构是(index, item)，其中index 从start 开始计数，item 则从iterable 中获取 map(func, it1, [it2, ..., itN]) 把it中的各个元素传给func，产出结果；如果传入N 个可迭代的对象，那么func 必须能接受N 个参数，而且要并行处理各个可迭代的对象 itertools.accumulate(it, [func]) 产出累积的总和；如果提供了func，那么把前两个元素传给它，然后把计算结果和下一个元素传给它，以此类推，最后产出结果 itertools.starmap(func, it) 把it 中的各个元素传给func，产出结果；输入的可迭代对象应该产出可迭代的元素iit，然后以func(*iit) 这种形式调用func 合并迭代器 zip(it1, ..., itN) 并行从输入的各个可迭代对象中获取元素，产出由N 个元素组成的元组，只要有一个可迭代的对象到头了，就默默地停止 itertools.chain(it1, ..., itN) 先产出it1中的所有元素，然后产出it2中的所有元素，以此类推，无缝连接在一起 itertools.chain.from_iterable(it) 产出it 生成的各个可迭代对象中的元素，一个接一个，无缝连接在一起；it 应该产出可迭代的元素，例如可迭代的对象列表 itertools.product(it1, ...,itN, repeat=1) 计算笛卡儿积：从输入的各个可迭代对象中获取元素，合并成由N个元素组成的元组，与嵌套的for 循环效果一样；repeat 指明重复处理多少次输入的可迭代对象 itertools zip_longest(it1, ...,itN, fillvalue=None) 并行从输入的各个可迭代对象中获取元素，产出由N 个元素组成的元组，等到最长的可迭代对象到头后才停止，空缺的值使用fillvalue填充 重排迭代器 itertools.groupby(it,key=None) 产出由两个元素组成的元素，形式为(key, group)，其中key 是分组标准，group 是生成器，用于产出分组里的元素 itertools.tee(it, n=2) 产出一个由n个生成器组成的元组，每个生成器用于单独产出输入的可迭代对象中的元素 可迭代的归约函数 所谓归约函数指接受一个可迭代的对象，然后返回单个结果的函数.python内置了许多这种函数 all(it) it 中的所有元素都为真值时返回True，否则返回False；all([]) 返回True sum(it, start=0) it 中所有元素的总和，如果提供可选的start，会把它加上（计算浮点数的加法时，可以使用math.fsum函数提高精度） any(it) 只要it 中有元素为真值就返回True，否则返回False；any([]) 返回False max(it, [key=,][default=]) 返回it 中值最大的元素；key 是排序函数，与sorted函数中的一样；如果可迭代的对象为空，返回default min(it, [key=,][default=]) 返回it 中值最小的元素；key 是排序函数，与sorted 函数中的一样；如果可迭代的对象为空，返回default functools reduce(func, it,[initial]) 把前两个元素传给func，然后把计算结果和第三个元素传给func，以此类推，返回最后的结果；如果提供了initial，把它当作第一个元素传入 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 00:29:54 "},"数据结构与算法/结语.html":{"url":"数据结构与算法/结语.html","title":"结语","keywords":"","body":"结语 不同的情况使用不同的数据结构和算法 下面是Python中最常用数据结构常用操作的时间复杂度表: 容器 使用环境 list 一般用用 tuple 当内部元素不需要改变的时候用 heapq 双端队列,当元素数量巨幅变动频繁的时候使用 bisect 当元素较多且需要频繁查找时使用 deque 堆,当需要排序时使用 array 数组,当类型相同时可以使用,可以减少内存占用 set 当需要去重的时候使用 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 22:30:42 "},"函数/":{"url":"函数/","title":"函数","keywords":"","body":"函数 函数是一种组织代码的形式,而python中函数也是对象.这种一致性其实也暗合了计算的本质. 现代计算机语言往往将操作与数据区别开,但本质上操作和代码都是一样的而进制代码而已,而在数学中,函数映射和数据也是相互可以转化的. 函数式一等对象 变量作用域与闭包 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 22:33:57 "},"函数/函数是一等对象.html":{"url":"函数/函数是一等对象.html","title":"函数是一等对象","keywords":"","body":"函数是一等对象 python从来不是一门函数式编程语言,但函数确实是一等对象,准确的说函数和其他对象一样,都是平等的. 编程语言理论家把'一等对象'定义为满足下述条件的程序实体: 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 Python函数是对象。这里我们创建了一个函数,然后调用它,读取它的__doc__属性,并且确定函数对象本身是function类的实例 def factorial(n): \"\"\"return n!\"\"\" return 1 if n factorial(42) 1405006117752879898543142606244511569936384000000000 factorial.__doc__ 'return n!' type(factorial) function 可以看到它和其他对象形式上是保持一致的. 有了一等函数,就可以使用函数式风格编程。函数式编程的特点之一是使用高阶函数 高阶函数 接受函数为参数,或者把函数作为结果返回的函数是高阶函数(higher-order function).内置的map,reduce,filter,sorted等都是高阶函数的代表,这边不再复述. 最为人熟知的高阶函数有map、filter、reduce 和 apply. apply函数在Python 3中已经移除了,因为不再需要它了.如果想使用不定量的参数调用函数,可以编写fn(*args, **keywords),不用再编写apply(fn, args, kwargs) map,filter 和reduce这三个高阶函数还能见到,不过多数使用场景下都有更好的替代品. map、filter和reduce的现代替代品 函数式语言通常会提供map、filter和reduce三个高阶函数(有时使用不同的名称)。在Python 3中,map和 filter还是内置函数,但是由于引入了列表推导和生成器表达式,它们变得没那么重要了.列表,字典,集合推导或生成器表达式具有map 和filter两个函数的功能,而且更易于阅读,具体的可以看数据结构预算法中相关的内容. 内置的高阶函数与可迭代对象有着很强的关联.这是python3的一项优化,通过延迟计算可以节省内存. 匿名函数 lambda关键字在Python 表达式内创建匿名函数. 然而,Python 简单的句法限制了lambda函数的定义体只能使用纯表达式.换句话说,lambda函数的定义体中不能赋值,也不能使用while和try等 Python 语句. 在参数列表中最适合使用匿名函数.比如sorted中就可以用lambda表达式 fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] sorted(fruits, key=lambda word: word[::-1]) ['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] 除了作为参数传给高阶函数之外,Python 很少使用匿名函数。由于句法上的限制,非平凡 的 lambda 表达式要么难以阅读,要么无法写出 如果使用 lambda 表达式导致一段代码难以理解,Fredrik Lundh 建议像下面这样重构 编写注释,说明 lambda 表达式的作用。 研究一会儿注释,并找出一个名称来概括注释。 把lambda表达式转换成def语句,使用那个名称来定义函数。 删除注释。 lambda句法只是语法糖:与def语句一样,lambda表达式会创建函数对象.这是Python中几种可调用对象的一种.下一节会说明所有可调用对象 可调用对象 除了用户定义的函数,调用运算符(即 ())还可以应用到其他对象上.如果想判断对象能否调用,可以使用内置的callable()函数.Python数据模型文档列出了8种可调用对象. 用户定义的函数 使用def语句或lambda表达式创建。 内置函数 使用C语言(CPython)实现的函数,如len或time.strftime 内置方法使用 C 语言实现的方法,如dict.get。 方法 在类的定义体中定义的函数. 类 调用类既是创建实例 类的实例 如果类定义了__call__方法,那么它的实例可以作为函数调用 生成器函数 使用yield关键字的函数或方法.调用生成器函数返回的是生成器对象 协程 使用async def创建 callable(...)函数可以用于判定对象是否是可调用的对象 用户定义的可调用类型 不仅Python函数是真正的对象,任何Python对象都可以表现得像函数。为此,只需实现实例方法__call__. 例:BingoCage 类.这个类的实例使用任何可迭代对象构建,而且会在内部存储一个随机顺序排列的列表。调用实例会取出一个元素 import random class BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() bingo = BingoCage(range(3)) bingo.pick() 1 bingo() 2 callable(bingo) True 函数内省 函数对象还有很多属性。使用dir函数可以探知函数具有的属性.这其中大多数属性是Python对象共有的.与函数对象相关的几个属性有: __annotations__参数和返回值的注解 __call__实现 () 运算符;即可调用对象协议 __closure__函数闭包,即自由变量的绑定(通常是 None) __code__编译成字节码的函数元数据和函数定义体 __defaults__形式参数的默认值 __get__实现只读描述符协议 __globals__函数所在模块中的全局变量 __kwdefaults__仅限关键字形式参数的默认值 __name__ 函数名称 __qualname__函 数 的 限 定 名 称, 如 Random.choice 从定位参数到仅限关键字参数 Python最好的特性之一是提供了极为灵活的参数处理机制,而且Python 3进一步提供了仅 限关键字参数(keyword-only argument).与之密切相关的是,调用函数时使用*和**\"展开\"可迭代对象,映射到单个参数. 仅限关键字参数是Python 3新增的特性。用于指定参数只能通过关键字参数指定,而一定不会捕获未命名的定位参数. 定义函数时若想指定仅限关键字参数,要把它们放到前面有*的参数后面.如果不想支持数量不定的定位参数,但是想支持仅限关键字参数,在签名中放一个*. def f(a, *, b): return a, b f(1, b=2) (1, 2) f(1,2) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 f(1,2) TypeError: f() takes 1 positional argument but 2 were given 仅限关键字参数不一定要有默认值,可以像上例中 b 那样,强制必须传入实参. 要获取一个函数的参数签名,可以使用inspect模块 inspect.signature函数返回一个inspect.Signature对象,它有一个parameters属性,这是一个有序映射,把参数名和inspect.Parameter对象对应起来.各个Parameter属性也有自己的属性,例如name、default 和 kind.特殊的inspect._empty值表示没有默认值.考虑到None是有效的默认值(也经常这么做),而且这么做是合理的.kind属性的值是_ParameterKind类中的5个值之一,列举如下: POSITIONAL_OR_KEYWORD 可以通过定位参数和关键字参数传入的形参(多数 Python 函数的参数属于此类) VAR_POSITIONAL 定位参数元组 VAR_KEYWORD 关键字参数字典 KEYWORD_ONLY 仅限关键字参数 POSITIONAL_ONLY 仅限定位参数;目前,Python 声明函数的句法不支持,但是有些使用 C 语言实现且不接受关键字参数的函数(如divmod)支持 除了name、default 和 kind,inspect.Parameter 对象还有一个annotation属性,它的值通常是inspect._empty,这部分与类型注释和检验有关 from inspect import signature sig = signature(f) for name, param in sig.parameters.items(): print(param.kind, ':', name, '=', param.default) POSITIONAL_OR_KEYWORD : a = KEYWORD_ONLY : b = inspect.Signature对象有个bind方法,它可以把任意个参数绑定到签名中的形参上,所 用的规则与实参到形参的匹配方式一样。框架可以使用这个方法在真正调用函数前验证参数 my_tag = {\"a\":22,\"b\":12} bound_args = sig.bind(**my_tag) bound_args for name, param in bound_args.arguments.items(): print(name, '=', param) a = 22 b = 12 支持函数式编程的包 虽然 Guido 明确表明,Python 的目标不是变成函数式编程语言,但是得益于operator和functools等包的支持,函数式编程风格也可以信手拈来. operator模块 在函数式编程中,经常需要把算术运算符当作函数使用。例如,不使用递归计算阶乘。求 和可以使用sum函数,但是求积则没有这样的函数。我们可以使用reduce函数,但是需要一个函数计算序列中两个元素之积。 operator模块为多个算术运算符提供了对应的函数,从而避免编写lambda a, b: a*b这种平凡的匿名函数。 from functools import reduce from operator import mul def fact(n): return reduce(mul, range(1, n+1)) operator模块中还有一类函数,能替代从序列中取出元素或读取对象属性的lambda表达式: 因此,itemgetter 和 attrgetter 其实会自行构建函数 metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] from operator import itemgetter for city in sorted(metro_data, key=itemgetter(1)): print(city) ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)) ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)) ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)) ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)) 如果把多个参数传给 itemgetter,它构建的函数会返回提取的值构成的元组: cc_name = itemgetter(1, 0) for city in metro_data: print(cc_name(city)) ('JP', 'Tokyo') ('IN', 'Delhi NCR') ('MX', 'Mexico City') ('US', 'New York-Newark') ('BR', 'Sao Paulo') itemgetter 使用[]运算符,因此它不仅支持序列,还支持映射和任何实现__getitem__ 方 法的类attrgetter与 itemgetter 作用类似,它创建的函数根据名称提取对象的属性。如果把多个属性名传给attrgetter,它也会返回提取的值构成的元组。此外,如果参数名中包含.(点号),attrgetter 会深入嵌套对象,获取指定的属性。 我们构建一个嵌套结构,这样才能展示attrgetter如何处理包含点号的属性名. 定义一个namedtuple,名为metro_data,演示使用attrgetter处理它 from collections import namedtuple LatLong = namedtuple('LatLong', 'lat long') Metropolis = namedtuple('Metropolis', 'name cc pop coord') metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long)) for name, cc, pop, (lat, long) in metro_data] metro_areas[0] Metropolis(name='Tokyo', cc='JP', pop=36.933, coord=LatLong(lat=35.689722, long=139.691667)) metro_areas[0].coord.lat 35.689722 from operator import attrgetter name_lat = attrgetter('name', 'coord.lat') for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city)) ('Sao Paulo', -23.547778) ('Mexico City', 19.433333) ('Delhi NCR', 28.613889) ('Tokyo', 35.689722) ('New York-Newark', 40.808611) 具体符号如下: Operation Syntax Function Addition a + b add(a, b) Concatenation seq1 + seq2 concat(seq1, seq2) Containment Test obj in seq contains(seq, obj) Division a / b truediv(a, b) Division a // b floordiv(a, b) Bitwise And a & b and_(a, b) Bitwise Exclusive Or a ^ b xor(a, b) Bitwise Inversion ~ a invert(a) Bitwise Or a l b or_(a, b) Exponentiation a ** b pow(a, b) Identity a is b is_(a, b) Identity a is not b is_not(a, b) Indexed Assignment obj[k] = v setitem(obj, k, v) Indexed Deletion del obj[k] delitem(obj, k) Indexing obj[k] getitem(obj, k) Left Shift a lshift(a, b) Modulo a % b mod(a, b) Multiplication a * b mul(a, b) Matrix Multiplication a @ b matmul(a, b) Right Shift a >> b rshift(a, b) Slice Assignment seq[i:j] = values setitem(seq, slice(i, j), values) Slice Deletion del seq[i:j] delitem(seq, slice(i, j)) Slicing seq[i:j] getitem(seq, slice(i, j)) String Formatting s % obj mod(s, obj) Subtraction a - b sub(a, b) Truth Test obj truth(obj) Ordering a lt(a, b) Ordering a le(a, b) Equality a == b eq(a, b) Difference a != b ne(a, b) Ordering a >= b ge(a, b) Ordering a > b gt(a, b) Matrix Multiplication a @ b matmul(a, b) Negation (Arithmetic) a neg(a) Negation (Logical) not a not_(a) Positive a pos(a) 使用functools.partial冻结参数 functools.partial这个高阶函数用于部分应用一个函数.部分应用是指,基于一个函数创建一个新的可调用对象,把原函数的某些参数固定.使用这个函数可以把接受一个或多个参数的函数改编成需要回调的API,这样参数更少. functools.partialmethod函数的作用与partial一样,不过是用于处理方法的.我们以partial来作为例子 from operator import mul from functools import partial triple = partial(mul, 3) triple(7) 21 list(map(triple, range(1, 10))) [3, 6, 9, 12, 15, 18, 21, 24, 27] 使用unicode.normalize函数再举个例子,这个示例更有实际意义.如果处理多国语言编写的文本,在比较或排序之前可能会想使用unicode.normalize('NFC', s)处理所有字符串s如果经常这么做,可以定义一个nfc函数. import unicodedata import functools nfc = functools.partial(unicodedata.normalize, 'NFC') s1 = 'café' s2 = 'cafe\\u0301' s1, s2 ('café', 'café') s1 == s2 True nfc(s1) == nfc(s2) True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 22:10:44 "},"函数/变量作用域与闭包.html":{"url":"函数/变量作用域与闭包.html","title":"变量作用域与闭包","keywords":"","body":"变量作用域 python的变量是有其作用域的,也就是说变量必须保存在上下文中,离开了这个上下文环境就找不到了 LEGB原则 python的变量作用域遵循LEGB原则,即: L-Local(function)；函数内的名字空间 E-Enclosing function locals；外部嵌套函数的名字空间(例如closure) G-Global(module)；函数定义所在模块（文件）的名字空间 B-Builtin(Python)；Python内置模块的名字空间 python遵循从上到下的查找方式,我们来看个例子,从闭包中观察LEGB规则. global语句 global语句用来在函数内声明一个变量是全局变量 Pi = 3 def acreage(r): global Pi Pi = 3.14 return Pi*r**2 def perimeters(r): return Pi*r*2 def acreage1(r): Pi = 3.1 return Pi*r**2 print(perimeters(2)) print(acreage1(2)) print(acreage(2)) print(acreage1(2)) print(perimeters(2)) 12 12.4 12.56 12.4 12.56 可以看出 acreage中用global声明改变了全局的Pi值,而acreage1中的pi是本地的所以只在本地有效而已 如果要查看有哪些全局变量的话,也只需要使用内置函数globals()即可 nolocal语句 nolocal语句是用来声明一个变量不是本地的,它常在闭包中使用. 我们知道global声明是明确指定一个变量作用域为模块全局,而nolocal是声明变量在外部嵌套函数的名字空间,这样就可以在local中修改外部嵌套函数中的变量了 X = 1 def a(): X = 2 def b(): X = 3 print(X) return b a()() 3 X = 1 def a(): X = 2 def b(): global X X = 11 print(X) return b a()() print(X) 11 11 X = 1 def a(): X = 2 print(X) def b(): nonlocal X X = 22 print(X) return X b() print(X) return b a()() 2 22 22 22 22 突破界限–用字典打破LEGB规则 python中字典是一个神奇的存在,它可以跨界,这主要是得益于字典是可变容器 d = {\"x\":1} def a(): d[\"x\"]+=1 print(d[\"x\"]) a() print(d[\"x\"]) 1 2 def a(): d={\"x\":1} print(d[\"x\"]) def b(): d[\"x\"]+=1 return d[\"x\"] b() print(d[\"x\"]) return b a()() 1 2 3 不论是global还是nonlocal都是LEGB原则下高级别作用域中修改低级别作用域变量的方法. 而在python中也可以用字典来作为迂回跳开LEGB的规则限制. 闭包 所谓闭包是指一种组织代码的结构.函数的对象也是有作用域的,我们希望一个函数可以不依赖于外界的函数或者变量,自己就可以实现它的既定功能(也就是没有副作用),那么,有的时候我们就需要在函数的内部定义函数,这就是闭包了. 在博客圈,人们有时会把闭包和匿名函数弄混.这是有历史原因的: 在函数内部定义函数不常见,直到开始使用匿名函数才会这样做.而且,只有涉及嵌套函数时才有闭包问题.因此,很多人是同时知道这两个概念的. 其实,闭包指延伸了作用域的函数,其中包含函数定义体中引用、但是不在定义体中定义的非全局变量.函数是不是匿名的没有关系,关键是它能访问定义体之外定义的非全局变量。 这个概念难以掌握,最好通过示例理解。 假如有个名为avg的函数,它的作用是计算不断增加的系列值的均值;例如,整个历史中某个商品的平均收盘价.每天都会增加新价格,因此平均值要考虑至目前为止所有的价格. 起初,avg是这样使用的: class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) avg = Averager() avg(10) 10.0 avg(11) 10.5 avg(12) 11.0 如果使用闭包可以这样实现 def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total/len(series) return averager avg = make_averager() avg(10) 10.0 avg(11) 10.5 注意,这两个示例有共通之处:调用Averager()或make_averager()得到一个可调用对象avg,它会更新历史值,然后计算当前均值。不管怎样,我们都只需调用 avg(n),把 n 放入系列值中, 然后重新计算均值. Averager类的实例avg在哪里存储历史值很明显:self.series实例属性。 但是第二个示例中的avg函数在哪里寻找series呢? 注意,series 是 make_averager 函数的局部变量,因为那个函数的定义体中初始化了series:series = []。可是,调用 avg(10) 时,make_averager 函数已经返回了,而它的本地作用域也一去不复返了 在 averager 函数中,series 是自由变量(free variable).这是一个技术术语,指未在本地作用域中绑定的变量: 审查返回的 averager 对象,我们发现 Python 在 __code__ 属性(表示编译后的函数定义体)中保存局部变量和自由变量的名称 avg.__code__.co_varnames ('new_value', 'total') avg.__code__.co_freevars ('series',) series的绑定在返回的avg函数的__closure__ 属性中。avg.__closure__ 中的各个元 素对应于avg.__code__.co_freevars 中的一个名称。这些元素是 cell 对象,有个 cell_ contents属性,保存着真正的值。 avg.__code__.co_freevars ('series',) avg.__closure__ (,) avg.__closure__[0].cell_contents [10, 11] 综上,闭包是一种函数,它会保留定义函数时存在的自由变量的绑定,这样调用函数时, 虽然定义作用域不可用了,但是仍能使用那些绑定。 注意,只有嵌套在其他函数中的函数才可能需要处理不在全局作用域中的外部变量 闭包生成器 我们想输出一个包含不同参数方法的列表 def closure1(): return [lambda : i*i for i in range(1, 4)] def main1(): for j in closure1(): print(j()) main1() 9 9 9 看到结果都是9是不是觉得很诡异,其实这就是因为函数f要寻找变量i,在函数内部找不到i,那就会在外部嵌套函数中寻找,外部嵌套中i已经从1走到3了,也就是i=3了,那就都是为啥结果都是9了 def closure2(): return (lambda :i*i for i in range(1, 4)) def main2(): for j in closure2(): print(j()) main2() 1 4 9 这是为啥呢?其实是因为生成器是一步一步执行的,不进行next程序就没跑完,所以当我们跑main2的时候实际上i在每一步都不一样 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 22:09:33 "},"函数/结语.html":{"url":"函数/结语.html","title":"结语","keywords":"","body":"结语 匿名函数的问题 除了 Python 独有的句法上的局限,在任何一门语言中,匿名函数都有一个严重的缺点:没有名称。 函数有名称,栈跟踪更易于阅读。匿名函数是一种便利的简洁方式,人们乐于使用它们,但是有时会忘乎所以, 尤其是在鼓励深层嵌套匿名函数的语言和环境中,如JavaScript和Node.js. 匿名函数嵌套的层级太深,不利于调试和处理错误。Python中的异步编程结构更好,或许就是因为lambda表达式有局限 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-22 22:36:14 "},"面向对象惯用法/":{"url":"面向对象惯用法/","title":"面向对象惯用法","keywords":"","body":"面向对象惯用法 python是不折不扣的面向对象语言,什么都是平等的对象,这也是它运行速度慢的重要原因. 所谓面向对象往往讲的特点是封装,多态和继承,而对于动态语言的python,很多东西都是自然而然的. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 21:38:50 "},"面向对象惯用法/python中的对象.html":{"url":"面向对象惯用法/python中的对象.html","title":"python中的对象","keywords":"","body":"python中的对象 python中万物都是对象,构造这些对象的都是由继承自object的类型创建而得.而得益于python数据模型,自定义类型的行为可以像内置类型那样自然。实现如此自然的行为,靠的不是继承,而是鸭子类型(duck typing):我们只需按照预定行为实现对象所需的方法即可. 面向对象惯用法部分我们会用一个贯穿始终的例子--自定义向量,来解释python中的类与对象.这边先将这个类的最基本形式写出来 from math import hypot,atan2 from array import array class Vector2D: # 在 Vector2d 实例和字节序列之间转换时使用 typecode = 'd' __slots__ = ('__x', '__y') @classmethod def frombytes(cls, octets): # 使用传入的`octets`字节序列创建一个 memoryview, # 然后使用 typecode 转换。 # 拆包转换后的 memoryview,得到构造方法所需的一对参数。 typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv) def __init__(self, x=0, y=0): # 把 x 和 y 转换成浮点数,尽早捕获错误, # 以防调用 Vector2d 函数时传入不当参数。 self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): # 定义 `__iter__` 方法,把 Vector2d 实例变成可迭代的对象 # 这样才能拆包(例如`x, y = my_vector`) # 这个方法的实现方式很简单,直接调用生成器表达式一个接一个产出分量. return (i for i in (self.x, self.y)) def __repr__(self): # `__repr__` 方法使用 `{!r}` 获取各个分量的表示形式,然后插值,构成一个字符串; #因为Vector2d 实例是可迭代的对象,所以 `*self` 会把` x `和` y `分量提供给 `format` 函数 class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): # 为了生成字节序列,我们把 typecode 转换成字节序列, #然后迭代 Vector2d 实例,得到一个数组,再把数组转换成字节序列. return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __format__(self, fmt_spec=''): # 使用内置的 format 函数把 fmt_spec 应用到向量的各个分量上,构建一个可迭代的格式化字符串。 # 再把格式化字符串代入公式 '(x, y)' 中。 if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) def __eq__(self, other): return tuple(self) == tuple(other) def __hash__(self): return hash(self.x) ^ hash(self.y) def __abs__(self): # 模是 x 和 y 分量构成的直角三角形的斜边长 return hypot(self.x, self.y) def __bool__(self): # __bool__ 方法使用 abs(self) 计算模,然后把结果转换成布尔值, # 因此,0.0 是 False,非零值是 True。 return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return type(self)(x, y) def __mul__(self, scalar): return type(self)(self.x * scalar, self.y * scalar) def angle(self): return atan2(self.y, self.x) def __complex__(self): return complex(self.x, self.y) v1 = Vector2D(3, 4) print(v1.x, v1.y) 3.0 4.0 x, y = v1 x,y (3.0, 4.0) v1 Vector2D(3.0, 4.0) v1_clone = eval(repr(v1)) v1 == v1_clone True print(v1) (3.0, 4.0) octets = bytes(v1) octets b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@' abs(v1) 5.0 bool(v1), bool(Vector2D(0, 0)) (True, False) 对象表示形式 每门面向对象的语言至少都有一种获取对象的字符串表示形式的标准方式.Python提供了两种方式. repr() 以便于开发者理解的方式返回对象的字符串表示形式. str() 以便于用户理解的方式返回对象的字符串表示形式. 估计你也猜到了,我们要实现接口__repr_ 和__str__特殊方法,为repr()和str()提供支持. 为了给对象提供其他的表示形式,还会用到另外两个特殊方法: __bytes__ __bytes__ 方法与__str__方法类似:bytes()函数调用它获取对象的字节序列表示形式. __format__ __format__方法会被内置的format()函数和str.format()方法调用,使用特殊的格式代码显示对象的字符串表示形式. 格式化显示 内置的format()函数和str.format()方法把各个类型的格式化方式委托给相应的.__format__(format_spec)方法.format_spec是格式说明符,它是: format(my_obj, format_spec)的第二个参数,或者 str.format()方法的格式字符串,{}里代换字段中冒号后面的部分 brl = 1/2.43 brl 0.4115226337448559 format(brl, '0.4f') '0.4115' '1 BRL = {rate:0.2f} USD'.format(rate=brl) '1 BRL = 0.41 USD' 格式规范微语言为一些内置类型提供了专用的表示代码。比如,b和x分别表示二进制和十六进制的 int 类型,f表示小数形式的float类型,而%表示百分数形式 format(42, 'b') '101010' format(2/3, '.1%') '66.7%' 格式规范微语言是可扩展的,因为各个类可以自行决定如何解释format_spec参数。例如,datetime模块中的类,它们的 __format__方法使用的格式代码与strftime()函数一样.下面是内置的format()函数和str.format()方法的几个示例: from datetime import datetime now = datetime.now() format(now, '%H:%M:%S') '23:01:26' \"It's now {:%I:%M %p}\".format(now) \"It's now 11:01 PM\" 如果类没有定义__format__方法,从object继承的方法会返回str(my_object)我们为Vector2D类定义了__str__方法,因此可以这样做. 我们实现自己的微语言来解决这个问题。首先,假设用户提供的格式说明符是用于格式化向量中各个浮点数分量的. 要在微语言中添加一个自定义的格式代码: 如果格式说明符以 'p' 结尾,那么在极坐标中显示向量,即,其中r是模,θ(西塔)是弧度;其他部分('p' 之前的部分)像往常那样解释。 为自定义的格式代码选择字母时,我会避免使用其他类型用过的字母.在格式规范微语言中我们看到, 整数使用的代码有'bcdoxXn' 浮点数使用的代码有'eEfFgGn%' 字符串使用的代码有's' 因此,我为极坐标选的代码是'p'(polar coordinates)。各个类使用自己的方式解释格式代码,在自定义的格式代码中重复使用代码字母不会出错,但是可能会让用户困惑。 对极坐标来说,我们已经定义了计算模的__abs__方法,因此还要定义一个简单的angle方法,使用math.atan2()函数计算角度 这样便可以增强__format__方法,计算极坐标. v1 = Vector2D(3, 4) format(v1) '(3.0, 4.0)' format(v1, '.3f') '(3.000, 4.000)' format(v1, '.3e') '(3.000e+00, 4.000e+00)' format(Vector2D(1, 1), 'p') '' format(Vector2D(1, 1), '.3ep') '' format(Vector2D(1, 1), '0.5fp') '' 静态方法和类方法 Python使用classmethod和staticmethod装饰器声明类方法和静态方法.学过Java面向对象编程的人可能觉得奇怪,为什么Python提供两个这样的装饰器,而不是只提供一个?java中只有静态方法. 先来看classmethod它的用法:定义操作类,而不是操作实例的方法.classmethod改变了调用方法的方式,因此类方法的第一个参数是类本身,而不是实例.classmethod最常见的用途是定义备选构造方法. 再看staticmethod装饰器也会改变方法的调用方式,但是第一个参数不是特殊的值.其实,静态方法就是普通的函数,只是碰巧在类的定义体中,而不是在模块层定义. classmethod装饰器非常有用,但是我从未见过不得不用staticmethod的情况.如果想定义不需要与类交互的函数,那么在模块中定义就好了.有时,函数虽然从不处理类,但是函数的功能与类紧密相关,因此想把它放在近处。即便如此,在同一模块中的类前面或后面定义函数也就行了. 下面的例子是静态方法与类方法的对比 class Demo: @classmethod def klassmeth(*args): return args @staticmethod def statmeth(*args): return args Demo.klassmeth() (__main__.Demo,) Demo.klassmeth('spam') (__main__.Demo, 'spam') Demo.statmeth() () Demo.statmeth('spam') ('spam',) 备选构造方法 我们可以把Vector2D实例转换成字节序列了;同理,也应该能从字节序列转换成Vector2D实例. 在标准库中探索一番之后,我们发现array.array有个类方法 .frombytes正好符合需求. v1 = Vector2D(3, 4) v1 Vector2D(3.0, 4.0) vb1 = bytes(v1) vb1 b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@' v2 = Vector2D.frombytes(vb1) v2 Vector2D(3.0, 4.0) 可散列的对象 如果对象不是可散列的,那么就不能放入集合(set)中,而要可散列必须保证3点: 必须实现__hash__方法 必须实现__eq__ 方法 要让向量不可变 使用特性让对象的分量只读. property装饰器可以把读值方法标记为特性. 我们让这些向量不可变是有原因的,因为这样才能实现__hash__方法.这个方法应该返回一个整数,理想情况下还要考虑对象属性的散列值(__eq__方法也要使用),因为相等的对象应该具有相同的散列值.Vector2d.__hash__方法的代码十分简单--使用位运算符异或(^)混合各分量的散列值. 要想创建可散列的类型,不一定要实现特性,也不一定要保护实例属性.只需正确地实现 __hash__ 和 __eq__ 方法即可.但是,实例的散列值绝不应该变化,因此我们借机提到了只读特性. Python的私有属性和“受保护的”属性 Python不能像Java那样使用private修饰符创建私有属性,但是Python有个简单的机制,能避免子类意外覆盖\"私有\"属性. 举个例子:有人编写了一个名为Dog的类,这个类的内部用到了mood实例属性,但是没有将其开放.现在,你创建了Dog类的子类:Beagle.如果你在毫不知情的情况下又创建了名为mood的实例属性,那么在继承的方法中就会把Dog类的mood属性覆盖掉.这是个难以调试的问题. 为了避免这种情况,如果以__mood的形式(两个前导下划线,尾部没有或最多有一个下划线)命名实例属性,Python会把属性名存入实例的__dict__属性中,而且会在前面加上一个下划线和类名.因此,对Dog类来说,__mood会变成_Dog__mood;对Beagle类来说,会变成_Beagle__mood.这个语言特性叫名称改写(name mangling)。 名称改写是一种安全措施,不能保证万无一失:它的目的是避免意外访问,不能防止故意做错事,只要知道改写私有属性名的机制,任何人都能直接读取私有属性——这对调试和序列化倒是有用.此外,只要编写v1._Vector__x = 7这样的代码,就能轻松地为 Vector2D实例的私有分量直接赋值.如果真在生产环境中这么做了,出问题时可别抱怨. 不是所有Python程序员都喜欢名称改写功能,也不是所有人都喜欢 self.__x 这种不对称的名称。有些人不喜欢这种句法,他们约定使用一个下划线前缀编写\"受保护\"的属性(如self._x)。批评使用两个下划线这种改写机制的人认为,应该使用命名约定来避免意外覆盖属性.Ian Bicking 有一句话,那句话的完整表述如下: 绝对不要使用两个前导下划线,这是很烦人的自私行为。如果担心名称冲突, 应该明确使用一种名称改写方式(如 `_MyThing_blahblah`)。 这其实与使用双下划线一样, 不过自己定的规则比双下划线易于理解。 Python解释器不会对使用单个下划线的属性名做特殊处理,不过这是很多 Python 程序员严格遵守的约定,他们不会在类外部访问这种属性.遵守使用一个下划线标记对象的私有属性很容易,就像遵守使用全大写字母编写常量那样容易. Python文档的某些角落把使用一个下划线前缀标记的属性称为\"受保护的\"属性.使用self._x这种形式保护属性的做法很常见,但是很少有人把这种属性叫作\"受保护的\"属性.有些人甚至将其称为\"私有\"属性. 总之,Vector2D的分量都是\"私有的\",而且Vector2D实例都是\"不可变的\"。我用了两对引号,这是因为并不能真正实现私有和不可变. 使用__slots__类属性节省空间 默认情况下,Python在各个实例中名为__dict__的字典里存储实例属性. 为了使用底层的散列表提升访问速度,字典会消耗大量内存.如果要处理数百万个属性不多的实例,通过__slots__类属性,能节省大量内存,方法是让解释器在元组中存储实例 属性,而不用字典. 继承自超类的__slots__属性没有效果.Python只会使用各个类中定义的__slots__属性. 定义__slots__的方式是,创建一个类属性,使用__slots__这个名字,并把它的值设为 一个字符串构成的可迭代对象,其中各个元素表示各个实例属性。我喜欢使用元组,因为这样定义的__slots__中所含的信息不会变化 在类中定义__slots__属性的目的是告诉解释器:\"这个类中的所有实例属性都在这儿了!\"这样,Python会在各个实例中使用类似元组的结构存储实例变量,从而避免使用消耗内存的__dict__属性.如果有数百万个实例同时活动,这样做能节省大量内存 在类中定义__slots__属性之后,实例不能再有__slots__中所列名称之外的其他属性.这只是一个副作用,不是__slots__存在的真正原因.不要使用__slots__属性禁止类的用户新增实例属性.__slots__是用于优化的,不是为了约束程序员. 然而,\"节省的内存也可能被再次吃掉\":如果把__dict__这个名称添加到__slots__中,实例会在元组中保存各个实例的属性,此外还支持动态创建属性,这些属性存储在常规的__dict__中.当然,把 __dict__ 添加到__slots__中可能完全违背了初衷,这取决于各个实例的静态属性和动态属性的数量及其用法.粗心的优化甚至比提早优化还糟糕. 此外,还有一个实例属性可能需要注意,即__weakref__属性,为了让对象支持弱引用,必须有这个属性.用户定义的类中默认就有__weakref__属性.可是,如果类中定义了__slots__属性,而且想把实例作为弱引用的目标,那么要把 __weakref__添加到__slots__中. 综上,__slots__属性有些需要注意的地方,而且不能滥用,不能使用它限制用户能赋值的属性.处理列表数据时__slots__ 属性最有用,例如模式固定的数据库记录,以及特大型数据集. __slots__的问题 总之,如果使用得当,__slots__能显著节省内存,不过有几点要注意. 每个子类都要定义 __slots__ 属性,因为解释器会忽略继承的 __slots__ 属性。 实例只能拥有 __slots__ 中列出的属性,除非把 __dict__ 加入 __slots__ 中(这样做就失去了节省内存的功效)。 如果不把 __weakref__ 加入 __slots__,实例就不能作为弱引用的目标. 如果你的程序不用处理数百万个实例,或许不值得费劲去创建不寻常的类,那就禁止它创 建动态属性或者不支持弱引用.与其他优化措施一样,仅当权衡当下的需求并仔细搜集资料后证明确实有必要时,才应该使用__slots__属性. 覆盖类属性 Python有个很独特的特性:类属性可用于为实例属性提供默认值。Vector2D中有个typecode类属性,__bytes__方法两次用到了它,而且都故意使用self.typecode读取它的值.因为Vector2D实例本身没有typecode属性,所以self.typecode默认获取的是Vector2D.typecode类属性的值. 但是,如果为不存在的实例属性赋值,会新建实例属性.假如我们为typecode实例属性赋值,那么同名类属性不受影响.然而,自此之后,实例读取的self.typecode是实例属性typecode,也就是把同名类属性遮盖了.借助这一特性,可以为各个实例的 typecode属性定制不同的值. Vector2D.typecode 属性的默认值是'd',即转换成字节序列时使用8字节双精度浮点数表示向量的各个分量.如果在转换之前把Vector2D实例的typecode属性设为'f',那么使用4字节单精度浮点数表示各个分量. 现在你应该知道为什么要在得到的字节序列前面加上typecode的值了:为了支持不同的格式.如果想修改类属性的值,必须直接在类上修改,不能通过实例修改.如果想修改所有实例(没有typecode实例变量)的typecode属性的默认值,可以这么做: Vector2d.typecode = 'f' 然而,有种修改方法更符合Python风格,而且效果持久,也更有针对性.类属性是公开的,因此会被子类继承,于是经常会创建一个子类,只用于定制类的数据属性. v11 = Vector2D(3, 4) v11.x, v11.y (3.0, 4.0) v11.x = 123 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 v11.x = 123 AttributeError: can't set attribute v22 = Vector2D(3.1, 4.2) hash(v11), hash(v22) (7, 384307168202284039) len(set([v11, v22])) 2 用于构建,解构,反射对象的工具 __new__构造运算符 也就是面向对象编程中常提到的构造方法了 这是一旦被调用就会执行的运算符,也是正常情况下一个实例第一个执行的运算符.该方法会返回一个对应对象的实例.我们来看看他的特性. 例: 建立一个可以记录调用次数的类 class Count_new: counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return super(Count_new,cls).__new__(cls) Count_new()#没有指定变量也会返回一个对象 1 times has been called. a = Count_new() 2 times has been called. __init__实例初始化 最常见的运算符重载应用就是__init__方法了,即实例初始化方法.该方法无返回值. 这个方法我们在将继承的时候就有过接触,所以不多说,主要看看他和__new__的关系. __new__运算符返回的是一个对象,这个对象就是类对象 class Count_new_init: counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return object.__new__(cls) def __init__(self): self.name = self.counter Count_new_init() 1 times has been called. My name is 4 , you've Created me! a = Count_new_init() 2 times has been called. My name is 8 , you've Created me! b = Count_new_init() 3 times has been called. My name is 12 , you've Created me! c = b.__new__(Count_new_init) 4 times has been called. d = c.__init__() My name is 16 , you've Created me! e = a.__new__(Count_new_init) 5 times has been called. __del__析构运算符 析构运算符__del__定义当对象实例被删除或者释放时的操作,继续修改那个例子 class Count_new_init__del(object): counter = 0 def __new__(cls): cls.counter += 1 print(cls.counter,\" times has been called. \") return super(Count_new_init__del,cls).__new__(cls) def __init__(self): self.name = self.counter c = Count_new_init__del() 1 times has been called. My name is 4 , you've Created me! c = 1 I'm 4 , I'll leave now! d = Count_new_init__del() 2 times has been called. My name is 8 , you've Created me! del d I'm 8 , I'll leave now! __dir__()反射实现的所有属性,包括特殊方法 v11.__dir__() ['__module__', 'typecode', '__slots__', 'frombytes', '__init__', 'x', 'y', '__iter__', '__repr__', '__str__', '__bytes__', '__format__', '__eq__', '__hash__', '__abs__', '__bool__', '__add__', '__mul__', 'angle', '__complex__', '_Vector2D__x', '_Vector2D__y', '__doc__', '__getattribute__', '__setattr__', '__delattr__', '__lt__', '__le__', '__ne__', '__gt__', '__ge__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__sizeof__', '__dir__', '__class__'] __class__反射对象所属的类 v11.__class__ __main__.Vector2D __sizeof__()反射对象所占的内存空间 v11.__sizeof__() 32 类作为对象 python中类也是对象,Python数据模型为每个类定义了很多属性. cls.__class__ 构造类对象的对象(元类) cls.__bases__ 由类的基类组成的元组. cls.__qualname__和cls.__name__ Python 3.3新引入的属性,其值是类或函数的限定名称,即从模块的全局作用域到类的点分路径.内部类ClassTwo的 __qualname__ 属性,其值是字符串'ClassOne.ClassTwo',而__name__属性的值是'ClassTwo'. cls.__subclasses__() 这个方法返回一个列表,包含类的直接子类.这个方法的实现使用弱引用,防止在超类和子类(子类在__bases__属性中储存指向超类的强引用)之间出现循环引用.这个方法返回的列表中是内存里现存的子类. cls.__mro__ 记录类的继承顺序 cls.mro() 构建类时,如果需要获取储存在类属性__mro__ 中的超类元组,解释器会调用这个方法.元类可以覆盖这个方法,定制要构建的类解析方法的顺序. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 00:47:12 "},"面向对象惯用法/协议与接口与抽象基类.html":{"url":"面向对象惯用法/协议与接口与抽象基类.html","title":"协议,接口与抽象基类","keywords":"","body":"协议和鸭子类型 在 Python 中创建功能完善的序列类型无需使用继承,只需实现符合序列协议的方法。不过,这里说的协议是什么呢? 在面向对象编程中,协议是非正式的接口,只在文档中定义(也可以在typehint中定义),在代码中不定义.例如, Python的序列协议只需要 __len__ 和 __getitem__ 两个方法.任何类(如Spam),只要使用标准的签名和语义实现了这两个方法,就能用在任何期待序列的地方.Spam是不是哪个类的子类无关紧要,只要提供了所需的方法即可. Python文化中的接口和协议 引入抽象基类之前,Python就已经非常成功了,即便现在也很少有代码使用抽象基类. 我们把协议定义为非正式的接口,是让Python这种动态类型语言实现多态的方式. 接口在动态类型语言中是怎么运作的呢? 首先， 基本的事实是，Python 语言没有interface关键字，而且除了抽象基类，每个类都有接口： 类实现或继承的公开属性，包括特殊方法，如__getitem__ 或__add__. 按照定义，受保护的属性和私有属性不在接口中：即便\"受保护的\"属性也只是采用命名约定实现的(单个前导下划线),私有属性可以轻松地访问，原因也是如此.不要违背这些约定. 另一方面，不要觉得把公开数据属性放入对象的接口中不妥，因为如果需要，总能实现读值方法和设值方法，把数据属性变成特性，使用obj.attr句法的客户代码不会受到影响. 关于接口，这里有个实用的补充定义： 对象公开方法的子集，让对象在系统中扮演特定的角色. Python文档中的“文件类对象”或“可迭代对象”就是这个意思，这种说法指的不是特定的类.接口是实现特定角色的方法集合，其他动态语言社区都借鉴了这个术语.协议与继承没有关系。一个类可能会实现多个接口，从而让实例扮演多个角色. 协议是接口，但不是正式的(只由文档和约定定义)，因此协议不能像正式接口那样施加限制(后面会说明抽象基类对接口一致性的强制).一个类可能只实现部分接口，这是允许的。有时，某些API 只要求\"文件类对象\"返回字节序列的.read()方法.在特定的上下文中可能需要其他文件操作方法，也可能不需要. 对Python 程序员来说，“X 类对象”“X 协议”和“X 接口”都是一个意思. 抽象基类和白鹅类型 我们讲\"当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\" 鸭子类型忽略对象的真正类型，转而关注对象有没有实现所需的方法、签名和语义.对Python来说，这基本上是指避免使用isinstance检查对象的类型,这样做没有任何好处，甚至禁止最简单的继承方式. 然而从进化的角度讲,平行进化往往会导致不相关的种产生相似的特征，形态和举止方面都是如此，但是生态位的相似性是偶然的，不同的种仍属不同的生态位。编程语言中也有这种“偶然的相似性”，比如说下述经典的面向对象编程示例 class Artist: def draw(self): pass class Gunslinger: def draw(self): pass class Lottery: def draw(self): pass 语言上的歧义造成了完全不应相关的两个类有着一样的接口,因此我们需要额外的外部知识来将鸭子类型提供的等价性维持在一定的层次上. 这种时候我们应该有这样的一种规定: 只要cls是抽象基类， 即cls的元类是abc.ABCMeta， 就可以使用isinstance(obj, cls) 这一思想来自于Alex Martelli的一篇文章,他管这叫白鹅类型,在流畅的python一书中有引用. 继承抽象基类很简单，只需要实现所需的方 法，这样也能明确表明开发者的意图。这一意图还能通过注册虚拟子类来实现。 此外，使用isinstance 和issubclass 测试抽象基类更为人接受。过去，这两个函数用来 测试鸭子类型，但用于抽象基类会更灵活。毕竟，如果某个组件没有继承抽象基类，事后 还可以注册，让显式类型检查通过。 然而，即便是抽象基类，也不能滥用isinstance 检查，用得多了可能导致代码异味，即表 明面向对象设计得不好。在一连串if/elif/elif 中使用isinstance 做检查，然后根据对 象的类型执行不同的操作，通常是不好的做法；此时应该使用多态，即采用一定的方式定 义类，让解释器把调用分派给正确的方法，而不使用if/elif/elif 块硬编码分派逻辑 另一方面，如果必须强制执行API 契约，通常可以使用isinstance 检查抽象基类。“老兄， 如果你想调用我，必须实现这个”，正如本书技术审校Lennart Regebro 所说的。这对采用插 入式架构的系统来说特别有用。在框架之外，鸭子类型通常比类型检查更简单，也更灵活。 要抑制住创建抽象基类的冲动。滥用抽象基类会造成 灾难性后果，表明语言太注重表面形式，这对以实用和务实著称的Python 可不是好事。 标准库中的抽象基类 从Python 2.6 开始，标准库提供了抽象基类。大多数抽象基类在collections.abc模块中定义，不过其他地方也有.例如，numbers 和io包中有一些抽象基类.但是,collections.abc 中的抽象基类最常用.我们来看看这个模块中有哪些抽象基类. collections.abc模块中的抽象基类 标准库中有两个名为abc的模块，这里说的是collections.abc.为了减少加载时间，Python 3.4在collections包之外实现这个模块,因此要与collections 分开导入.另一个abc模块就是abc这里定义的是abc.ABC 类.每个抽象基类都依赖这个类，但是不用导入它，除非定义新抽象基类. collections.abc中定义了如下容器抽象基类: ABC 继承自 抽象方法 Mixin 方法 Container --- __contains__ --- Hashable --- __hash__ --- Iterable --- __iter__ --- Iterator Iterable __next__ __iter__ Reversible Iterable __reversed__ --- Generator Iterator send, throw close, __iter__, __next__ Sized --- __len__ --- Callable --- __call__ --- Collection Sized, Iterable, Container __contains__, __iter__,__len__ --- Sequence Reversible, Collection __getitem__, __len__ __contains__, __iter__, __reversed__, index,count MutableSequence Sequence __getitem__, __setitem__,__delitem__, __len__, insert Sequence实现的方法以及append,reverse, extend,pop, remove, __iadd__ ByteString Sequence __getitem__,__len__ Sequence实现的方法 Set Collection __contains__, __iter__, __len__ __le__, __lt__, __eq__, __ne__, __gt__, __ge__, __and__, __or__,__sub__, __xor__,isdisjoint MutableSet Set __contains__,__iter__, __len__, add, discard Set实现的方法以及clear, pop, remove, __ior__,__iand__,__ixor__, __isub__ Mapping Collection __getitem__, __iter__, __len__ __contains__,keys, items, values, get, __eq__, __ne__ MutableMapping Mapping __getitem__, __setitem__, __delitem__, __iter__, __len__ Mapping实现的方法以及pop, popitem, clear,update, setdefault MappingView Sized --- __len__ ItemsView MappingView, Set --- __contains__, __iter__ KeysView MappingView, Set --- __contains__,__iter__ ValuesView MappingView --- __contains__, __iter__ Awaitable --- __await__ --- Coroutine Awaitable send,throw close AsyncIterable --- __aiter__ --- AsyncIterator AsyncIterable __anext__ __aiter__ AsyncGenerator AsyncIterator asend, athrow aclose, __aiter__, __anext__ 除此之外,其中还包括了两个特殊的抽象基类: Callable Hashable 这两个抽象基类与集合没有太大的关系，只不过因为collections.abc是标准库中定义抽象基类的第一个模块，而它们又太重要了，因此才把它们放到其中 .这两个抽象基类的主要作用是为内置函数isinstance提供支持，以一种安全的方式判断对象能不能调用或散列. numbers模块中的抽象基类 numbers包定义的是\"数字塔\"(即各个抽象基类的层次结构是线性的)，其中Number是位于最顶端的超类，随后是Complex子类，依次往下，最底端是Integral 类： Number Complex Real Rational Integral 因此,如果想检查一个数是不是整数.可以使用isinstance(x, numbers.Integral),这样代码就能接受int、bool(int 的子类),或者外部库使用numbers抽象基类注册的其他类型.为了满足检查的需要,你或者你的API的用户始终可以把兼容的类型注册为numbers.Integral的虚拟子类. 与之类似，如果一个值可能是浮点数类型，可以使用isinstance(x, numbers.Real)检查.这样代码就能接受bool、int、float、fractions.Fraction，或者外部库(如NumPy，它做了相应的注册)提供的非复数类型. decimal.Decimal没有注册为numbers.Real的虚拟子类,这有点奇怪.没注册的原因是,如果你的程序需要Decimal的精度,要防止与其他低精度数字 类型混淆,尤其是浮点数. 定义一个抽象基类 为了证明有必要定义抽象基类，我们要在框架中找到使用它的场景。想象一下这个场景： 你要在网站或移动应用中显示随机广告，但是在整个广告清单轮转一遍之前，不重复显示广告.假设我们在构建一个广告管理框架，名为ADAM.它的职责之一是，支持用户提供随机挑选的无重复类. 为了让ADAM 的用户明确理解\"随机挑选的无重复\"组件是什么意思，我们将定义一个抽象基类. 受到'栈'和'队列'启发，我将使用现实世界中的物品命名这个抽象基类： 宾果机和彩票机是随机从有限的集合中挑选物品的机器，选出的物品没有重复，直到选完为止. 我们把这个抽象基类命名为Tombola，这是宾果机和打乱数字的滚动容器的意大利名. Tombola 抽象基类有四个方法， 其中两个是抽象方法: load(...)：把元素放入容器. .pick()：从容器中随机拿出一个元素，返回选中的元素. 另外两个是具体方法: loaded()：如果容器中至少有一个元素，返回True。 inspect()：返回一个有序元组，由容器中的现有元素构成，不会修改容器的内容 定义抽象基类需要使用abc模块,继承abc.ABC就可以构建抽象基类,这样它就无法实例化, 装饰器@abc.abstractmethod则可以申明方法为抽象方法,而且定义体中通常只有文档字符串.其实,抽象方法可以有实现代码.即便实现了,子类也必须覆盖抽象方法,但是在子类中可以使用super()函数调用抽象方法，为它添加功能，而不是从头开始实现. 除了@abstractmethod之外，abc模块还定义了@abstractclassmethod、@abstractstaticmethod和@abstractproperty 三个装饰器.然而,后三个装饰器从Python 3.3 起废弃了，因为装饰器可以在@abstractmethod上堆叠，那三个就显得多余了.例如，声明抽象类方法的推荐方 式是： class MyABC(abc.ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ...): pass 注意:typehint应当使用@typing.overload标注子类中的抽象方法实现为方法覆写. import abc class Tombola(abc.ABC): @abc.abstractmethod def load(self, iterable): \"\"\"从可迭代对象中添加元素。\"\"\" pass @abc.abstractmethod def pick(self): \"\"\"随机删除元素，然后将其返回。 如果实例为空，这个方法应该抛出`LookupError`。 \"\"\" pass def loaded(self): \"\"\"如果至少有一个元素，返回`True`，否则返回`False`。\"\"\" return bool(self.inspect()) def inspect(self): \"\"\"返回一个有序元组，由当前元素构成。\"\"\" items = [] while True: try: items.append(self.pick()) except LookupError: break self.load(items) return tuple(sorted(items)) 使用__init_subclass__(cls)在基类中定义子类的初始化函数(3.6) 定制类的创建使用新协议进行了简化 Simpler customisation of class creation提供了一种可以在不使用元类的情况下自定义子类的方法.每当创建一个新的子类时，新的init_subclass类方法会被调用,可以将其理解为子类创建前的一个钩子： class PluginBase: subclasses = [] def __init_subclass__(cls, **kwargs): print(\"subclass\") super().__init_subclass__(**kwargs) cls.subclasses.append(cls) class Plugin1(PluginBase): def __init__(self): print(\"init\") class Plugin2(PluginBase): def __init__(self): print(\"init\") subclass subclass Plugin1() init Plugin2() init PluginBase.subclasses [__main__.Plugin1, __main__.Plugin2] 定义抽象基类的子类 定义好Tombola 抽象基类之后，我们要开发两个具体子类，满足Tombola规定的接口. import random class BingoCage(Tombola): def __init__(self, items): self._randomizer = random.SystemRandom() self._items = [] self.load(items) def load(self, items): self._items.extend(items) self._randomizer.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): self.pick() import random class LotteryBlower(Tombola): def __init__(self, iterable): self._balls = list(iterable) def load(self, iterable): self._balls.extend(iterable) def pick(self): try: position = random.randrange(len(self._balls)) except ValueError: raise LookupError('pick from empty LotteryBlower') return self._balls.pop(position) def loaded(self): return bool(self._balls) def inspect(self): return tuple(sorted(self._balls)) 白鹅类型的重要动态特性了：使用register 方法声明虚拟子类 python的抽象基类还有一个重要的实用优势：可以使用register类方法在终端用户的代码中把某个类\"声明\"为一个抽象基类的\"虚拟子类\"(为此，被注 册的类必须满足抽象基类对方法名称和签名的要求，最重要的是要满足底层语义契约.但是，开发那个类时不用了解抽象基类，更不用继承抽象基类).这大大地打破了严格的强耦合,与面向对象编程人员掌握的知识有很大出入，因此使用继承时要小心. 白鹅类型的一个基本特性(也是值得用水禽来命名的原因)：即便不继承，也有办法把一个类注册为抽象基类的虚拟子类.这样做时，我们保证注册的类忠实地实现了抽象基类定义的接口，而Python会相信我们，从而不做检查.如果我们说谎了，那么常规的运行时异常会把我们捕获. 注册虚拟子类的方式是在抽象基类上调用register方法。这么做之后，注册的类会变成抽象基类的虚拟子类，而且issubclass 和isinstance 等函数都能识别，但是注册的类不会从抽象基类中继承任何方法或属性. 虚拟子类不会继承注册的抽象基类，而且任何时候都不会检查它是否符合抽象基类的接口，即便在实例化时也不会检查。为了避免运行时错误，虚拟子类要实现所需的全部方法. register方法通常作为普通的函数调用，不过也可以作为装饰器使用.我们使用装饰器句法实现了TomboList类，这是Tombola 的一个虚拟子类. from random import randrange @Tombola.register class TomboList(list): def pick(self): if self: position = randrange(len(self)) return self.pop(position) else: raise LookupError('pop from empty TomboList') load = list.extend def loaded(self): return bool(self) def inspect(self): return tuple(sorted(self)) t = TomboList([12,23,34]) isinstance(t,Tombola) True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 21:38:50 "},"面向对象惯用法/多重继承和Mixin.html":{"url":"面向对象惯用法/多重继承和Mixin.html","title":"多重继承和Mixin","keywords":"","body":"多重继承 很多人觉得多重继承得不偿失.不支持多重继承的 Java 显然没有什么损失,C++ 对多重继承的滥用伤害了很多人,这可能还坚定了使用 Java 的决心.然而,Java的巨大成功和广泛影响,也导致很多刚接触Python的程序员没怎么见过真实的代码使用多重继承. 子类化内置类型很麻烦 在 Python 2.2 之前,内置类型(如list或dict)不能子类化。在Python2.2之后,内置类型可以子类化了,但是有个重要的注意事项--内置类型(使用 C 语言编写)不会调用用户定义的类覆盖的特殊方法. class DoppelDict(dict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) dd = DoppelDict(one=1) dd {'one': 1} dd['two'] = 2 dd {'one': 1, 'two': [2, 2]} dd.update(three=3) dd {'one': 1, 'three': 3, 'two': [2, 2]} 原生类型的这种行为违背了面向对象编程的一个基本原则:始终应该从实例(self)所 属的类开始搜索方法,即使在超类实现的类中调用也是如此。在这种糟糕的局面中, __missing__ 方法却能按预期方式工作,不过这只是特例. 不只实例内部的调用有这个问题(self.get()不调用self.__getitem__()),内置类型的方法调用的其他类的方法,如果被覆盖了,也不会被调用. 例子:dict.update方法会忽略AnswerDict.__getitem__方法 class AnswerDict(dict): def __getitem__(self, key): return 42 ad = AnswerDict(a='foo') ad['a'] 42 d = {} d.update(ad) d['a'] 'foo' d {'a': 'foo'} 直接子类化内置类型(如dict、list 或str)容易出错,因为内置类型的方法通常会忽略用户覆盖的方法.不要子类化内置类型,用户自己定义的类应该继承collections模块中的类,例如 UserDict、UserList 和 UserString,这些类做了特殊设计,因此 易于扩展. 如果不子类化 dict,而是子类化collections.UserDict,上面例子中暴露的问题便迎刃而解了 import collections class DoppelDict2(collections.UserDict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) dd = DoppelDict2(one=1) dd {'one': [1, 1]} dd['two'] = 2 dd {'one': [1, 1], 'two': [2, 2]} dd.update(three=3) dd {'one': [1, 1], 'two': [2, 2], 'three': [3, 3]} class AnswerDict2(collections.UserDict): def __getitem__(self, key): return 42 ad = AnswerDict2(a='foo') ad['a'] 42 d = {} d.update(ad) d['a'] 42 d {'a': 42} 多重继承和方法解析顺序 任何实现多重继承的语言都要处理潜在的命名冲突,这种冲突由不相关的祖先类实现同名方法引起。这种冲突称为'菱形问题' class A: def ping(self): print('ping:', self) class B(A): def pong(self): print('pong:', self) class C(A): def pong(self): print('PONG:', self) class D(B, C): def sp(self): return super() def ping(self): super().ping() print('post-ping:', self) def pingpong(self): self.ping() super().ping() self.pong() super().pong() C.pong(self) d = D() d.sp() > d.pong()# 直接调用 d.pong() 运行的是 B 类中的版本。 pong: C.pong(d) #超类中的方法都可以直接调用,此时要把实例作为显式参数传入 PONG: Python能区分d.pong()调用的是哪个方法,是因为Python会按照特定的顺序遍历继承图.这个顺序叫方法解析顺序(Method Resolution Order,MRO)。类都有一个名为__mro__的 属性,它的值是一个元组,按照方法解析顺序列出各个超类,从当前类一直向上,直到object类.D 类的__mro__ 属性如下: D.__mro__ (__main__.D, __main__.B, __main__.C, __main__.A, object) 若想把方法调用委托给超类,推荐的方式是使用内置的super()函数.在Python 3中,这 种方式变得更容易了. 然而,有时可能需要绕过方法解析顺序,直接调用某个超类的方法——这样做有时更方便。例如,D.ping方法可 以这样写: class D(B, C): def ping(self): A.ping(self) # 而不是super().ping() print('post-ping:', self) def pingpong(self): self.ping() super().ping() self.pong() super().pong() C.pong(self) d = D() d.ping() ping: post-ping: 使用super()处理父类引用 super()方法是python用于处理超类引用的推荐方法 super(type, obj_or_type) 会按照MRO的順序去委託type的超类或兄弟类的方法來调用.光super()则是会指向定义类时最左边的那个超类. 下例中: super().__init__(author) 会找到 并调用其__init__(author) super(Song, self).__init__(name) 会找到 並調用其 __init__(name) class Song(object): def __init__(self, author): self._author = author print(\"init Song\") class Singer(object): def __init__(self, name): self._name = name print(\"init Singer\") class Mtv(Song, Singer): def __init__(self, name, author): super().__init__(author) # init Song super(Song, self).__init__(name) # init Singer mtv = Mtv('name', 'author') init Song init Singer Mtv.__mro__ (__main__.Mtv, __main__.Song, __main__.Singer, object) Mixin 我们知道多重继承是危险的,很容易造成继承混乱,如何解决这个问题呢,就是使用mixin.原则上,应该只在使用Mixin组件制作工具时进行多重继承. mixin是一个行为的集合,是受限制的多重继承.mixin定义的这个行为可以被加到任意class里，然而在一些情况下，使用mix-in的类，可以要求宿主满足一些协议(contract),这个协议可以是属性也可以是方法. 如果有协议要求的话，协议应该是被声明在mixin内的.这样更容易复用. Mixin是一种非常谨慎的多重继承用法,它的特点是: Mixin 类是单一职责的 Mixin 类对宿主类一无所知 不存在超类方法调用（super）以避免引入 MRO 查找顺序问题 例:把内存中的python对象转换为字典形式 class ToDictMixin: def to_dict(self): return self._traverse_dict(self.__dict__) def _traverse_dict(self,instance_dict): output = {} for key,value in instance_dict.items(): output[key] = self._traverse(key,value) return output def _traverse(self,key,value): \"\"\"递归的将对象转化为字典形式\"\"\" if isinstance(value,ToDictMixin): return value.to_dict() elif isinstance(value,dict): return self._traverse_dict(value) elif isinstance(value,list): return [self._traverse(key,i) for i in value] elif hasattr(value,'__dict__'): return self._traverse_dict(value.__dict__) else: return value class BinaryTree(ToDictMixin): def __init__(self,value,left=None,right=None): self.value = value self.left = left self.right = right tree = BinaryTree(10, left=BinaryTree(7, right = BinaryTree(9)), right = BinaryTree(13, left = BinaryTree(11)) ) tree.to_dict() {'left': {'left': None, 'right': {'left': None, 'right': None, 'value': 9}, 'value': 7}, 'right': {'left': {'left': None, 'right': None, 'value': 11}, 'right': None, 'value': 13}, 'value': 10} Mixin最大的优势是使用者可以随时安插这些功能,并且可以在必要的时候覆写他们,比如二叉树中节点也要求有指向父节点的引用,那么上面的树就会陷入死循环,解决办法是可以在其中覆写_traverse方法以避免这个问题. class BinaryTreeWithParent(BinaryTree): def __init__(self,value,left=None,right=None,parent = None): super().__init__(value,left=left,right=right) self.parent = parent def _traverse(self,key,value): if isinstance(value,BinaryTreeWithParent) and key == 'parent': return value.value else: return super()._traverse(key,value) root = BinaryTreeWithParent(10) root.left = BinaryTreeWithParent(7,parent = root) root.left.right = BinaryTreeWithParent(9,parent = root.left) root.to_dict() {'left': {'left': None, 'parent': 10, 'right': {'left': None, 'parent': 7, 'right': None, 'value': 9}, 'value': 7}, 'parent': None, 'right': None, 'value': 10} 并且如果其他类的某个属性也是BinaryTreeWithParent,那么ToDictMixin也会自动处理好这些属性 class NamedSubTree(ToDictMixin): def __init__(self,name,tree_with_parent): self.name = name self.tree_with_parent = tree_with_parent mytree = NamedSubTree(\"foobar\",root.left.right) mytree.to_dict() {'name': 'foobar', 'tree_with_parent': {'left': None, 'parent': 7, 'right': None, 'value': 9}} 多个Mixin之间也可以相互转化组合,例如可以编写一个这样的Mixin,可以将任意类提供通用的JSON序列化功能.我们这个Mixin要求宿主类提供to_dict接口. from typing import Callable,Dict import json class JsonMixin: to_dict:Callable[...,Dict] @classmethod def from_json(cls,data): kwargs = json.loads(data) return cls(**kwargs) def to_json(self): return json.dumps(self.to_dict()) 有了这样的Mixin后,我们只需要极少的代码既可以通过继承体系轻松创建相关工具类. class NamedSubTree(ToDictMixin,JsonMixin): def __init__(self,name,tree_with_parent): self.name = name self.tree_with_parent = tree_with_parent mytree = NamedSubTree(\"foobar\",root.left.right) mytree.to_json() '{\"name\": \"foobar\", \"tree_with_parent\": {\"value\": 9, \"left\": null, \"right\": null, \"parent\": 7}}' 处理多重继承的原则 继承有很多用途,而多重继承增加了可选方案和复杂度.使用多重继承容易得出令人费解和脆弱的设计.我们还没有完整的理论,根据上面的内容,下面是总结的避免把类图搅乱的一些建议: 把接口继承和实现继承区分开 使用多重继承时,一定要明确一开始为什么创建子类。主要原因可能有: 继承接口,创建子类型,实现“是什么”关系 继承实现,通过重用避免代码重复 其实这两条经常同时出现,不过只要可能,一定要明确意图。通过继承重用代码是实现细 节,通常可以换用组合和委托模式。而接口继承则是框架的支柱. 使用抽象基类显式表示接口 现代的 Python 中,如果类的作用是定义接口,应该明确把它定义为抽象基类.Python 3.4及以上的版本中,我们要创建abc.ABC或其他抽象基类的子类. 通过混入重用代码 如果一个类的作用是为多个不相关的子类提供方法实现,从而实现重用,但不体现“是什么”关系,应该把那个类明确地定义为混入类(mixin class)。从概念上讲,混入不定义新类型,只是打包方法,便于重用.混入类绝对不能实例化,而且具体类不能只继承混入类.混入类应该提供某方面的特定行为,只实现少量关系非常紧密的方法. 在名称中明确指明混入 因为在Python中没有把类声明为混入的正规方式,所以强烈推荐在名称中加入 xxxMixin后缀. 抽象基类可以作为混入,反过来则不成立 抽象基类可以实现具体方法,因此也可以作为混入使用.不过,抽象基类会定义类型,而混入做不到.此外,抽象基类可以作为其他类的唯一基类,而混入决不能作为唯一的超类,除非继承另一个更具体的混入——真实的代码很少这样做. 抽象基类有个局限是混入没有的:抽象基类中实现的具体方法只能与抽象基类及其超类中的方法协作.这表明,抽象基类中的具体方法只是一种便利措施,因为这些方法所做的一切,用户调用抽象基类中的其他方法也能做到. 不要子类化多个具体类 具体类可以没有,或最多只有一个具体超类.也就是说,具体类的超类中除了这一个具体超类之外,其余的都是抽象基类或混入.例如,在下述代码中,如果 Alpha 是具体类,那么 Beta 和 Gamma 必须是抽象基类或混入: class MyConcreteClass(Alpha, Beta, Gamma): \"\"\"这是一个具体类,可以实例化。\"\"\" # ......更多代码...... 为用户提供聚合类 如果抽象基类或混入的组合对客户代码非常有用,那就提供一个类,使用易于理解的方式把它们结合起来.Grady Booch把这种类称为聚合类(aggregate class). 例如,下面是 tkinter.Widget 类的完整代码: class Widget(BaseWidget, Pack, Place, Grid): \"\"\"Internal class. Base class for a widget which can be positioned with the geometry managers Pack, Place or Grid. \"\"\" pass “优先使用对象组合,而不是类继承” 这句话引自\"设计模式:可复用面向对象软件的基础\"一书. 熟悉继承之后,就太容易过度使用它了。出于对秩序的诉求,我们喜欢按整洁的层次结构放置物品,程序员更是乐此不疲.然而,优先使用组合能让设计更灵活。例如,对 tkinter.Widget 类来说,它可以不从全部几何管理器中继承方法,而是在小组件实例中维护一个几何管理器引用,然后通过它调用 方法。毕竟,小组件“不是”几何管理器,但是可以通过委托使用相关的服务。这样,我 们可以放心添加新的几何管理器,不必担心会触动小组件类的层次结构,也不必担心名称 冲突。即便是单继承,这个原则也能提升灵活性,因为子类化是一种紧耦合,而且较高的 继承树容易倒.组合和委托可以代替混入,把行为提供给不同的类,但是不能取代接口继承去定义类型层次结构. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-04 23:01:46 "},"面向对象惯用法/自定义序列Vector.html":{"url":"面向对象惯用法/自定义序列Vector.html","title":"自定义序列Vector","keywords":"","body":"自定义序列Vector 本篇通过自定义Vector来看如何使用组合模式实现Vector类,而不使用继承.既然是使用组合,那么我们首先想到的就是Mixin. 向量的分量存储在浮点数数组中,而且还将实现不可变扁平序列所需的方法. 不过,在实现序列方法之前,我们要确保Vector类与之前定义的Vector2D类兼容,除非有些地方让二者兼容没有什么意义. 第一版--与Vector2D兼容 from array import array from typing import Sequence,Optional,Iterator import reprlib from math import sqrt class VectorBase: typecode:str = 'd' _components:Optional[array]=None def __init__(self, components:Sequence): self._components = array(self.typecode, components) self._dimension = None def __iter__(self)->Iterator: return iter(self._components) def __bool__(self)->bool: return bool(abs(self)) class DimensionMixin: _components:Optional[array]=None _dimension:Optional[int]=None def __len__(self)->int: return len(self._components) @property def dimension(self)->int: if not self._dimension: self._dimension = len(self) return self._dimension class AbsMixin: def __abs__(self)->float: return sqrt(sum(x * x for x in self)) from typing import Optional from array import array class LiteralMixin: _components:Optional[array]=None def __str__(self)->str: return str(tuple(self)) def __repr__(self)->str: \"\"\" 如果 Vector 实例的分量超过 6 个,`repr()` 生成的字符串就会使用 ... 省略一 部分, 包含大量元素的集合类型一定要这么做,因为字符串表示形式是用于调试的 (因此不想让大型对象在控制台或日 志中输出几千行内容). 使用 reprlib 模块可以生成长度有限的表示形式. \"\"\" components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector({})'.format(components) def __format__(self,fmt_spec='')->str: return NotImplemented from array import array class CodecMixin: typecode:str _components:Optional[array] def __bytes__(self)->bytes: return (bytes([ord(self.typecode)]) + bytes(self._components)) @classmethod def frombytes(cls, octets:bytes)->'VectorBase': typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv) class Vector(VectorBase,DimensionMixin,AbsMixin, LiteralMixin,CodecMixin): pass Vector([3.1, 4.2]) Vector([3.1, 4.2]) Vector((3, 4, 5)) Vector([3.0, 4.0, 5.0]) Vector(range(10)) Vector([0.0, 1.0, 2.0, 3.0, 4.0, ...]) bytes(Vector(range(10))) b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@\\x00\\x00\\x00\\x00\\x00\\x00\\x1c@\\x00\\x00\\x00\\x00\\x00\\x00 @\\x00\\x00\\x00\\x00\\x00\\x00\"@' Vector.frombytes(b'd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@\\x00\\x00\\x00\\x00\\x00\\x00\\x1c@\\x00\\x00\\x00\\x00\\x00\\x00 @\\x00\\x00\\x00\\x00\\x00\\x00\"@') Vector([0.0, 1.0, 2.0, 3.0, 4.0, ...]) Vector([3.1, 4.2]).dimension 2 第二版--实现可切片的序列 实现可切片需要实现__len__ 和__getitem__,我们希望切片后得到的还是Vector.实际上切片是通过slice实现 class MySeq: def __getitem__(self, index): return index s = MySeq() s[1] 1 s[1:4] slice(1, 4, None) s[1:4:2] slice(1, 4, 2) s[1:4:2, 9] (slice(1, 4, 2), 9) s[1:4:2, 7:9] (slice(1, 4, 2), slice(7, 9, None)) 切片原理 slice是内置的类型.它有start、stop 和step数据属性，以及indices方法. indices这个方法有很大的作用，但是鲜为人知.help(slice.indices) 给出的信息如下: S.indices(len) -> (start, stop, stride) 给定长度为len的序列，计算S表示的扩展切片的起始（start）和结尾（stop）索引，以及步幅（stride）。超出边界的索引会被截掉，这与常规切片的处理方式一样. 换句话说,indices方法开放了内置序列实现的棘手逻辑，用于优雅地处理缺失索引和负数索引，以及长度超过目标序列的切片.这个方法会“整顿”元组，把start、stop 和stride都变成非负数，而且都落在指定长度序列的边界内. slice(None, 10, 2).indices(5) (0, 5, 2) slice(-3, None, None).indices(5) (2, 5, 1) from array import array import numbers from typing import Optional,Union class SliceMixin: \"\"\"需要实现`__len__`\"\"\" _components:array def __getitem__(self, index:int)->Optional[Union[VectorBase,float]]: cls = type(self) if isinstance(index, slice): return cls(self._components[index]) elif isinstance(index, numbers.Integral): return self._components[index] else: msg = '{cls.__name__} indices must be integers' raise TypeError(msg.format(cls=cls)) class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin): pass v7 = Vector(range(7)) v7[-1] 6.0 v7[1:4] Vector([1.0, 2.0, 3.0]) v7[-1:] Vector([6.0]) v7[1,2] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 v7[1,2] in __getitem__(self, index) 13 else: 14 msg = '{cls.__name__} indices must be integers' ---> 15 raise TypeError(msg.format(cls=cls)) TypeError: Vector indices must be integers 第三版 动态存取属性 Vector2D变成Vector 之后，就没办法通过名称访问向量的分量了（如v.x 和v.y）。现在我们处理的向量可能有大量分量.不过，若能通过单个字母访问前几个分量的话会比较方便.比如，用x、y 和z 代替v[0]、v[1] 和v[2]。 我们想额外提供下述句法，用于读取向量的前四个分量： v = Vector(range(10)) v.x >>> 0.0 v.y, v.z, v.t >>> (1.0, 2.0, 3.0) 在Vector2D中，我们使用@property装饰器把x 和y 标记为只读特性。我们可以在Vector中编写四个特性，但这样太麻烦。特殊方法__getattr__提供了更好的方式。 属性查找失败后，解释器会调用__getattr__方法.简单来说，对my_obj.x表达式: Python会检查my_obj实例有没有名为x的属性 如果没有，到类（my_obj.__class__）中查找 如果还没有，顺着继承树继续查找 如果依旧找不到，调用myobj 所属类中定义的`_getattr`方法，传入self 和属性名称的字符串形式（如'x'） 下例中列出的是我们为Vector类定义的__getattr__方法.这个方法的作用很简单，它检查所查找的属性是不是xyzt中的某个字母 from typing import Optional class DynamicAccessMixin: shortcut_names = 'xyzt' def __getattr__(self, name:str)->Optional[float]: cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 class Vector(VectorBase,AbsMixin, DimensionMixin,LiteralMixin,CodecMixin,SliceMixin,DynamicAccessMixin): pass v = Vector(range(5)) v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) v.x 0.0 v.x = 10 v.x 10 v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) 可以看到,：为v.x 赋值没有抛出错误，但是前后矛盾.上面之所以前后矛盾，是__getattr__的运作方式导致的： 仅当对象没有指定名称的属性时，Python才会调用那个方法，这是一种后备机制. 可是，像v.x = 10这样赋值之后，v对象有x属性了，因此使用v.x 获取x属性的值时不会调用__getattr__方法了，解释器直接返回绑定到v.x上的值，即10。另一方面，__getattr__方法的实现没有考虑到self._components之外的实例属性，而是从这个属性中获取shortcut_names中所列的“虚拟属性”. 为了避免这种前后矛盾的现象，我们要改写mixin中设置属性的逻辑 多数时候，如果实现了__getattr__ 方法，那么也要定义__setattr__ 方法，以防对象的行为不一致 class DynamicAccessMixin: shortcut_names = 'xyzt' def __getattr__(self, name:str)->Optional[float]: cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 bool: cls = type(self) if len(name) == 1: if name in cls.shortcut_names: error = 'readonly attribute {attr_name!r}' elif name.islower(): error = \"can't set attributes 'a' to 'z' in {cls_name!r}\" else: error = '' if error: msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) return True class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v = Vector(range(5)) v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) v.x 0.0 v.x = 10 v.x --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 v.x = 10 2 v.x in __setattr__(self, name, value) 1 class Vector(VectorBase,AbsMixin,DimensionMixin, LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin): 2 def __setattr__(self, name:str, value:float): ----> 3 self._setattr_error_handler(name) 4 super().__setattr__(name, value) in _setattr_error_handler(self, name) 21 if error: 22 msg = error.format(cls_name=cls.__name__, attr_name=name) ---> 23 raise AttributeError(msg) 24 return True AttributeError: readonly attribute 'x' v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) Vector类第4版：散列和快速等值测试 我们要再次实现__hash__ 方法。加上现有的__eq__ 方法，这会把Vector实例变成可散列的对象. 我们的散列方式就是计算各个分量的散列值,然后聚合求异或 from functools import reduce from operator import xor class HashableMixin: def __eq__(self, other:VectorBase)->VectorBase: \"\"\"使用`and`运算符的截断特性和迭代器工具惰性计算特性判断是否一致,一旦有不一致就会终止后面的计算\"\"\" return len(self) == len(other) and all(a == b for a, b in zip(self, other)) def __hash__(self)->int: hashes = (hash(x) for x in self._components) # return reduce(xor, hashes, 0) class Vector(VectorBase,AbsMixin, DimensionMixin,LiteralMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) Vector类第5版：格式化 Vector 类的__format__ 方法与Vector2D类的相似，但是不使用极坐标，而使用超球面坐标，因为Vector 类支持n个维度，而超过四维后，球体变成了“超球体”. 因此，我们会把自定义的格式后缀由'p' 变成'h'。 from math import sqrt,atan2,pi from typing import Tuple class HypersphereMixin: \"\"\"需要实现`__len__`\"\"\" def angle(self, n:int)->float: \"\"\"使用[\"n 维球体\"词条](http://en.wikipedia.org/wiki/N-sphere)中的公式计算某个角坐标\"\"\" r = sqrt(sum(x * x for x in self[n:])) a = atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] Tuple[float]: \"\"\"创建生成器表达式，按需计算所有角坐标\"\"\" return (self.angle(n) for n in range(1, len(self))) from itertools import chain class LiteralMixin: \"\"\"需要HypersphereMixin\"\"\" _components:Optional[array]=None def __str__(self)->str: return str(tuple(self)) def __repr__(self)->str: \"\"\" 如果 Vector 实例的分量超过 6 个,`repr()` 生成的字符串就会使用 ... 省略一 部分, 包含大量元素的集合类型一定要这么做,因为字符串表示形式是用于调试的 (因此不想让大型对象在控制台或日 志中输出几千行内容). 使用 reprlib 模块可以生成长度有限的表示形式. \"\"\" components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector({})'.format(components) def __format__(self,fmt_spec:str='')->str: if fmt_spec.endswith('h'): # 超球面坐标 fmt_spec = fmt_spec[:-1] coords = chain([abs(self)],self.angles()) outer_fmt = '' else: coords = self outer_fmt = '({})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(', '.join(components)) class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v = Vector(range(5)) format(v) '(0.0, 1.0, 2.0, 3.0, 4.0)' format(Vector([2, 2, 2, 2]), '.3eh') '' Vector类第6版:运算符重载 向量的求反运算就是每位求反 向量的求和运算就是对应位求和. 向量的标量乘法就是每位乘以一个常数 向量点乘则是各位相乘后再相加 class PositiveNegativeMixin: def __neg__(self)->VectorBase: cls = type(self) return cls(-x for x in self) def __pos__(self)->VectorBase: cls = type(self) return cls(self) from itertools import zip_longest class AddMixin: def __add__(self, other:VectorBase)->VectorBase: cls = type(self) if isinstance(other, cls) and self.dimension == other.dimension: try: pairs = zip_longest(self, other, fillvalue=0.0) result = cls(a + b for a, b in pairs) return result except TypeError: return NotImplemented else: return NotImplemented def __radd__(self, other:VectorBase)->VectorBase: print(\"radd\") return self + other import numbers class MulMixin: def __mul__(self, scalar:numbers.Real)->VectorBase: cls = type(self) if isinstance(scalar, numbers.Real): return cls(n * scalar for n in self) else: return NotImplemented def __rmul__(self, scalar:numbers.Real)->VectorBase: return self * scalar class MatmulMixin: def __matmul__(self, other:VectorBase)->float: cls = type(self) if isinstance(other,cls) and self.dimension == other.dimension: try: return sum(a * b for a, b in zip(self, other)) except TypeError: return NotImplemented else: return NotImplemented def __rmatmul__(self, other): return self @ other class CalculMixin(PositiveNegativeMixin,AddMixin,MulMixin,MatmulMixin): pass class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin, CalculMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v1 = Vector([1,2,3,4,5]) v2 = Vector([1,2,3,4,5,6]) v3 = Vector([5,4,3,2,1]) n = 10 v1+v2 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 v1+v2 TypeError: unsupported operand type(s) for +: 'Vector' and 'Vector' v1+v3 Vector([6.0, 6.0, 6.0, 6.0, 6.0]) v1*3 Vector([3.0, 6.0, 9.0, 12.0, 15.0]) 3*v1 Vector([3.0, 6.0, 9.0, 12.0, 15.0]) v1@v3 35.0 -v1 Vector([-1.0, -2.0, -3.0, -4.0, -5.0]) Vector类第7版:比较符号 使用==或者!=判断两个向量是否一致 class EqualityMixin: def __eq__(self, other): cls = type(self) if isinstance(other, cls): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) else: return NotImplemented class Vector(VectorBase, AbsMixin,DimensionMixin,CodecMixin,SliceMixin, DynamicAccessMixin,HashableMixin,HypersphereMixin,LiteralMixin, CalculMixin,EqualityMixin): def __setattr__(self, name:str, value:float): self._setattr_error_handler(name) super().__setattr__(name, value) v1 = Vector([1,2,3,4,5]) v2 = Vector([1,2,3,4,5,6]) v3 = Vector([1,2,3,4,5]) v1==v2 False v1==v3 True v1 != v2 True Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 00:46:21 "},"面向对象惯用法/结语.html":{"url":"面向对象惯用法/结语.html","title":"结语","keywords":"","body":"结语 想想哪些类是真正需要的 大多数程序员编写应用程序而不开发框架.即便是开发框架的那些人,多数时候(或大多数时候)也是在编写应用程序. 编写应用程序时,我们通常不用设计类的层次结构。我们至多会编写子类、继承抽象基类或框架提供的其他类. 作为应用程序开发者, 我们极少需要编写作为其他类的超类的类.我们自己编写的类几乎都是末端类(即继承树的叶子). 如果作为应用程序开发者,你发现自己在构建多层类层次结构,可能是发生了下述事件中的一个或多个. 你在重新发明轮子。去找框架或库,它们提供的组件可以在应用程序中重用. 你使用的框架设计不良。去寻找替代品. 你在过度设计.记住要遵守 KISS 原则. 你厌烦了编写应用程序,决定新造一个框架.恭喜,祝你好运! 这些事情你可能都会遇到: 你厌倦了,决定重新发明轮子,自己构建设计过度和不良的框架,因此不得不编写一个又一个类去解决鸡毛蒜皮的小事. 希望你能乐在其中, 至少得到应有的回报. python的封装--私有属性的安全性和保障性 Perl 不会强制你保护隐私。你应该待在客厅外,因为你没收到邀请,而不是因为 里面有把枪。 ——Larry Wall Perl 之父 Python 和 Perl 在很多方面的做法是截然相反的,但是Larry和Guido似乎都同意要保护对象的隐私. 我发现很多人都对Java提供的隐私保障推崇备至.可事实是,Java 的 private 和 protected 修饰符 往往只是为了防止意外(即一种安全措施).只有使用安全管理器部署应用时才能保障绝对安全,防止恶意访问; 但是,实际上很少有人这么做,即便在企业中也少见. 把协议当作非正式的接口 协议不是 Python 发明的。Smalltalk 团队,也就是\"面向对象\"的发明者,使用\"协议\"这个词表示现在我们称 之为接口的特性.某些 Smalltalk 编程环境允许程序员把一组方法标记为协议,但这只不过是一种文档, 用于辅助导航,语言不对其施加特定措施.因此,向熟悉正式(而且编译器会施加措施)接口的人解释\"协议\"时, 我会简单地说它是\"非正式的接口\". 动态类型语言中的既定协议会自然进化.所谓动态类型是指在运行时检查类型,因为方法签名和变量没有静态类型信息. Ruby是一门重要的面向对象动态类型语言,它也使用协议. 在 Python 文档中,如果看到\"文件类对象\"这样的表述,通常说的就是协议.这是一种简短的说法,意思是: \"行为基本与文件一致,实现了部分文件接口,满足上下文相关需求的东西.\" 你可能觉得只实现协议的一部分不够严谨,但是这样做的优点是简单. 不要为了满足过度设计的接口契约和让编译器开心,而去实现不需要的方法,我们要遵守KISS原则. 类型提示 2014年,Python世界最大的新闻应该是 Guido van Rossum 同意实现可选的静态类型检查,这与检查程序 Mypy(http://www.mypy-lang.org)的做法类似,即使用函数注解实现。这一消息出自 8 月 15 日发表在 Python-ideas邮件列表中的一个话题,题为 Optional static typing —the crossroads. 一个月后,“PEP 484—Type Hints”草案发布了,发起人是 Guido. 这个功能的目的是让程序员在函数定义中使用注解声明参数和返回值的类型,但这是可选的. 关键在于“可选”二字.仅当你想得到注解的好处和限制时才需要添加注解,而且可以在一些函数中添加,在另一些函数中不添加. 从表面上看,这与 Microsoft 对 TypeScript采取的方式类似,不过 TypeScript 做得更进一步: TypeScript 添加了新的语言结构(如模块、类、显式接口, 等等),允许声明变量类型,而且最终编译成常规的JavaScript 目前来看,Python的可选静态类型没这么大的雄心.但似乎cython团队打算好好利用这一语言特性. 为了理解这个提案的动机,不能忽略 Guido 在 2014 年 8 月 15 日发送的那封重要邮件中的这段话: 我还得做个假设:这个功能主要供 lint 程序、IDE 和文档生成工具使用.这些工具有个共同点:即使类型检查失败了,程序仍能运行。此外,程序中添加的类 型不能降低性能(也不能提升性能 :-)). 因此,这一举动并不像乍一看那么激进.PEP 484—Type Hints提到了PEP 482—Literature Overview for Type Hints,后者概述了第三方 Python 工具和其他语言实现类型提示的方式. 不管激进不激进,类型提示都已经到来: 最后,PEP 484明确指出: 还要强调一点,Python 依旧是一门动态类型语言,作者从未打算强制要求使用类型提示,甚至不会把它变成约定. 接口中的隐喻和习惯用法 隐喻能打破壁垒,让人更易于理解.使用\"栈\"和\"队列\"描述基本的数据类型就有这样的功效: 这两个词清楚地道出了添加或删除元素的方式. 另一方面,Alan Cooper 在《交互设计精髓(第 4 版)》中写道: 严格奉行隐喻设计毫无必要,却把界面死死地与物理世界的运行机制捆绑在一起. 他说的是用户界面,但对 API 同样适用。不过 Cooper 同意,当\"真正合适的\"隐喻\"正中下怀\"时,可以使用隐喻(他用的词是\"正中下怀\",因为合适的隐喻可遇不可求). Python 语言的基本协议就是 Cooper 所说的\"习惯用法\"。知道\"序列\"是什么之后,可以把这些知识应用到不同的场合. Python这门语言的学习最关键的就是学习基本惯用法,让你的代码简洁、高效且可读。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 22:12:57 "},"元编程/":{"url":"元编程/","title":"元编程","keywords":"","body":"元编程 Meta-这个前缀在希腊语中的本意是「在…后，越过…的」，类似于拉丁语的 post-，比如 metaphysics 就是「在物理学之后」，这个词最开始指一些亚里士多德的著作，因为它们通常排序在《物理学》之后。但西方哲学界在几千年中渐渐赋予该词缀一种全新的意义：关于某事自身的某事。比如meta-knowledge就是「关于知识本身的知识」，meta-data 就是「关于数据的数据」，meta-language 就是「关于语言的语言」，而 meta-programming 也是由此而来，是「关于编程的编程」。弄清了词源和字面意思，可知大陆将 meta-这个前缀译为「元」并不恰当。台湾译为「后设」，稍微好一点点，但仍旧无法望文生义。也许「自相关」是个不错的选择，「自相关数据」、「自相关语言」、「自相关编程」——但是好像又太罗嗦了。 怎样才算meta-programming呢？泛泛来说，只要是与编程相关的编程就算是meta-programming了——比如，若编程甲可以输出 A - Z，那么写程序甲算「编程」；而程序乙可以生成程序甲（也许还会连带着运行它输出 A - Z），那么编写程序乙的活动，就可以算作meta-programming，「元编程」.注意，程序甲和程序乙并不一定是同一种语言. 不过metaprogramming更狭义的意思应该是指「编写能改变语言语法特性或者运行时特性的程序」.换言之，一种语言本来做不到的事情，通过你编程来修改它，使得它可以做到了，这就是元编程. python有着一定程度的元编程能力,可以通过 动态编译 动态属性,特性,描述符 运算符重载 装饰器 元类编程 等手段编写能改变语言语法特性或者运行时特性的程序. 元编程常用于高度抽象,或者改造接口,它相对比较难以理解,一般也用不着.本部分主要讲这个技术. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 01:13:26 "},"元编程/导入时与运行时.html":{"url":"元编程/导入时与运行时.html","title":"导入时与运行时","keywords":"","body":"导入时与运行时 为了正确地做元编程，你必须知道Python解释器什么时候计算各个代码块.Python 程序员会区分“导入时”和“运行时”，不过这两个术语没有严格的定义，而且二者之间存在着灰色地带. 在导入时，解释器会从上到下一次性解析完.py 模块的源码，然后生成用于执行的字节码。如果句法有错误，就在此时报告。如果本地的__pycache__文件夹中有最新的.pyc 文件，解释器会跳过上述步骤，因为已经有运行所需的字节码了. 编译肯定是导入时的活动，不过那个时期还会做些其他事，因为Python 中的语句几乎都是可执行的，也就是说语句可能会运行用户代码，修改用户程序的状态。尤其是import语句，它不只是声明，在进程中首次导入模块时，还会运行所导入模块中的全部顶层代码——以后导入相同的模块则使用缓存，只做名称绑定。那些顶层代码可以做任何事，包括通常在“运行时”做的事，例如连接数据库. 因此，“导入时”与“运行时”之间的界线是模糊的： import 语句可以触发任何“运行时”行为。 导入模块时，解释器会执行顶层的def语句，可是这么做有什么作用呢？解释器会编译函数的定义体(首次导入模块时)，把函数对象绑定到对应的全局名称上，但是显然解释器不会执行函数的定义体。通常这意味着解释器在导入时定义顶层函数，但是仅当在运行时调用函数时才会执行函数的定义体。 对类来说，情况就不同了：在导入时，解释器会执行每个类的定义体，甚至会执行嵌套类 的定义体。执行类定义体的结果是，定义了类的属性和方法，并构建了类对象。从这个意 义上理解，类的定义体属于“顶层代码”，因为它在导入时运行。 上述说明模糊又抽象，下面通过练习理解各个时期所做的事情。 %%writefile evalsupport.py print(' evalsupport module start') def deco_alpha(cls): print(' deco_alpha') def inner_1(self): print(' deco_alpha:inner_1') cls.method_y = inner_1 return cls class MetaAleph(type): print(' MetaAleph body') def __init__(cls, name, bases, dic): print(' MetaAleph.__init__') def inner_2(self): print(' MetaAleph.__init__:inner_2') cls.method_z = inner_2 print(' evalsupport module end') Overwriting evalsupport.py %%writefile evaltime.py from evalsupport import deco_alpha print(' evaltime module start') class ClassOne(): print(' ClassOne body') def __init__(self): print(' ClassOne.__init__') def __del__(self): print(' ClassOne.__del__') def method_x(self): print(' ClassOne.method_x') class ClassTwo(object): print(' ClassTwo body') @deco_alpha class ClassThree(): print(' ClassThree body') def method_y(self): print(' ClassThree.method_y') class ClassFour(ClassThree): print(' ClassFour body') def method_y(self): print(' ClassFour.method_y') if __name__ == '__main__': print(' ClassOne tests', 30 * '.') one = ClassOne() one.method_x() print(' ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print(' ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print(' evaltime module end') Overwriting evaltime.py 场景1: 导入模块 解释器会执行所导入模块及其依赖（evalsupport）中的每个类定义体。 解释器先计算类的定义体，然后调用依附在类上的装饰器函数，这是合理的行为，因为必须先构建类对象，装饰器才有类对象可处理。 在这个场景中，只运行了一个用户定义的函数或方法——deco_alpha装饰器。 import evaltime evalsupport module start MetaAleph body evalsupport module end evaltime module start ClassOne body ClassTwo body ClassThree body deco_alpha ClassFour body evaltime module end 场景2:执行evaltime.py 场景2 主要想说明的是，类装饰器可能对子类没有影响.在示例中， 我们把ClassFour定义为ClassThree的子类.ClassThree类上依附的@deco_alpha装饰器把method_y方法替换掉了，但是这对ClassFour类根本没有影响. 当然，如果ClassFour.method_y方法使用super(...)调用ClassThree.method_y方法，我们便会看到装饰器起作用，执行inner_1函数. !python evaltime.py evalsupport module start MetaAleph body evalsupport module end evaltime module start ClassOne body ClassTwo body ClassThree body deco_alpha ClassFour body ClassOne tests .............................. ClassOne.__init__ ClassOne.method_x ClassThree tests .............................. deco_alpha:inner_1 ClassFour tests .............................. ClassFour.method_y evaltime module end ClassOne.__del__ Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 01:01:04 "},"元编程/猴子补丁和热更新.html":{"url":"元编程/猴子补丁和热更新.html","title":"猴子补丁和热更新","keywords":"","body":"使用猴子补丁在运行时对代码进行修改 Monkey patch就是在运行时对已有的代码进行修改，达到hot patch的目的 在运行时修改类或模块,而不改动源码,这种技术叫猴子补丁. 猴子补丁很强大,但是打补丁的代码与要打补丁的程序耦合十分紧密,而且往往要处理隐藏和没有文档的部分 使用猴子补丁在运行时修改模块中的对象 例: 修改math模块中pi和e的值 import math math.pi 3.141592653589793 math.pi = 3.14 math.pi 3.14 math.e 2.718281828459045 def patch_math(): math.e = 2.72 patch_math() math.e 2.72 取消猴子补丁 取消猴子补丁需要先取消模块的引入,之后再重新引入即可. 模块引入后会存放在sys.modules这个字典中.因此,要取消引入,只要删除该字典中的对应值即可 def run_e(): print(math.e) import sys def disable_patch(name): del sys.modules[name] module = __import__(name) sys.modules[name] = module globals()[name] = module math.e = 2.7 math.e 2.7 run_e() 2.7 disable_patch(\"math\") math.e 2.718281828459045 run_e() 2.718281828459045 热更新 另一个用于热更新的方式是使用imp.reload方法 %%writefile a.py A = 10 def powA(n): return n**A Overwriting a.py import a a.A 10 a.powA(2) 1024 %%writefile a.py A = 100 def powA(n): return n**A Overwriting a.py from imp import reload reload(a) a.A 100 a.powA(2) 1267650600228229401496703205376 总结: 猴子补丁和热更新需要直接使用import引入模块对象.这种技术常用于动态地在运行时修改模块 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 00:38:59 "},"元编程/动态编译.html":{"url":"元编程/动态编译.html","title":"动态编译","keywords":"","body":"动态编译 动态编译指的是在运行时接收字符串,动态的将其编译为python可执行的代码的功能. python提供了两个函数用于实现动态编译: exec 和eval 函数 eval(exp[, globals[, locals]]) globals是字典形式,表示全局命名空间,如果传入globals的字典中缺少__builtins__ 的时候,当前的全局命名空间将作为globals参数输入并在表达式计算之前被解析. locals则为任何映射对象,表示局部命名空间,与globals两者默认相同. 如果两者都省略则表示在eval的调用环境中执行 exec() 与eval()类似的是exec()方法,但exec是翻译并执行,因此我们上面的例子得写成 a = eval(\"lambda *x: sum(x)\") a(1,2,3,4,5) 15 %timeit a(1,2,3,4,5,6,7,8,9) 658 ns ± 56.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) %timeit lambda *x:sum(x)(1,2,3,4,5,6,7,8,9) 108 ns ± 3.79 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) exec(\"aa = lambda x: x\") aa(10) 10 eval和exec有两个弊端: 降低运算效率 如上面看到的,运行时间上差距不小 安全性 这主要是因为可以调用一些危险的方法而没有设限.也就是所谓的代码注入攻击. 当然了,我们也可以通过限制globals和locals来实现对可用项的限制. 如果只是为了传入参数,那么可以使用ast库的literal_eval函数,它是安全的 import ast ast.literal_eval(\"[1,2,3]\") [1, 2, 3] 在Python中做元编程时，最好不用exec 和eval 函数。如果接收的字符串（或片段）来自不可信的源，那么这两个函数会带来严重的安全风险.Python提供了充足的内省工具，大多数时候都不需要使用exec 和eval函数。然而，Python 核心开发者实现namedtuple函数时选择了使用exec 函数，这样做是为了让生成的类代码能通过._source获取. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 01:00:37 "},"元编程/运算符重载.html":{"url":"元编程/运算符重载.html","title":"运算符重载","keywords":"","body":"运算符重载 运算符重载在任何语言中都算得上是高级特性,因为它可以改变语言本身即元编程. Python支持有限的运算符重载,并有几个特殊的运算符可以改变类的一些特性. 受限制的运算符重载 在某些圈子中，运算符重载的名声并不好。这个语言特性可能(已经)被滥用，让程序员困惑，导致缺陷和意料之外的性能瓶颈.但是，如果使用得当，API 会变得好用，代码会变得易于阅读.Python 施加了一些限制，做好了灵活性、可用性和安全性方面的平衡： 不能重载内置类型的运算符 不能新建运算符，只能重载现有的 某些运算符不能重载——is、and、or 和not（不过位运算符&、| 和~ 可以） 下面是python所有可以重载的运算符以及对应的特殊方法: 一元运算符 特殊方法 + __pos__ - __neg__ ~ __invert__ abs(...) __abs__ 二元运算符 特殊方法 + __add__,__radd__ += __iaddr__ - __sub__,__rsub__ * __mul__,__rmul__ / __div__,__rdiv__,__truediv__,__rtruediv__ // __floordiv__,__rfloordiv__ % __mod__,__rmod__ ** __pow__,__rpow__ __lshift__,__rlshift__ >> __rshift__,__rrshift__ & __and__,__rand__ ^ __xor__,__rxor__ l __or__,__ror_ -= __isub__ *= __imul__ /= __idiv__,__itruediv__ //= __ifloordiv__ %= __imod__ **= __ipow__ __ilshift__ >>= __irshift__ &= __iand__ ^= __ixor__ l= __ior__ == __eq__ !=,<> __ne__ > __get__ __lt__ >= __ge__ __le__ @ __matmul__(),__rmatmul__() @= __imatmul__() 例: 定义一个数组类,实现减法索引打印等操作 class Array: def __init__(self,*args):#构造函数 self.value = args def __sub__(self,other):#减法运算符 if isinstance(other,(int ,float)): new = Array(*list(map(lambda x : x-other,self.value))) return new if isinstance(other,Array): new = Array(*list(map(lambda x,y : x-y,self.value,other.value))) return new else: raise ValueError(\"Illegal operations\") def __repr__(self):#打印 return \"Array: \"+str(self.value) def __str__(self):#字符串化 return \"Array: \"+str(self.value) def __getitem__(self,index):#索引分片,有了分片也就有了迭代,但不如迭代器好 new = Array(*self.value[index]) return new arr1=Array(1,2,3,4) arr2=Array(10,20,30,40) arr2-arr1 Array: (9, 18, 27, 36) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 00:59:21 "},"元编程/动态属性与特性与描述符.html":{"url":"元编程/动态属性与特性与描述符.html","title":"动态属性,特性与描述符","keywords":"","body":"属性 在Python中，数据的属性和处理数据的方法统称属性attribute.其实，方法只是可调用的属性. Python提供了丰富的API，用于控制属性的访问权限，以及实现动态属性. 使用点号访问属性时(如obj.attr)，Python解释器会调用特殊的方法(如__getattr__和__setattr__)计算属性.用户自己定义的类可以通过__getattr__方法实现“虚拟属性”.当访问不存在的属性时（如obj.no_such_attribute），即时计算属性的值. 动态创建属性照理说是一种元编程，框架的作者经常这么做.然而，在Python中，相关的基础技术十分简单，任何人都可以使用，甚至在日常的数据转换任务中也能用到.下面以这种任务开启本章的话题. 动态属性 python提供了处理动态属性相关的api 影响属性处理方式的特殊属性 __class__ 对象所属类的引用（即obj.__class__ 与type(obj) 的作用相同）.Python 的某些特殊方法，例如__getattr__，只在对象的类中寻找，而不在实例中寻找. __dict__ 一个映射，存储对象或类的可写属性.有__dict__ 属性的对象，任何时候都能随意设置新属性。如果类有__slots__属性，它的实例可能没有__dict__属性。参见下面对__slots__ 属性的说明. __slots__ 类可以定义这个这属性，限制实例能有哪些属性.__slots__属性的值是一个字符串组成的元组，指明允许有的属性.如果__slots__ 中没有'__dict__'，那么该类的实例没有__dict__ 属性，实例只允许有指定名称的属性。 处理属性的内置函数 下述5 个内置函数对对象的属性做读、写和内省操作. dir([object]) 列出对象的大多数属性.dir 函数的目的是交互式使用，因此没有提供完整的属性列表，只列出一组“重要的”属性名。dir 函数能审查有或没有__dict__属性的对象.dir函数不会列出__dict__属性本身，但会列出其中的键.dir 函数也不会列出类的几个特殊属性，例如__mro__、__bases__ 和__name__.如果没有指定可选的object 参数，dir 函数会列出当前作用域中的名称. getattr(object, name[, default]) 从object 对象中获取name字符串对应的属性.获取的属性可能来自对象所属的类或超类。如果没有指定的属性，getattr 函数抛出AttributeError异常，或者返回default参数的值(如果设定了这个参数的话). hasattr(object, name) 如果object对象中存在指定的属性，或者能以某种方式(例如继承)通过object对象获取指定的属性， 返回True setattr(object, name, value) 把object对象指定属性的值设为value，前提是object 对象能接受那个值.这个函数可能会创建一个新属性，或者覆盖现有的属性. vars([object]) 返回object对象的__dict__属性；如果实例所属的类定义了__slots__ 属性，实例没有__dict__ 属性，那么vars 函数不能处理那个实例(相反，dir 函数能处理这样的实例).如果没有指定参数，那么vars()函数的作用与locals()函数一样：返回表示本地作用域的字典. 处理属性的特殊方法 在用户自己定义的类中，下述特殊方法用于获取、设置、删除和列出属性. 使用点号或内置的getattr、hasattr 和setattr 函数存取属性都会触发下述列表中相应的特殊方法.但是，直接通过实例的__dict__属性读写属性不会触发这些特殊方法——如果需要，通常会使用这种方式跳过特殊方法. 对用户自己定义的类来说，如果隐式调用特殊方法，仅当特殊方法在对象所属的类型上定义，而不是在对象的实例字典中定义时，才能确保调用成功. 要假定特殊方法从类上获取，即便操作目标是实例也是如此。因此，特殊方法不会被同名实例属性遮盖。 __delattr__(self, name) 只要使用del语句删除属性，就会调用这个方法。例如，del obj.attr 语句触发Class.__delattr__(obj, 'attr')方法. __dir__(self) 把对象传给dir 函数时调用，列出属性。例如，dir(obj) 触发Class.__dir__(obj)方法. __getattr__(self, name) 仅当获取指定的属性失败，搜索过obj、Class和超类之后调用.表达式obj.no_such_attr、getattr(obj, 'no_such_attr') 和hasattr(obj, 'no_such_attr')可能会触发Class.__getattr__(obj, 'no_such_attr') 方法，但是，仅当在obj、Class 和超类中找不到指定的属性时才会触发. __getattribute__(self, name) 尝试获取指定的属性时总会调用这个方法，不过，寻找的属性是特殊属性或特殊方法时除外。点号与getattr 和hasattr 内置函数会触发这个方法.调用__getattribute__方法且抛出AttributeError 异常时， 才会调用__getattr__ 方法。为了在获取obj实例的属性时不导致无限递归，__getattribute__ 方法的实现要使用super().__getattribute__(obj, name)。 __setattr__(self, name, value) 尝试设置指定的属性时总会调用这个方法.点号和setattr内置函数会触发这个方法.例如，obj.attr = 42 和setattr(obj, 'attr', 42) 都会触发Class.__setattr__(obj,attr’, 42) 方法。 其实，特殊方法__getattribute__ 和__setattr__ 不管怎样都会调用，几乎会影响每一次属性存取，因此比__getattr__ 方法（只处理不存在的属性名）更难正确使用.与定义这些特殊方法相比，使用特性或描述符相对不易出错。 例子 我们要使用动态属性处理O’Reilly 为OSCON 2014 大会提供的JSON 格式数据源. 那个JSON源中有895条记录，整个数据集是一个JSON 对象，里面有一个键，名为\"Schedule\"；这个键对应的值也是一个映像，有4 个键：\"conferences\"、\"events\"、\"speakers\" 和\"venues\"。这4 个键对应的值都是一个记录列表。 列表中有成百上千条记录。不过，\"conferences\" 键对应的列表中只有一条记录，如上述示例所示。这4 个列表中的每个元素都有一个名为\"serial\" 的字段，这是元素在各个列表中的唯一标识符. 第一个脚本只用于下载那个OSCON 数据源.为了避免浪费流量，我会先检查本地有没有副本。这么做是合理的，因为OSCON 2014 大会已经结束，数据源不会再更新。 第一个例子没用到元编程，几乎所有代码的作用可以用这一个表达式概括：json.load(fp). 不过，这样足以处理那个数据集了.osconfeed.load 函数会在后面几个示例中用到. import requests import warnings import os import json URL = 'http://www.oreilly.com/pub/sc/osconfeed' JSON = 'osconfeed.json' def load(): if not os.path.exists(JSON): msg = 'downloading {} to {}'.format(URL, JSON) warnings.warn(msg) with open(JSON, 'w') as local: remote = requests.get(URL) json.dump(remote.json(),local) with open(JSON) as fp: return json.load(fp) raw_feed = load() sorted(raw_feed['Schedule'].keys()) ['conferences', 'events', 'speakers', 'venues'] for key, value in sorted(raw_feed['Schedule'].items()): print('{:3} {}'.format(len(value), key)) 1 conferences 494 events 357 speakers 53 venues raw_feed['Schedule']['speakers'][-1]['name'] 'Carina C. Zona' raw_feed['Schedule']['speakers'][-1]['serial'] 141590 raw_feed['Schedule']['events'][40]['name'] 'There *Will* Be Bugs' raw_feed['Schedule']['events'][40]['speakers'] [3471, 5199] 使用动态属性访问JSON类数据 feed['Schedule']['events'][40]['name'] 这种句法很冗长.在JavaScript中，可以使用feed.Schedule.events[40].name获取那个值。在Python 中，可以实现一个近似字典的类（网上有大量实现），达到同样的效果。我自己实现了FrozenJSON类，比大多数实现都简单，因为只支持读取，即只能访问数据。不过，这个类能递归，自动处理嵌套的映射和列表 from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __init__(self, mapping): self.__data = dict(mapping) def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) @classmethod def build(cls, obj): if isinstance(obj, abc.Mapping): return cls(obj) elif isinstance(obj, abc.MutableSequence): return [cls.build(item) for item in obj] else: return obj feed = FrozenJSON(raw_feed) len(feed.Schedule.speakers) 357 sorted(feed.Schedule.keys()) ['conferences', 'events', 'speakers', 'venues'] feed.Schedule.speakers[-1].name 'Carina C. Zona' talk = feed.Schedule.events[40] type(talk) __main__.FrozenJSON talk.name 'There *Will* Be Bugs' talk.speakers [3471, 5199] talk.flavor --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in () ----> 1 talk.flavor in __getattr__(self, name) 10 return getattr(self.__data, name) 11 else: ---> 12 return FrozenJSON.build(self.__data[name]) 13 14 @classmethod KeyError: 'flavor' 处理无效属性名 FrozenJSON 类有个缺陷：没有对名称为Python 关键字的属性做特殊处理。比如说像下面这 样构建一个对象 grad = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) 此时无法读取grad.class的值，因为在Python中class是保留字: grad.class File \"\", line 1 grad.class ^ SyntaxError: invalid syntax 但是，FrozenJSON 类的目的是为了便于访问数据，因此更好的方法是检查传给Frozen-JSON.__init__ 方法的映射中是否有键的名称为关键字，如果有，那么在键名后加上_. 这种有问题的键在Python 3中易于检测，因为str类提供的s.isidentifier()方法能根据语言的语法判断s是否为有效的Python标识符.但是，把无效的标识符变成有效的属性名却不容易.对此，有两个简单的解决方法: 一个是抛出异常 另一个是把无效的键换成通用名称，例如attr_0、attr_1，等等. 为了简单起见，我将忽略这个问题. 对动态属性的名称做了一些处理之后，我们要分析FrozenJSON类的另一个重要功能——类方法build的逻辑。这个方法把嵌套结构转换成FrozenJSON实例或FrozenJSON实例列表，因此__getattr__ 方法使用这个方法访问属性时，能为不同的值返回不同类型的对象. import keyword from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) @classmethod def build(cls, obj): if isinstance(obj, abc.Mapping): return cls(obj) elif isinstance(obj, abc.MutableSequence): return [cls.build(item) for item in obj] else: return obj grad = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) grad.class_ 1982 使用__new__方法以灵活的方式创建对象 除了在类方法中实现这样的逻辑之外，还可以在特殊的__new__方法中实现. 我们通常把__init__称为构造方法，这是从其他语言借鉴过来的术语.其实，用于构建实例的是特殊方法__new__--这是个类方法(使用特殊方式处理，因此不必使用@classmethod装饰器)，必须返回一个实例。返回的实例会作为第一个参数（即self）传给__init__方法。因为调用__init__方法时要传入实例，而且禁止返回任何值，所以__init__ 方法其实是“初始化方法”.真正的构造方法是__new__。我们几乎不需要自己编写__new__方法，因为从object类继承的实现已经足够了。 刚才说明的过程，即从__new__方法到__init__方法，是最常见的，但不是唯一的. __new__方法也可以返回其他类的实例，此时，解释器不会调用__init__方法. 下面是FrozenJSON 类的另一个版本，把之前在类方法build 中的逻辑移到了__new__方法中. import keyword from collections import abc class FrozenJSON: \"\"\"一个只读接口，使用属性表示法访问JSON类对象 \"\"\" def __new__(cls, arg): if isinstance(arg, abc.Mapping): return super().__new__(cls) elif isinstance(arg, abc.MutableSequence): return [cls(item) for item in arg] else: return arg def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): # `__getattr__`特殊方法用于重载`.`符号获取值的行为 if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON.build(self.__data[name]) __new__方法的第一个参数是类,因为创建的对象通常是那个类的实例.所以,在FrozenJSON.__new__方法中,super().__new__(cls)表达式会调object.__new__(FrozenJSON)， 而object类构建的实例其实是FrozenJSON实例，即那个实例的__class__属性存储的是 FrozenJSON类的引用.不过，真正的构建操作由解释器调用C语言实现的object.__new__方法执行. OSCON的JSON数据源有一个明显的缺点：索引为40的事件，即名为There *Will* Be Bugs的那个,有两位演讲者，3471 和5199，但却不容易找到他们，因为提供的是编号， 而Schedule.speakers列表没有使用编号建立索引。此外，每条事件记录中都有venue_serial 字段，存储的值也是编号，但是如果想找到对应的记录，那就要线性搜索Schedule.venues列表.接下来的任务是，调整数据结构，以便自动获取所链接的记录. 使用shelve模块调整OSCON数据源的结构 标准库中有个shelve(架子)模块，这名字听起来怪怪的，可是如果知道pickle(泡菜)是Python 对象序列化格式的名字，还是在那个格式与对象之间相互转换的某个模块的名字，就会觉得以shelve 命名是合理的。泡菜坛子摆放在架子上，因此shelve模块提供了pickle存储方式. shelve.open 高阶函数返回一个shelve.Shelf 实例，这是简单的键值对象数据库，背后由dbm模块支持，具有下述特点: shelve.Shelf 是abc.MutableMapping 的子类，因此提供了处理映射类型的重要方法。 此外，shelve.Shelf 类还提供了几个管理I/O 的方法，如sync 和close；它也是一个上 下文管理器。 只要把新值赋予键，就会保存键和值。 键必须是字符串。 值必须是pickle 模块能处理的对象。 shelve 模块为识别OSCON 的日程数据提供了一种简单有效的方式.我们将从JSON 文件中读取所有记录，将其存在一个shelve.Shelf 对象中，键由记录类型和编号组成（例如，event.33950 或speaker.3471），而值是我们即将定义的Record 类的实例. import warnings DB_NAME = 'schedule1_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def load_db(db): raw_data = load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = Record(**record) import shelve db = shelve.open(DB_NAME) if CONFERENCE not in db: load_db(db) speaker = db['speaker.3471'] type(speaker) __main__.Record speaker.name, speaker.twitter ('Anna Martelli Ravenscroft', 'annaraven') db.close() Record.__init__方法展示了一个流行的Python 技巧。我们知道，对象的__dict__ 属性中存储着对象的属性——前提是类中没有声明__slots__ 属性.因此，更新实例的__dict__属性，把值设为一个映射，能快速地在那个实例中创建一堆属性. 示例中定义的Record类太简单了，因此你可能会问，为什么之前没用，而是使用更复杂的FrozenJSON类。原因有两个: 第一，FrozenJSON类要递归转换嵌套的映射和列表；而Record 类不需要这么做，因为转换好的数据集中没有嵌套的映射和列表，记录中只有字符串、整数、字符串列表和整数列表. 第二，FrozenJSON 类要访问内嵌的__data属性（值是字典，用于调用keys等方法），而现在我们也不需要这么做 像上面那样调整日程数据集之后，我们可以扩展Record类，让它提供一个有用的服务--自动获取event记录引用的venue 和speaker记录。这与Django ORM 访问models.ForeignKey 字段时所做的事类似--得到的不是键，而是链接的模型对象. 动态绑定方法 python中方法只是可以调用的属性,因此方法也是可以动态绑定的.尤其实例方法的动态绑定尤其实用. 动态绑定实例方法 动态绑定实例方法需要借助types.MethodType from types import MethodType class Student(object): age = 10 def set_age(self, age): # 定义一个函数作为实例方法 self.age = age s = Student() s.set_age = MethodType(set_age, s) # 给实例绑定一个方法 s.age 10 s.set_age(12) s.age 12 动态绑定类方法 动态绑定类方法与前面类似,只是MethodType的第一个参数改成了类名 def set_score(clz, score):#定义一个函数作为类的方法 clz.score = score Student.set_score = MethodType(set_score, Student) Student.set_score(30) Student.score 30 s.score 30 动态绑定静态方法 动态绑定静态方法更加简单了,只要直接在类名后面像添加元素一样添加即可 def echo(score):#定义一个函数作为类的方法 return score Student.echo = echo Student.echo(123) 123 特性 除了属性之外，我们还可以创建特性(property)，在不改变类接口的前提下，使用存取方法(即读值方法和设值方法)修改数据属性.这与统一访问原则相符--不管服务是由存储还是计算实现的，一个模块提供的所有服务都应该通过统一的方式使用. property是一个用于类中方法的装饰器,用于将方法属性转换为特性,如果要设定特性的增删改查能力,则可以使用.setter,.deleter定义. class Event(DbRecord): @property def venue(self): '''The Event attribute''' return self.__venue @venue.setter def venue(self,value): self.__venue = value @venue.deleter def venue(self,value): del self.__venue 虽然内置的property经常用作装饰器，但它其实是一个类。在Python 中，函数和类通常可以互换，因为二者都是可调用的对象，而且没有实例化对象的new运算符，所以调用构造方法与调用工厂函数没有区别。此外，只要能返回新的可调用对象，代替被装饰的函数，二者都可以用作装饰器. property构造方法的完整签名如下： property(fget=None, fset=None, fdel=None, doc=None) 所有参数都是可选的，如果没有把函数传给某个参数，那么得到的特性对象就不允许执行相应的操作. 某些情况下，这种经典形式比装饰器句法好.但是，在方法众多的类定义体中使用装饰器的话，一眼就能看出哪些是读值方法，哪些是设值方法，而不用按照惯例，在方法名的前面加上get 和set.类中的特性能影响实例属性的寻找方式，而一开始这种方式可能会让人觉得意外. 特性都是类属性，但是特性管理的其实是实例属性的存取.如果实例和所属的类有同名数据属性，那么实例属性会覆盖（或称遮盖）类属性——至少通过那个实例读取属性时是这样. 实例属性遮盖类的数据属性 class Class: data = 'the class data attr' @property def prop(self): return 'the prop value' obj = Class() vars(obj) {} obj.data 'the class data attr' obj.data = 'bar' vars(obj) {'data': 'bar'} obj.data 'bar' Class.data 'the class data attr' 实例属性不会遮盖类特性 Class.prop obj.prop 'the prop value' obj.prop = 'foo' --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 obj.prop = 'foo' AttributeError: can't set attribute obj.__dict__['prop'] = 'foo' vars(obj) {'data': 'bar', 'prop': 'foo'} obj.prop 'the prop value' Class.prop obj.prop 'the prop value' 新添的类特性遮盖现有的实例属性 obj.data 'bar' Class.data 'the class data attr' Class.data = property(lambda self: 'the \"data\" prop value') obj.data 'the \"data\" prop value' del Class.data obj.data 'bar' 特性的文档 控制台中的help()函数或IDE 等工具需要显示特性的文档时，会从特性的__doc__ 属性中 提取信息。 如果使用经典调用句法，为property对象设置文档字符串的方法是传入doc参数： weight = property(get_weight, set_weight, doc='weight in kilograms') +使用装饰器创建property对象时，读值方法（有@property装饰器的方法）的文档字符串作 为一个整体，变成特性的文档. 使用特性获取链接的记录 下图是用到的几个类 Record __init__ 方法与schedule1.py 脚本（见示例19-9）中的一样；为了辅助测试，增加了eq 方法。 DbRecord Record 类的子类，添加了__db 类属性，用于设置和获取__db 属性的set_db 和get_db静态方法，用于从数据库中获取记录的fetch 类方法，以及辅助调试和测试的__repr__实例方法。 Event DbRecord类的子类，添加了用于获取所链接记录的venue 和speakers 属性，以及特殊的__repr__ 方法。 import inspect DB_NAME = 'schedule2_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def __eq__(self, other): if isinstance(other, Record): return self.__dict__ == other.__dict__ else: return NotImplemented class MissingDatabaseError(RuntimeError): \"\"\"需要数据库但没有指定数据库时抛出。\"\"\" pass class DbRecord(Record): __db = None @staticmethod def set_db(db): DbRecord.__db = db @staticmethod def get_db(): return DbRecord.__db @classmethod def fetch(cls, ident): db = cls.get_db() try: return db[ident] except TypeError: if db is None: msg = \"database not set; call '{}.set_db(my_db)'\" raise MissingDatabaseError(msg.format(cls.__name__)) else: raise def __repr__(self): if hasattr(self, 'serial'): cls_name = self.__class__.__name__ return ''.format(cls_name, self.serial) else: return super().__repr__() class Event(DbRecord): @property def venue(self): key = 'venue.{}'.format(self.venue_serial) return self.__class__.fetch(key) @property def speakers(self): if not hasattr(self, '_speaker_objs'): spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch self._speaker_objs = [fetch('speaker.{}'.format(key)) for key in spkr_serials] return self._speaker_objs def __repr__(self): if hasattr(self, 'name'): cls_name = self.__class__.__name__ return ''.format(cls_name, self.name) else: return super().__repr__() def load_db(db): raw_data = load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] cls_name = record_type.capitalize() cls = globals().get(cls_name, DbRecord) if inspect.isclass(cls) and issubclass(cls, DbRecord): factory = cls else: factory = DbRecord for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = factory(**record) import shelve db = shelve.open(DB_NAME) if CONFERENCE not in db: load_db(db) DbRecord.set_db(db) event = DbRecord.fetch('event.33950') event event.venue event.venue.name 'Portland 251' for spkr in event.speakers: print('{0.serial}: {0.name}'.format(spkr)) speaker.3471: Anna Martelli Ravenscroft speaker.5199: Alex Martelli db.close() 使用特性验证属性 目前，我们只介绍了如何使用@property装饰器实现只读特性。本节要创建一个可读写的特性 LineItem类第1版：表示订单中商品的类 假设有个销售散装有机食物的电商应用，客户可以按重量订购坚果、干果或杂粮.在这个系统中，每个订单中都有一系列商品，而每个商品都可以使用. class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) raisins.subtotal() 69.5 raisins.weight = -20 raisins.subtotal() -139.0 这个类没法限制参数.比如作为一个商品订单,它的值可以是负的. LineItem类第2版：能验证值的特性 class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price @property def weight(self): return self.__weight @weight.setter def weight(self, value): if value > 0: self.__weight = value else: raise ValueError('value must be > 0') 特性工厂函数 我们的weight 和price有相似的特点,都不能为负.如果一个类有很多这样的特性,那一个一个写特性会很麻烦,因此可以使用特性工厂函数来产生一样特点的特性. 我们将定义一个名为quantity的特性工厂函数，取这个名字是因为，在这个应用中要管理的属性表示不能为负数或零的量.下例是LineItem类的简洁版，用到了quantity特性的两个实例： 一个用于管理weight属性， 另一个用于管理price属性。 def quantity(storage_name): def qty_getter(instance): return instance.__dict__[storage_name] def qty_setter(instance, value): if value > 0: instance.__dict__[storage_name] = value else: raise ValueError('value must be > 0') return property(qty_getter, qty_setter) class LineItem: weight = quantity('weight') price = quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price nutmeg = LineItem('Moluccan nutmeg', 8, 13.95) nutmeg.weight, nutmeg.price (8, 13.95) sorted(vars(nutmeg).items()) [('description', 'Moluccan nutmeg'), ('price', 13.95), ('weight', 8)] 工厂函数构建的特性利用了特性覆盖实例属性的行为，因此对self.weight 或nutmeg.weight 的每个引用都由特性函数处理，只有直接存取__dict__属性才能跳过特性的处理逻辑. 在真实的系统中，分散在多个类中的多个字段可能要做同样的验证，此时最好把quantity工厂函数放在实用工具模块中，以便重复使用。最终可能要重构那个简单的工厂函数，改成更易扩展的描述符类，然后使用专门的子类执行不同的验证. 属性描述符 描述符是对多个属性运用相同存取逻辑的一种方式,ORM 中的字段类型是往往使用描述符，把数据库记录中字段里的数据与Python对象的属性对应起来. 描述符是实现了特定协议的类， 这个协议包括__get__、__set__ 和__delete__ 方法. property类实现了完整的描述符协议.通常，可以只实现部分协议.其实，我们在真实的代码中见到的大多数描述符只实现了__get__ 和__set__方法，还有很多只实现了其中的一个.描述符是Python的独有特征,不仅在应用层中使用，在语言的基础设施中也有用到.除了特性之外，使用描述符的Python功能还有方法及classmethod和staticmethod装饰器。理解描述符是精通Python的关键. LineItem类第3版：一个简单的描述符 实现了__get__、__set__ 或__delete__方法的类是描述符。描述符的用法是，创建一个实 例，作为另一个类的类属性. 我们将定义一个Quantity描述符用来代替特性工厂函数，LineItem 类会用到两个Quantity实例： 一个用于管理weight 属性， 另一个用于管理price 属性。 从现在开始，我会使用下述定义: 描述符类 实现描述符协议的类。在上图中，是Quantity 类。 托管类 把描述符实例声明为类属性的类——上图中的LineItem 类。 描述符实例 描述符类的各个实例，声明为托管类的类属性。在上图中，各个描述符实例使用箭头和带下划线的名称表示（在UML 中，下划线表示类属性）.与黑色菱形接触的LineItem 类包含描述符实例. 托管实例 托管类的实例.在这个示例中，LineItem 实例是托管实例 储存属性 托管实例中存储自身托管属性的属性。在上图中，LineItem 实例的weight 和price属性是储存属性.这种属性与描述符属性不同，描述符属性都是类属性. 托管属性 托管类中由描述符实例处理的公开属性，值存储在储存属性中.也就是说，描述符实例和储存属性为托管属性建立了基础. class Quantity: def __init__(self, storage_name): self.storage_name = storage_name def __set__(self, instance, value): if value > 0: instance.__dict__[self.storage_name] = value else: raise ValueError('value must be > 0') 各个托管属性的名称与储存属性一样，而且读值方法不需要特殊的逻辑，所以Quantity 类不需要定义__get__方法. 编写__set__方法时，要记住self 和instance 参数的意思： self 是描述符实例， instance 是托管实例 管理实例属性的描述符应该把值存储在托管实例中。因此，Python 才为描述符中的那个方法提供了instance参数. class LineItem: weight = Quantity('weight') price = Quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price truffle = LineItem('White truffle', 100, 0) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 truffle = LineItem('White truffle', 100, 0) in __init__(self, description, weight, price) 5 self.description = description 6 self.weight = weight ----> 7 self.price = price 8 def subtotal(self): 9 return self.weight * self.price in __set__(self, instance, value) 6 instance.__dict__[self.storage_name] = value 7 else: ----> 8 raise ValueError('value must be > 0') ValueError: value must be > 0 上面的方式还是不够简洁,我们不得不在申明LineItem时为每个属性指定Quantity()的参数--属性的名称. 可问题是，赋值语句右手边的表达式先执行，而此时变量还不存在. Quantity() 表达式计算的结果是创建描述符实例，而此时Quantity类中的代码无法猜出要把描述符绑定给哪个变量(例如weight 或price). 因此，上例必须明确指明各个Quantity实例的名称.这样不仅麻烦，还很危险： 如果程序员直接复制粘贴代码而忘了编辑名称，比如写成price = Quantity('weight')，那 么程序的行为会大错特错，设置price的值时会覆盖weight 的值. LineItem类第4版：自动获取储存属性的名称 为了避免在描述符声明语句中重复输入属性名，我们将为每个Quantity 实例的storage_name 属性生成一个独一无二的字符串。下图是更新后的Quantity 和LineItem 类的UML类图. 为了生成storage_name， 我们以'_Quantity#' 为前缀，然后在后面拼接一个整数： Quantity.__counter 类属性的当前值，每次把一个新的Quantity 描述符实例依附到类上，都会递增这个值。在前缀中使用井号能避免storage_name与用户使用点号创建的属性冲突，因为nutmeg._Quantity#0 是无效的Python句法.但是，内置的getattr 和setattr函数可以使用这种“无效的”标识符获取和设置属性，此外也可以直接处理实例属性__dict__ class Quantity: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): if value > 0: setattr(instance, self.storage_name, value) else: raise ValueError('value must be > 0') class LineItem: weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price coconuts = LineItem('Brazilian coconut', 20, 17.95) coconuts.weight, coconuts.price (20, 17.95) getattr(coconuts, '_Quantity#0'), getattr(coconuts, '_Quantity#1') (20, 17.95) LineItem类第5版：一种新型描述符 我们虚构的有机食物网店遇到一个问题：不知怎么回事儿，有个商品的描述信息为空，导致无法下订单.为了避免出现这个问题，我们要再创建一个描述符，NonBlank.在设计NonBlank的过程中，我们发现，它与Quantity描述符很像，只是验证逻辑不同. 回想Quantity的功能，我们注意到它做了两件不同的事： 管理托管实例中的储存属性 验证用于设置那两个属性的值 由此可知，我们可以重构，并创建两个基类 AutoStorage 自动管理储存属性的描述符类 Validated 扩展AutoStorage类的抽象子类，覆盖__set__ 方法，调用必须由子类实现的validate方法 我们重写Quantity类，并实现NonBlank，让它继承Validated类，只编写validate方法.类之间的关系见图. Validated、Quantity和NonBlank 三个类之间的关系体现了模板方法设计模式.具体而言，Validated.__set__ 方法正是Gamma等四人所描述的模板方法的例证： 一个模板方法用一些抽象的操作定义一个算法，而子类将重定义这些操作以提供具体的行为. import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price coconuts = LineItem('Brazilian coconut', 20, 17.95) coconuts.weight, coconuts.price (20, 17.95) raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#0', '_Quantity#0', '_Quantity#1'] LineItem.description.storage_name '_NonBlank#0' 覆盖型与非覆盖型描述符 Python存取属性的方式特别不对等。通过实例读取属性时，通常返回的是实例中定义的属性；但是，如果实例中没有指定的属性，那么会获取类属性.而为实例中的属性赋值时，通常会在实例中创建属性，根本不影响类.这种不对等的处理方式对描述符也有影响.其实，根据是否定义__set__方法，描述符可分为两大类.其中覆盖型又可以分为2小类. 覆盖型 定义__set__,描述符的__set__方法使用托管实例中的同名属性覆盖（即插手接管）了要设置的属性,这种类型描述符的典型用途是管理数据属性 没有__get__方法的覆盖型描述符 通常，覆盖型描述符既会实现__set__ 方法，也会实现__get__方法，不过也可以只实现__set__ 方法.此时，只有写操作由描述符处理。通过实例读取描述符会返回描述符对象本身，因为没有处理读操作的__get__ 方法。如果直接通过实例的__dict__属性创建同名实例属性，以后再设置那个属性时，仍会由__set__ 方法插手接管，但是读取那个属性的话，就会直接从实例中返回新赋予的值，而不会返回描述符对象。也就是说，实例属性会遮盖描述符，不过只有读操作是如此 非覆盖型 没有实现__set__方法的描述符是非覆盖型描述符.如果设置了同名的实例属性，描述符会被遮盖，致使描述符无法处理那个实例的那个属性.方法是以非覆盖型描述符实现的 我们通过下面的例子观察这两类描述符的行为差异 def cls_name(obj_or_cls): cls = type(obj_or_cls) if cls is type: cls = obj_or_cls return cls.__name__.split('.')[-1] def display(obj): cls = type(obj) if cls is type: return ''.format(obj.__name__) elif cls in [type(None), int]: return repr(obj) else: return ''.format(cls_name(obj)) def print_args(name, *args): pseudo_args = ', '.join(display(x) for x in args) print('-> {}.__{}__({})'.format(cls_name(args[0]), name, pseudo_args)) class Overriding: \"\"\"覆盖型描述符 也称数据描述符或强制描述符\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) def __set__(self, instance, value): print_args('set', self, instance, value) class OverridingNoGet: \"\"\"没有`__get__`方法的覆盖型描述符\"\"\" def __set__(self, instance, value): print_args('set', self, instance, value) class NonOverriding: \"\"\"也称非数据描述符或遮盖型描述符\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) class Managed: over = Overriding() over_no_get = OverridingNoGet() non_over = NonOverriding() def spam(self): print('-> Managed.spam({})'.format(display(self))) 覆盖型描述符的行为 上面的例子都是覆盖型描述符 obj = Managed() obj.over -> Overriding.__get__(, , ) Managed.over -> Overriding.__get__(, None, ) obj.over = 7 -> Overriding.__set__(, , 7) obj.over -> Overriding.__get__(, , ) obj.__dict__['over'] = 8 vars(obj) {'over': 8} obj.over -> Overriding.__get__(, , ) 没有__get__的覆盖型描述符的行为 只有写操作由描述符处理。通过实例读取描述符会返回描述符对象本身， obj.over_no_get Managed.over_no_get obj.over_no_get = 7 -> OverridingNoGet.__set__(, , 7) obj.over_no_get obj.__dict__['over_no_get'] = 9 obj.over_no_get 9 obj.over_no_get = 7 -> OverridingNoGet.__set__(, , 7) obj.over_no_get 9 非覆盖型描述符的行为 如果设置了同名的实例属性，描述符会被遮盖，致使描述符无法处理那个实例的那个属性 obj = Managed() obj.non_over -> NonOverriding.__get__(, , ) obj.non_over = 7 obj.non_over 7 Managed.non_over -> NonOverriding.__get__(, None, ) del obj.non_over obj.non_over -> NonOverriding.__get__(, , ) 在类中覆盖描述符 依附在类上的描述符无法控制为类属性赋值的操作。其实，这意味着为类属性赋值能覆盖描述符属性.这是一种猴子补丁技术，不过在下例中，我们把描述符替换成了整数，这其实会导致依赖描述符的类不能正确地执行操作. obj = Managed() Managed.over = 1 Managed.over_no_get = 2 Managed.non_over = 3 obj.over, obj.over_no_get, obj.non_over (1, 2, 3) 读类属性的操作可以由依附在托管类上定义有__get__ 方法的描述符处理，但是写类属性的操作不会由依附在托管类上定义有__set__方法的描述符处理. 若想控制设置类属性的操作，要把描述符依附在类的类上，即依附在元类上.默认情况下，对用户定义的类来说，其元类是type，而我们不能为type 添加属性,但我们可以自定义元类. 描述符协议增强(3.6) 上面的LineItem有个缺陷--就是初始化的时候都明确让属性的值绑定在Integer上的name属性上，而无法获知所有者类的属性名。如果使用自定义内部名字,又会难以调试.使用在PEP487上提供的可选的__set_name__()可以获得这个属性名字，并且可以自定义这部分内容： class AutoStorage: def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.name) def __set__(self, instance, value): setattr(instance, self.name, value) def __set_name__(self, owner, name): cls = self.__class__ prefix = cls.__name__ index = name self.name = '_{}#{}'.format(prefix, index) class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.name '_NonBlank#description' 方法是描述符 在类中定义的函数属于绑定方法（bound method），因为用户定义的函数都有__get__方法，所以依附到类上时，就相当于描述符.函数没有实现__set__方法，因此是非覆盖型描述符. 与描述符一样，通过托管类访问时，函数的__get__方法会返回自身的引用。但是，通过实例访问时，函数的__get__方法返回的是绑定方法对象：一种可调用的对象，里面包装着函数，并把托管实例（例如obj）绑定给函数的第一个参数（即self），这与functools.partial函数的行为一致 描述符用法建议 下面根据刚刚论述的描述符特征给出一些实用的结论: 使用特性以保持简单 内置的property 类创建的其实是覆盖型描述符，__set__方法和__get__ 方法都实现了，即便不定义设值方法也是如此。特性的__set__方法默认抛出AttributeError:can't set attribute，因此创建只读属性最简单的方式是使用特性，这能避免下一条所述的问题. 只读描述符必须有__set__方法 如果使用描述符类实现只读属性， 要记住，__get__ 和__set__ 两个方法必须都定义，否则，实例的同名属性会遮盖描述符。只读属性的__set__方法只需抛出AttributeError 异常，并提供合适的错误消息. 用于验证的描述符可以只有__set__方法 对仅用于验证的描述符来说，__set__ 方法应该检查value参数获得的值，如果有效，使用描述符实例的名称为键，直接在实例的__dict__属性中设置。这样，从实例中读取同名属性的速度很快，因为不用经过__get__方法处理. 仅有__get__方法的描述符可以实现高效缓存 如果只编写了__get__方法，那么创建的是非覆盖型描述符。这种描述符可用于执行某些耗费资源的计算，然后为实例设置同名属性，缓存结果.同名实例属性会遮盖描述符，因此后续访问会直接从实例的__dict__属性中获取值，而不会再触发描述符的__get__方法。 非特殊的方法可以被实例属性遮盖 由于函数和方法只实现了__get__ 方法，它们不会处理同名实例属性的赋值操作.因此，像my_obj.the_method = 7 这样简单赋值之后，后续通过该实例访问the_method得到的是数字7——但是不影响类或其他实例.然而，特殊方法不受这个问题的影响.解释器只会在类中寻找特殊的方法，也就是说，repr(x) 执行的其实是x.__class__.__repr__(x)，因此x的__repr__ 属性对repr(x)方法调用没有影响。出于同样的原因，实例的__getattr__属性不会破坏常规的属性访问规则. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 01:00:01 "},"元编程/装饰器.html":{"url":"元编程/装饰器.html","title":"装饰器","keywords":"","body":"装饰器 函数装饰器用于在源码中“标记”函数,以某种方式增强函数的行为.严格来说装饰器这种形式是一种语法糖. 装饰器的特点有两个: 装饰器是可调用的对象,其参数是另一个可调用对象。 装饰器可能会处理被装饰的可调用对象,然后把它返回,或者将其替换成另一个可调用对象 装饰器在加载模块时立即执行 装饰器的形式如下: @decorator def call(args): pass 它等价于 call(args) = decorator(call(args)) 实现装饰器 下面这个例子定义了一个装饰器,用来在每次调用被装饰的函数时计时，然后把经过的时间、传入的参数和调用的结果打印出来。 import time def timer(func): def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) elapsed = time.perf_counter() - t0 name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked @timer def snooze(seconds): time.sleep(seconds) snooze(2) [used:1.9998886096583577s] function snooze(2)->None @timer def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(5) [used:6.037416890869451e-07s] function factorial(1)->1 [used:0.00012950259231558903s] function factorial(2)->2 [used:0.00017085889802048726s] function factorial(3)->6 [used:0.0002067815285231589s] function factorial(4)->24 [used:0.00023244055031090838s] function factorial(5)->120 120 factorial.__name__ 'clocked' 包装装饰器 上面的装饰器有个缺点--遮盖了被装饰函数的__name__ 和__doc__ 属性.这时可以使用functools.wraps 装饰器把相关的属性从func复制到clocked中 import functools def timer(func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) elapsed = time.perf_counter() - t0 name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked @timer def snooze(seconds): time.sleep(seconds) snooze(2) [used:1.999928154738995s] function snooze(2)->None @timer def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(6) [used:3.018708447655172e-07s] function factorial(1)->1 [used:0.00013372878413964173s] function factorial(2)->2 [used:0.0001944048238957663s] function factorial(3)->6 [used:0.0005726489921293876s] function factorial(4)->24 [used:0.0006001192389835097s] function factorial(5)->120 [used:0.0006197408438799457s] function factorial(6)->720 720 factorial.__name__ 'factorial' 带参数的装饰器 我们修改之前的timer,希望它可以添加一个参数,用于指定秒数的精确位数.这样就需要写一个带参数的装饰器. 带参数的装饰器我们还需要再在外面套一层用来返回我们的装饰器函数. import time import functools def timer(rd=3): def decorate(func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) rs = time.perf_counter() - t0 elapsed = round(rs ,rd) name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked return decorate @timer() def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(2) [used:0.0s] function factorial(1)->1 [used:0.0s] function factorial(2)->2 2 @timer(7) def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(2) [used:6e-07s] function factorial(1)->1 [used:7.7e-05s] function factorial(2)->2 2 factorial.__name__ 'factorial' factorial.__doc__ 'factorial' 当然了返回装饰器函数的对象只要是可执行对象就行.因此或许用类来实现看起来会更加自然一些 class timer: def __call__(self,func): @functools.wraps(func) def clocked(*args,**kw): t0 = time.perf_counter() result = func(*args,**kw) rs = time.perf_counter() - t0 elapsed = round(rs ,self.rd) name = func.__name__ if args: arg = \",\".join(repr(arg) for arg in args) if kw: kws = \",\".join([repr(i)+\"=\"+repr(v) for i,v in sorted(kw.items())]) arg = arg+\",\"+kws print(\"[used:{}s] function \".format(elapsed)+func.__name__+\"(\"+arg+\")->\"+repr(result)) return result return clocked def __init__(self,rd=3): self.rd = rd @timer(7) def factorial(n): \"\"\"factorial\"\"\" return 1 if n factorial(3) [used:2.1e-06s] function factorial(1)->1 [used:0.0003037s] function factorial(2)->2 [used:0.0004392s] function factorial(3)->6 6 factorial.__name__ 'factorial' 但从开销角度来看,显然使用函数闭包实现带参数装饰器会比使用带__call__方法的类实例来的更加好,毕竟函数一旦定义,调用的开销远比实例化一个类小的多,但如果需要实现一些复杂的状态管理功能,这种开销或许也是值得的. 类装饰器 装饰器除了可以装饰函数,也可以装饰类,原理也差不多,参数是一个类,而返回的也是一个类,下面以之前的LineItem作为例子讲解如何定义和使用类装饰器. 定制描述符的类装饰器 动态属性,特性与描述符部分的倒数第二个LineItem例子中储存属性的名称不具有描述性，即属性（如weight）的值存储在名为_Quantity#0 的实例属性中，这样的名称不便于调试的问题.单靠描述符无法存储属性名字,，因为实例化描述符时无法得知托管属性（即绑定到描述符上的类属性，例如前述示例中的weight）的名称. 可是，一旦组建好整个类，而且把描述符绑定到类属性上之后，我们就可以审查类，并为描述符设置合理的储存属性名称.LineItem类的__new__方法可以做到这一点，因此，在__init__方法中使用描述符时，储存属性已经设置了正确的名称。 为了解决这个问题而使用__new__ 方法纯属白费力气--每次新建LineItem实例时都会运行__new__ 方法中的逻辑，可是，一旦LineItem类构建好了，描述符与托管属性之间的绑定就不会变了.因此，我们要在创建类时设置储存属性的名称. 使用3.6的新接口__set_name__,类装饰器或元类都可以做到这一点.这边的例子使用类装饰器 def entity(cls): for key, attr in cls.__dict__.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) return cls import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) def __set_name__(self, owner, name): self.name = name class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value @entity class LineItem: description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.storage_name '_NonBlank#description' 类装饰器能以较简单的方式做到元类做的事情——创建类时定制类. 但类装饰器也有个重大缺点：只对直接依附的类有效.这意味着，被装饰的类的子类可能继承也可能不继承装饰器所做的改动，具体情况视改动的方式而定. 标准库中的装饰器 Python内置了三个用于装饰方法的函数：property、classmethod 和staticmethod.这三个在面向对象惯用法部分讲. 而剩下的装饰器中 functools.total_ordering是用来装饰类的 functools.lru_cache,functools.singledispatch是用来装饰函数/方法的 functools.total_ordering自动添加比较特殊方法 functools.total_ordering装饰器可以装饰一个类,只要其中有实现__lt__、__le__、__gt__、__ge__中的至少一个,它就会将其他的补全 from functools import total_ordering @total_ordering class Student: def __eq__(self, other): return ((self.lastname.lower(), self.firstname.lower()) == (other.lastname.lower(), other.firstname.lower())) def __lt__(self, other): return ((self.lastname.lower(), self.firstname.lower()) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__'] 使用functools.lru_cache(maxsize=128, typed=False)做备忘 functools.lru_cache 是非常实用的装饰器，它实现了备忘（memoization）功能。这是一项优化技术，它把耗时的函数的结果保存起来，避免传入相同的参数时重复计算。LRU 三个字母是“Least Recently Used”的缩写，表明缓存不会无限制增长，一段时间不用的缓存条目会被扔掉。 maxsize参数指定存储多少个调用的结果.缓存满了之后，旧的结果会被扔掉，腾出空间.为了得到最佳性能，maxsize 应该设为2的幂. typed 参数如果设为True，把不同参数类型得到的结果分开保存，即把通常认为相等的浮点数和整数参数（如1 和1.0）区分开. 因为lru_cache使用字典存储结果，而且键根据调用时传入的定位参数和关键字参数创建，所以被lru_cache 装饰的函数，它的所有参数都必须是可散列的。 生成第n个斐波纳契数这种慢速递归函数适合使用lru_cache @timer(7) def fibonacci(n): if n fibonacci(6) [used:1.5e-06s] function fibonacci(0)->0 [used:1.8e-06s] function fibonacci(1)->1 [used:0.000521s] function fibonacci(2)->1 [used:1.2e-06s] function fibonacci(1)->1 [used:1.2e-06s] function fibonacci(0)->0 [used:1.2e-06s] function fibonacci(1)->1 [used:0.0001485s] function fibonacci(2)->1 [used:0.0003013s] function fibonacci(3)->2 [used:0.0009726s] function fibonacci(4)->3 [used:1.2e-06s] function fibonacci(1)->1 [used:1.5e-06s] function fibonacci(0)->0 [used:1.2e-06s] function fibonacci(1)->1 [used:0.000147s] function fibonacci(2)->1 [used:0.0003088s] function fibonacci(3)->2 [used:1.2e-06s] function fibonacci(0)->0 [used:1.2e-06s] function fibonacci(1)->1 [used:0.0001404s] function fibonacci(2)->1 [used:9e-07s] function fibonacci(1)->1 [used:9e-07s] function fibonacci(0)->0 [used:9e-07s] function fibonacci(1)->1 [used:0.000118s] function fibonacci(2)->1 [used:0.0003462s] function fibonacci(3)->2 [used:0.0006104s] function fibonacci(4)->3 [used:0.001033s] function fibonacci(5)->5 [used:0.0023374s] function fibonacci(6)->8 8 浪费时间的地方很明显：fibonacci(1) 调用了8 次，fibonacci(2) 调用了5 次……但是，如果增加两行代码，使用lru_cache，性能会显著改善 from functools import lru_cache @lru_cache() @timer(7) def fibonacci(n): if n fibonacci(6) [used:1.2e-06s] function fibonacci(0)->0 [used:1.2e-06s] function fibonacci(1)->1 [used:0.0001654s] function fibonacci(2)->1 [used:2.1e-06s] function fibonacci(3)->2 [used:0.0002496s] function fibonacci(4)->3 [used:1.5e-06s] function fibonacci(5)->5 [used:0.000329s] function fibonacci(6)->8 8 装饰器的叠放顺序 装饰器的叠放顺序也是有讲究的,它是从下向上执行的,因此最终执行的结果是最上面一层的包装. 使用functools.singledispatch实现单分配泛函 假设我们在开发一个调试Web 应用的工具，我们想生成HTML，显示不同类型的Python对象,我们可能会编写这样的函数： import html def htmlize(obj): content = html.escape(repr(obj)) return '{}'.format(content) 这个函数适用于任何Python 类型，但是现在我们想做个扩展，让它使用特别的方式显示某些类型. str：把内部的换行符替换为\\\\n；不使用\\，而是使用\\。 int：以十进制和十六进制显示数字。 list：输出一个HTML列表，根据各个元素的类型进行格式化。 因为Python不支持重载方法或函数，所以我们不能使用不同的签名定义htmlize的变体，也无法使用不同的方式处理不同的数据类型。在Python 中，一种常见的做法是把htmlize变成一个分派函数，使用一串if/elif/elif，调用专门的函数，如htmlize_str、htmlize_int，等等。这样不便于模块的用户扩展，还显得笨拙：时间一长，分派函数htmlize会变 得很大，而且它与各个专门函数之间的耦合也很紧密. functools.singledispatch装饰器可以把整体方案拆分成多个模块，甚至可以为你无法修改的类提供专门的函数。使用@singledispatch 装饰的普通函数会变成泛函数（generic function）：根据第一个参数的类型，以不同方式执行相同操作的一组函数 from functools import singledispatch from collections import abc import numbers import html @singledispatch def htmlize(obj): content = html.escape(repr(obj)) return '{}'.format(content) @htmlize.register(str) def _(text): content = html.escape(text).replace('\\n', '\\n') return '{0}'.format(content) @htmlize.register(numbers.Integral) def _(n): return '{0} (0x{0:x})'.format(n) @htmlize.register(tuple) @htmlize.register(abc.MutableSequence) def _(seq): inner = '\\n'.join(htmlize(item) for item in seq) return '\\n' + inner + '\\n' htmlize(123) '123 (0x7b)' htmlize('123') '123' htmlize([1,2,3]) '\\n1 (0x1)\\n2 (0x2)\\n3 (0x3)\\n' 只要可能，注册的专门函数应该处理抽象基类（如numbers.Integral 和abc.MutableSequence），不要处理具体实现（如int 和list）。这样，代码支持的兼容类型更广泛。例如，Python扩展可以子类化numbers.Integral，使用固定的位数实现int 类型。 singledispatch 机制的一个显著特征是，你可以在系统的任何地方和任何模块中注册专门函数。如果后来在新的模块中定义了新的类型，可以轻松地添加一个新的专门函数来处理那个类型。此外，你还可以为不是自己编写的或者不能修改的类添加自定义函数。 singledispatch 是经过深思熟虑之后才添加到标准库中的，它提供的特性很多，这里无法一一说明.这个机制最好的文档是PEP 443 — Single-dispatch generic functions. @singledispatch 不是为了把Java的那种方法重载带入Python。在一个类中为同一个方法定义多个重载变体，比在一个函数中使用一长串if/elif/elif/elif块要更好。但是这两种方案都有缺陷，因为它们让代码单元（类或函数）承担的职责太多。@singledispath 的优点是支持模块化扩展：各个模块可以为它支持的各个类型注册一个专门函数. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 01:01:20 "},"元编程/元类编程.html":{"url":"元编程/元类编程.html","title":"元类编程","keywords":"","body":"type--类工厂 有时，我觉得应该有类似nametuple的工厂函数，用于创建可变对象.假设我在编写一个宠物店应用程序，我想把狗的数据当作简单的记录处理.编写下面的样板代码让人厌烦： class Dog: def __init__(self, name, weight, owner): self.name = name self.weight = weight self.owner = owner rex = Dog('Rex', 30, 'Bob') rex 各个字段名称出现了三次。写了这么多样板代码，甚至字符串表示形式都不友好. 参考namedtuple,下面我们创建一个record_factory函数，即时创建简单的类 def record_factory(cls_name, field_names): try: field_names = field_names.replace(',', ' ').split() except AttributeError: # 不能调用.replace或.split方法 pass # 假定field_names本就是标识符组成的序列 field_names = tuple(field_names) def __init__(self, *args, **kwargs): attrs = dict(zip(self.__slots__, args)) attrs.update(kwargs) for name, value in attrs.items(): setattr(self, name, value) def __iter__(self): for name in self.__slots__: yield getattr(self, name) def __repr__(self): values = ', '.join('{}={!r}'.format(*i) for i in zip(self.__slots__, self)) return '{}({})'.format(self.__class__.__name__, values) cls_attrs = dict(__slots__ = field_names, __init__ = __init__,__iter__ = __iter__,__repr__ = __repr__) return type(cls_name, (object,), cls_attrs) Cat = record_factory('Cat', 'name weight owner') rex = Cat('Rex', 30, 'Bob') rex Cat(name='Rex', weight=30, owner='Bob') name, weight, _ = rex name, weight ('Rex', 30) \"{2}'s dog weighs {1}kg\".format(*rex) \"Bob's dog weighs 30kg\" rex.weight = 32 rex Cat(name='Rex', weight=32, owner='Bob') Cat.__mro__ (__main__.Cat, object) 可以看出上面的工厂函数核心就在于type()的使用.通常，我们把type视作函数，因为我们像函数那样使用它，例如，调用type(my_object) 获取对象所属的类——作用与my_object.__class__相同. 然而，type是一个类。当成类使用时，传入三个参数可以新建一个类： MyClass = type('MyClass', (MySuperClass, MyMixin),{'x': 42, 'x2': lambda self: self.x * 2}) type的三个参数分别是name、bases 和dict.最后一个参数是一个映射，指定新类的属性名和值. 元类 元类是制造类的工厂，不过不是函数而是类. 根据Python对象模型，类是对象，因此类肯定是另外某个类的实例.默认情况下，Python 中的类是type类的实例.也就是说，type 是大多数内置的类和用户定义的类的元类 'spam'.__class__ str str.__class__ type type.__class__ type 为了避免无限回溯，type 是其自身的实例，如最后一行所示。 注意，我没有说str 或其他对象继承自type.我的意思是，str 和其他对象是type 的实例。这两个类是object的子类。下图是他们的关系 两个示意图都是正确的。左边的示意图强调str、type 和LineItem 是object 的子类。右 边的示意图则清楚地表明str、object 和LineItem 是type 的实例，因为它们都是类. 除了type，标准库中还有一些别的元类，例如ABCMeta 和Enum。如下述代码片段所示，collections.Iterable 所属的类是abc.ABCMeta.Iterable是抽象类，而ABCMeta不是—— 不管怎样，Iterable 是ABCMeta的实例 import collections collections.Iterable.__class__ abc.ABCMeta import abc abc.ABCMeta.__class__ type abc.ABCMeta.__mro__ (abc.ABCMeta, type, object) 向上追溯，ABCMeta最终所属的类也是type。所有类都直接或间接地是type 的实例，不过只有元类同时也是type 的子类。若想理解元类，一定要知道这种关系：元类（如ABCMeta）从type 类继承了构建类的能力. 我们要抓住的重点是，所有类都是type的实例，但是元类还是type 的子类，因此可以作为制造类的工厂。具体来说，元类可以通过实现__init__ 方法定制实例。元类的__init__方法可以做到类装饰器能做的任何事情，但是作用更大. %%writefile evaltime_meta.py from evalsupport import deco_alpha from evalsupport import MetaAleph print(' evaltime_meta module start') @deco_alpha class ClassThree(): print(' ClassThree body') def method_y(self): print(' ClassThree.method_y') class ClassFour(ClassThree): print(' ClassFour body') def method_y(self): print(' ClassFour.method_y') class ClassFive(metaclass=MetaAleph): print(' ClassFive body') def __init__(self): print(' ClassFive.__init__') def method_z(self): print(' ClassFive.method_z') class ClassSix(ClassFive): print(' ClassSix body') def method_z(self): print(' ClassSix.method_z') if __name__ == '__main__': print(' ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print(' ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print(' ClassFive tests', 30 * '.') five = ClassFive() five.method_z() print(' ClassSix tests', 30 * '.') six = ClassSix() six.method_z() print(' evaltime_meta module end') Overwriting evaltime_meta.py import evaltime_meta evalsupport module start MetaAleph body evalsupport module end evaltime_meta module start ClassThree body deco_alpha ClassFour body ClassFive body MetaAleph.__init__ ClassSix body MetaAleph.__init__ evaltime_meta module end !python evaltime_meta.py evalsupport module start MetaAleph body evalsupport module end evaltime_meta module start ClassThree body deco_alpha ClassFour body ClassFive body MetaAleph.__init__ ClassSix body MetaAleph.__init__ ClassThree tests .............................. deco_alpha:inner_1 ClassFour tests .............................. ClassFour.method_y ClassFive tests .............................. ClassFive.__init__ MetaAleph.__init__:inner_2 ClassSix tests .............................. ClassFive.__init__ MetaAleph.__init__:inner_2 evaltime_meta module end 元类的定义和使用: 元类继承自type,行为通过实现 __new__(meta,name,bases,class_dict) 类似于类中的__new__,用于定义元类的创建行为 __init__(cls, name, bases,attr_dict) 类似于类中的__init__,用于初始化元类,通过元类产生类时会用到. __call__(cls) 定义类实例化时的行为. 类方法__prepare__(meta, name, bases) 解释器调用元类的__new__ 方法之前会先调用__prepare__ 方法，使用类定义体中的属性创建映射.__prepare__ 方法的第一个参数是元类，随后两个参数分别是要构建的类的名称和基类组成的元组，返回值必须是映射.元类构建新类时,__prepare__方法返回的映射会传给__new__ 方法的最后一个参数，然后再传给__init__ 方法。 使用元类的类实例化产出类的顺序是: meta.__prepare__ meta.__new__ meta.__init__ 类实例化对象的顺序是: clz.__call__ clz.__new__ clz.__init__ class meta_A(type): def __call__(clz,*args, **kwargs): print(\"clz.call\") return super().__call__(*args, **kwargs) def __new__(meta,name,bases,class_dict): print(\"meta.new\") return type.__new__(meta,name,bases,class_dict) def __init__(cls, name, bases,attr_dict): print(\"meta.init\") super().__init__(name, bases,attr_dict) @classmethod def __prepare__(meta, name, bases): print('meta.prepare') return dict() class A(metaclass = meta_A): def __new__(cls,*args, **kwargs): print('clz.new') return super().__new__(cls) def __init__(self,name): self.name=name print('clz.init') meta.prepare meta.new meta.init a = A(\"qw\") clz.call clz.new clz.init a.name 'qw' 元类的基本用途 一般来说能不用元类就别用元类,或者说元编程的部分都是这个原则,能不用就别用,但很多时候为了实现一些特殊功能我们不得不用元类来实现 用来验证子类 元类的最简单用途就是用来验证其子类是否定义正确.构建复杂类体系时我们可能需要确保类风格一致,确保某些方法得到了覆写,或者确保类属性之间具有某些严格的关系. 元类提供了一种可靠的验证方式,每当开发者定义新类时,他会运行验证代码,确保符合规定. 实现这个功能并非必须使用元类,可以在__init__中写验证代码,在类初始化的时候验证,但如果想构建的时候就验证,那就需要使用元类了. 例: 确保类及其子类定义的图形边数大于3: class ValidatePolygon(type): def __new__(meta,name,bases,class_dict): if bases != (object): if class_dict['sides'] is not None and class_dict['sides'] class Polygon(metaclass=ValidatePolygon): sides = None @classmethod def interior_angles(cls): return (cls.sides-2) * 180 class Triangle(Polygon): sides = 3 class Line(Polygon): print(\"before sides\") sides = 1 print(\"after sides\") before sides after sides --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 class Line(Polygon): 2 print(\"before sides\") 3 sides = 1 4 print(\"after sides\") in __new__(meta, name, bases, class_dict) 3 if bases != (object): 4 if class_dict['sides'] is not None and class_dict['sides'] 5 raise ValueError('Polygons need 3+ sides') 6 return type.__new__(meta,name,bases,class_dict) ValueError: Polygons need 3+ sides 用来注册子类 元类的另一个用途是在程序中自动注册类型,对于需要反向查找(reverse lookup)的场合会有用.它使我们可以在简单的标识符与对应的类之间建立映射. 例: 我们希望使用下面的这个类将python对象表示为json格式的序列化数据.但同时我们希望可以反序列化,这就要用到元类了. import json registry = {} def register_class(target): registry[target.__name__] = target def deserialize(data): params = json.loads(data) name = params[\"class\"] target_class = registry[name] return target_class(*params[\"args\"]) class Meta(type): def __new__(meta,name,bases,class_dict): cls = type.__new__(meta,name,bases,class_dict) register_class(cls) return cls class Serializable: def __init__(self,*args): self.args = args def serialize(self): return json.dumps({ 'class':self.__class__.__name__, 'args':self.args, }) class RegisterSerializable(Serializable,metaclass = Meta): pass class Vector3D(RegisterSerializable): def __init__(self,x,y,z): super().__init__(x,y,z) self.x,self.y,self.z = x,y,z v3 = Vector3D(10,-7,3) v3.serialize() '{\"class\": \"Vector3D\", \"args\": [10, -7, 3]}' v = deserialize(v3.serialize()) v.args (10, -7, 3) 用来与描述符结合使用注解属性 用来解决LineItem倒数第二版问题的另一个方法就是使用元类 import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) def __set_name__(self, owner, name): self.name = name class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" pass class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value 0') return value class NonBlank(Validated): def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class EntityMeta(type): \"\"\"元类，用于创建带有验证字段的业务实体\"\"\" def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) for key, attr in attr_dict.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) class Entity(metaclass=EntityMeta): \"\"\"带有验证字段的业务实体\"\"\" 用户级别的代码只需继承Entity类，Validated 字段就能自动获得储存属性的名称。 class LineItem(Entity): description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price raisins = LineItem('Golden raisins', 10, 6.95) dir(raisins)[:3] ['_NonBlank#description', '_Quantity#price', '_Quantity#weight'] LineItem.description.storage_name '_NonBlank#description' 如前所述type构造方法及元类的__new__和__init__ 方法都会收到要计算的类的定义体，形式是名称到属性的映像。然而在默认情况下，那个映射是字典；也就是说，元类或类装饰器获得映射时，属性在类定义体中的顺序已经丢失了. 这个问题的解决办法是，使用Python3引入的特殊方法__prepare__.解释器调用元类的__new__ 方法之前会先调用__prepare__方法，使用类定义体中的属性创建映射. __prepare__方法的第一个参数是元类，随后两个参数分别是要构建的类的名称和基类组成的元组，返回值必须是映射. 元类构建新类时，__prepare__方法返回的映射会传给__new__方法的最后一个参数，然后再传给__init__方法. import collections class EntityMeta(type): \"\"\"元类，用于创建带有验证字段的业务实体\"\"\" @classmethod def __prepare__(cls, name, bases): return collections.OrderedDict() def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) cls._field_names = [] for key, attr in attr_dict.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) cls._field_names.append(key) class Entity(metaclass=EntityMeta): \"\"\"带有验证字段的业务实体\"\"\" @classmethod def field_names(cls): for name in cls._field_names: yield name class LineItem(Entity): description = NonBlank() weight = Quantity() price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price for name in LineItem.field_names(): print(name) description weight price Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-28 00:59:43 "},"元编程/结语.html":{"url":"元编程/结语.html","title":"结语","keywords":"","body":"结语 特性有助于减少前期投入 默认情况下,Python的所有实例属性和类属性都是公开的. 如果觉得应该避免意外更新属性,可以实现特性,但是代码的其他部分没有变化. 这表明我们可以先以最简单的方式定义类,也就是使用公开属性,因为如果以后需要对读值方法和设值方法增加控制, 那就可以实现特性,这样做对一开始通过公开属性的名称(如 x 和 y)与对象交互的代码没有影响. Java语言采用的方式则截然相反: Java 程序员不能先定义简单的公开属性,然后在需要时再实现特性,因为Java语言没有特性. 因此,在Java中编写读值方法和设值方法是常态,就算这些方法没做什么有用的事情也得这么做, 因为API不能从简单的公开属性变成读值方法和设值方法,同时又不影响使用那些属性的代码. 而且到处都使用读值方法和设值方法是愚蠢的行为。如果想编写下面的代码: my_object.set_foo(my_object.get_foo() + 1) 这样做就行了: my_object.foo += 1 维基的发明人和极限编程先驱 Ward Cunningham 建议问这个问题:\"做这件事最简单的方法是什么?\" 意即,我们应该把焦点放在目标上.提前实现设值方法和读值方法偏离了目标.在 Python 中,我们可以先使用公开属性,然后等需要时再变成特性. python作为动态语言,这些特性也让他非常适合敏捷开发. 运算符重载的优缺点 James Gosling决定不让Java支持运算符重载.在那次访谈中(“The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling”,他说: 大约 20% 到 30% 的人觉得运算符重载是罪恶之源;有些人对运算符的重载惹怒了很多人, 因为他们使用+做列表插入,导致生活一团糟.这类问题大都源于一个事实--世界上有成千上万个运算符, 但是只有少数几个适合重载.因此, 我们要挑选,但是有时所作的决定违背直觉. Guido van Rossum为运算符重载采取了一种折中方式--不放任用户随意创建运算符, 如: 或 :-),这样防止了用户对运算符的异想天开,而且能让Python解析器保持简单. 此外,Python 还禁止重载内置类型的运算符,这个限制也能增强可读性和可预知的性能. Gosling 接着说道: 社区中约有10%的人能正确地使用和真正关心运算符重载,对这些人来说,运算符重载是极其重要的. 这部分人几乎专门处理数字,在这一领域中,为了符合人类的直觉,表示法特别重要,因为他们进入这一领域时, 直觉中已经知道`+`的意思,他们知道`“a + b”`中的`a`和`b`可以是复数、矩阵或其他合理的东西. 表示法方面的问题不能低估.下面以金融领域为例说明.在Python中,可以使用下述 公式计算复利: interest = principal * ((1 + rate) ** periods - 1) 不管涉及什么数字类型,这种表示法都成立.因此,如果是做重要的金融工作,你要确保periods是整数, rate``interest和principal是精确的数字(Python 中 decimal.Decimal类的实例), 这样上述公式就能完好运行. 但是在Java中,如果把float换成精度不定的BigDecimal,就无法再使用中缀运算符, 因为中缀运算符只支持基本类型.在 Java 中,支持 BigDecimal数字的公式要这样写: BigDecimal interest = principal.multiply(BigDecimal.ONE.add(rate) .pow(periods).subtract(BigDecimal.ONE)); 显然,使用中缀运算符的公式更易读,至少对大多数人来说如此.为了让中缀运算符表示法支持非基本类型, 运算符必须能重载.Python是门高级语言,易于使用,支持运算符重载可能就是它这些年在科学计算领域得到广泛使用的主要原因. 当然,语言不支持运算符重载也有好处.对极为重视性能和安全的低级系统语言而言,这无疑是正确的决定. 新近出现的Go语言在这方面效仿了Java,它不支持运算符重载. 但是,重载的运算符,如果使用得当,的确能让代码更易于阅读和编写.对现代的高级语言来说,这是个好功能. 猴子补丁 猴子补丁的名声不太好.如果滥用,会导致系统难以理解和维护. 补丁通常与目标紧密耦合,因此很脆弱. 另一个问题是,打了猴子补丁的两个库可能相互牵绊,因为第二个库可能撤销了第一个库的补丁. 不过猴子补丁也有它的作用,例如可以在运行时让类实现协议.适配器设计模式通过实现全新的类解决这种问题. 为 Python 打猴子补丁不难,但是有些局限.Python 不允许为内置类型打猴子补丁.其实我觉得这是优点, 因为这样可以确保 str对象的方法始终是那些.这一局限能减少外部库打的补丁有冲突的概率. Python 装饰器和装饰器设计模式 Python 函数装饰器符合Gamma等人在《设计模式:可复用面向对象软件的基础》一 书中对“装饰器”模式的一般描述: “动态地给一个对象添加一些额外的职责。就扩展功能而言,装饰器模式比子类化更灵活。” 在实现层面,Python装饰器与“装饰器”设计模式不同,但是有些相似之处: 在设计模式中,Decorator 和 Component 是抽象类. 为了给具体组件添加行为,具体装饰器的实例要包装具体组件的实例.《设计模式:可复用面向对象软件的基础》一书是 这样说的: 装饰器与它所装饰的组件接口一致,因此它对使用该组件的客户透明.它将客户请求转发给该组件,并且可能在转发前后执行一些额外的操作(例如绘制一个边框)。透明性使得你可以递归嵌套多个装饰器,从而可以添加任意多的功能.(第 115页) 在 Python 中,装饰器函数相当于Decorator的具体子类,而装饰器返回的内部函数相当于装饰器实例.返回的函数包装了被装饰的函数,这相当于“装饰器”设计模式中的组件.返回的函数是透明的,因为它接受相同的参数,符合组件的接口.返回的函数把调用转发给组件,可以在转发前后执行额外的操作.因此,前面引用那段话的最 后一句可以改成:“透明性使得你可以递归嵌套多个装饰器,从而可以添加任意多的行为.”这就是叠放装饰器的理论基础. 注意,我不是建议在 Python 程序中使用函数装饰器实现“装饰器”模式。在特定情况下确实可以这么做,但是一般来说,实现“装饰器”模式时最好使用类表示装饰器和要包装的组件。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-29 22:06:29 "},"设计模式/":{"url":"设计模式/","title":"设计模式","keywords":"","body":"设计模式 虽然设计模式与语言无关，但这并不意味着每一个模式都能在每一门语言中使用.1996 年，Peter Norvig在题为Design Patterns in Dynamic Languages 的演讲中指出，Gamma 等人合著的《设计模式：可复用面向对象软件的基础》一 书中有23个模式，其中有16个在动态语言中'不见了，或者简化了'.他讨论的是Lisp 和Dylan, 不过很多相关的动态特性在Python中也能找到. 《设计模式：可复用面向对象软件的基础》的作者在引言中承认，所用的语言决定了哪些 模式可用： 程序设计语言的选择非常重要，它将影响人们理解问题的出发点。我们的设计模式采用了 Smalltalk 和C++ 层的语言特性，这个选择实际上决定了哪些机制可以方便地实现，而哪些则不能。 若我们采用过程式语言，可能就要包括诸如“集成”“封装”和“多态”的设计模式。 相应地，一些特殊的面向对象语言可以直接支持我们的某些模式，例如CLOS 支持多方法概念， 这就减少了访问者模式的必要性. 具体而言，Norvig 建议在有一等函数的语言中重新审视“策略”“命令”“模板方法”和“访问者”模式. 通常，我们可以把这些模式中涉及的某些类的实例替换成简单的函数，从而减少样板代码. 策略模式 命令模式 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-24 20:03:49 "},"设计模式/策略模式.html":{"url":"设计模式/策略模式.html","title":"策略模式","keywords":"","body":"经典的“策略”模式 UML 类图指出了“策略”模式对类的编排: [设计模式:可复用面向对象软件的基础]一书是这样概述\"策略\"模式的: 定义一系列算法,把它们一一封装起来,并且使它们可以相互替换。本模式使得算法可以独立于使用它的客户而变化. 电商领域有个功能明显可以使用“策略”模式,即根据客户的属性或订单中的商品计算折扣.假如一个网店制定了下述折扣规则。 有 1000 或以上积分的顾客,每个订单享 5% 折扣。 同一订单中,单个商品的数量达到 20 个或以上,享 10% 折扣。 订单中的不同商品达到 10 个或以上,享 7% 折扣。 简单起见,我们假定一个订单一次只能享用一个折扣.\"策略\"模式的UML类图,其中涉及下列内容。 上下文 把一些计算委托给实现不同算法的可互换组件,它提供服务。在这个电商示例中,上下文是 Order,它会根据不同的算法计算促销折扣。 策略 实现不同算法的组件共同的接口。在这个示例中,名为 Promotion 的抽象类扮演这个角色。 具体策略 \"策略\"的具体子类。fidelityPromo、BulkPromo 和 LargeOrderPromo是这里实现的三个具体策略。 from abc import ABC, abstractmethod from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: \"\"\"上下文 \"\"\" def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion.discount(self) return self.total() - discount def __repr__(self): fmt = '' return fmt.format(self.total(), self.due()) class Promotion(ABC): \"\"\"策略:抽象基类\"\"\" @abstractmethod def discount(self, order): \"\"\"返回折扣金额(正值)\"\"\" pass class FidelityPromo(Promotion): # 第一个具体策略 \"\"\"为积分为1000或以上的顾客提供5%折扣\"\"\" def discount(self, order): return order.total() * .05 if order.customer.fidelity >= 1000 else 0 class BulkItemPromo(Promotion): # 第二个具体策略 \"\"\"单个商品为20个或以上时提供10%折扣\"\"\" def discount(self, order): discount = 0 for item in order.cart: if item.quantity >= 20: discount += item.total() * .1 return discount class LargeOrderPromo(Promotion): # 第三个具体策略 \"\"\"订单中的不同商品达到10个或以上时提供7%折扣\"\"\" def discount(self, order): distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * .07 return 0 joe = Customer('John Doe', 0) ann = Customer('Ann Smith', 1100) cart = [LineItem('banana', 4, .5), LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)] Order(joe,cart,FidelityPromo()) Order(ann, cart, FidelityPromo()) banana_cart = [LineItem('banana', 30, .5), LineItem('apple', 10, 1.5)] Order(joe,banana_cart,BulkItemPromo()) long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)] Order(joe, long_order, LargeOrderPromo()) Order(joe, cart, LargeOrderPromo()) 使用装饰器优化策略模式 上例完全可用,但是利用 Python 中的装饰器,可以使用更少的代码实现相同的功能.本例除了实现策略模式,还提供了一个选择最佳策略的函数best_promo from abc import ABC, abstractmethod from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: \"\"\"上下文 \"\"\" def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount def __repr__(self): fmt = '' return fmt.format(self.total(), self.due()) promos = [] def promotion(promo_func): promos.append(promo_func) return promo_func @promotion def fidelity(order): \"\"\"为积分为1000或以上的顾客提供5%折扣\"\"\" return order.total() * .05 if order.customer.fidelity >= 1000 else 0 @promotion def bulk_item(order): \"\"\"单个商品为20个或以上时提供10%折扣\"\"\" discount = 0 for item in order.cart: if item.quantity >= 20: discount += item.total() * .1 return discount @promotion def large_order(order): \"\"\"订单中的不同商品达到10个或以上时提供7%折扣\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * .07 return 0 def best_promo(customer, cart): \"\"\"选择可用的最佳折扣\"\"\" order = Order(joe, banana_cart ) max_off,best_promo = max(((promo(order),promo) for promo in promos), key=lambda x:x[0]) return max_off,best_promo.__name__,Order(joe, banana_cart,best_promo) joe = Customer('John Doe', 0) ann = Customer('Ann Smith', 1100) cart = [LineItem('banana', 4, .5), LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)] Order(ann, cart, fidelity) banana_cart = [LineItem('banana', 30, .5), LineItem('apple', 10, 1.5)] Order(joe, banana_cart, bulk_item) long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)] Order(joe, long_order, large_order) Order(joe, cart, large_order) best_promo(joe, banana_cart) (1.5, 'bulk_item', ) best_promo(joe, banana_cart) (1.5, 'bulk_item', ) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-24 20:03:49 "},"设计模式/命令模式.html":{"url":"设计模式/命令模式.html","title":"命令模式","keywords":"","body":"命令模式 “命令”模式的目的是解耦调用操作的对象（调用者）和提供实现的对象（接收者）。在《设计模式：可复用面向对象软件的基础》所举的示例中，调用者是图形应用程序中的菜单项，而接收者是被编辑的文档或应用程序自身. 这个模式的做法是，在二者之间放一个Command对象，让它实现只有一个方法（execute）的接口，调用接收者中的方法执行所需的操作。这样，调用者无需了解接收者的接口而且不同的接收者可以适应不同的Command子类.调用者有一个具体的命令，通过调用execute 方法执行。注意，中的MacroCommand 可能保存一系列命令，它的execute() 方法会在各个命令上调用相同的方法。 Gamma等人说过：“命令模式是回调机制的面向对象替代品。”问题是，我们需要回调机制的面向对象替代品吗？有时确实需要，但并非始终需要。 我们可以不为调用者提供一个Command实例，而是给它一个函数.此时，调用者不用调用command.execute()，直接调用command()即可。MacroCommand可以实现成定义了__call__方法的类。这样,MacroCommand的实例就是可调用对象，各自维护着一个函数列表，供以后调用. class MacroCommand: \"\"\"一个执行一组命令的命令\"\"\" def __init__(self,commands): self.commands = list(commands) def __call__(self): for command in self.commands: command() def command1(): print(\"a\") def command2(): print(\"b\") def command3(): print(\"c\") mc = MacroCommand([command1,command2,command3]) mc() a b c python的一等函数特性为命令模式节省了大量的代码, Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-24 20:03:49 "},"设计模式/结语.html":{"url":"设计模式/结语.html","title":"结语","keywords":"","body":"结语 Python拥有一等函数和一等类型Norvig声称，这些特性对23个模式中的16 个有影 响（“Design Patterns in Dynamic Languages”，第10 张幻灯片 。Python还有泛函数。泛函数与CLOS 中的多方法（multimethod）类似，Gamma 等人建议使用多方法以一种简单的方式实现经典 的“访问者”模式。Norvig 却说，多方法能简化“生成器”模式(第10 张幻灯片)可见，设计模式与语言特性无法精确对应。 世界各地的课堂经常使用Java示例讲解设计模式。我不止一次听学生说过，他们以为设计模式在任何语言中都有用. 事实证明，在Gamma等人合著的那本书中，尽管大部分使用C++代码说明,但是23个“经典的”设计模式都能很好地 在“经典的”Java 中运用.然而,这并不意味着所有模式都能一成不变地在任何语言中运用. 那本书的作者在开头就明确表明了，“一些特殊的面向对象语言可以直接支持我们的某些模式”. 与Java、C++或Ruby 相比，Python 设计模式方面的书籍都很薄.如今,Python 在学术界越来越流行， 希望以后会有更多以这门语言讲解设计模式的书籍.此外，Java 8 引入了方法引用和匿名函数, 这些广受期盼的特性有可能为Java催生新的模式实现方式——要知道,语言会进化,因此运用经典设计模式的方式必定要随之进化。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-24 20:03:49 "},"标准库中的数学工具/":{"url":"标准库中的数学工具/","title":"标准库中的数学工具","keywords":"","body":"标准库中的数学工具 不考虑向量化计算,不考虑运算速度的话数学运算完全可以使用标准库来解决 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 08:59:16 "},"标准库中的数学工具/数学运算模块.html":{"url":"标准库中的数学工具/数学运算模块.html","title":"数学运算模块","keywords":"","body":"数学模块math 数学模块math python自带的math模块提供了一些常用的数学运算和常数 常数 常数 说明 math.e 自然常数e math.pi 圆周率pi 数值 函数 说明 例子 math.ceil(x) 返回大于x的整数上限的浮点数,x为整数则返回自己的浮点形式 math.ceil(1)->1.0,math.ceil(1.1)->2.0,math.ceil(-1.5)->-1.0 math.copysign(x, y) 返回绝对值为x,符号为y的符号的数 math.copysign(1.0, -0.0)->-1.0 math.fabs(x) 相当于abs(x),返回绝对值 math.fabs(-3.4)->3.4 math.factorial(x) 数学上的x!,阶乘 math.factorial(3)->6 math.floor(x) 与ceil相反,得到上限 math.floor(-0.5)->-1.0 math.fmod(x, y) 求模运算,适合用在浮点数,注意和%的不同 math.fmod(3.5, -2)->1.53.5%-2->-0.5 math.frexp(x) 将x拆成分(m,e),x== m 2*e math.frexp(2.43)->(0.6075, 2) math.fsum(iterable) 求序列中所有数的和的精确值 fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])->1.0 math.isinf(x) 判断x是不是float(\"inf\") --- math.isnan(x) 判断x是不是float(\"NaN\") --- math.ldexp(m,e) 求m 2*e math.ldexp(3, 1)->6.0 math.modf(x) 拆分整数小数部分 math.modf(-3.5)->(-0.5, -3.0) math.trunc(x) 返回整数部分 math.trunc(3.5)->3 平方和对数 函数 说明 例子 math.exp(x) 自然数的幂 e**x math.exp(2)->7.38905609893065 math.expm1(x) 返回e的x次方减1 math.expm1(2)->6.38905609893065 math.log(x[, base]) 返回x的以base为底的对数，base默认为e math.log(math.e)->1.0math.log(10,2)->3.3219280948873626 math.log10(x) 返回x的以10为底的对数 math.log10(2)->0.30102999566398114 math.log1p(x) 返回1+x的自然对数（以e为底) math.log1p(math.e-1)->1.0 math.pow(x, y) 返回x的y次方 math.pow(5,3)->125.0 math.sqrt(x) 返回x的平方根 math.sqrt(3)->1.7320508075688772 三角函数 弧度 函数 说明 math.acos(x) acos(x) math.asin(x) asin(x) math.atan(x) atan(x) math.atan2(y, x) atan(y / x) math.cos(x) cos(x) math.hypot(x, y) sqrt(xx + yy) math.sin(x) sin(x) math.tan(x) tan(x) 角度,弧度转换 函数 说明 math.degrees(x) 弧度转度 math.radians(x) 度转弧度 双曲函数 函数 说明 math.sinh(x) 双曲正弦 $ \\sinh x = {\\frac {e^x - e^{ - x} } 2} $ math.cosh(x) 双曲余弦 $ \\cosh x = {\\frac {e^x + e^{ - x} } 2} $ math.tanh(x) 双曲正切 $ \\tanh x = {\\frac {\\sinh x} {\\cosh x}} $ math.acosh(x) 反双曲余弦 math.asinh(x) 反双曲正弦 math.atanh(x) 反双曲正切 特殊函数: 函数 说明 math.erf(x) 误差函数: $\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-t^2}\\,\\mathrm dt.$ math.erfc(x) 互补误差函数:$\\mbox{erfc}(x) = 1-\\mbox{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_x^{\\infty} e^{-t^2}\\,\\mathrm dt\\,.$ math.gamma(x) 伽玛函数 $\\Gamma(z) = \\int_{0}^{\\infty} \\frac{t^{z-1}}{\\mathrm{e}^t} \\,{\\rm{d}}t$ math.lgamma(x) 伽马函数绝对值的自然对数 在标准库中还有一个cmath,他是针对复数的数学库,差不太多就不做详细介绍了. 而3.4后新增的统计模块因为数据科学一般用2.7版本,所以也不多介绍 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 09:03:20 "},"标准库中的数学工具/统计模块.html":{"url":"标准库中的数学工具/统计模块.html","title":"统计模块","keywords":"","body":"统计模块(statistics) 该模块是3.4后新增的模块,这个模块提供一些统计学方法 均值中心性 函数 说明 mean() 均值 median() 中位数 median_low() Low median of data. median_high() High median of data. median_grouped() Median, or 50th percentile, of grouped data. mode() 众数 Mode (most common value) of discrete data. L = range(10000) from statistics import mean,median,median_low,median_high,median_grouped,mode mean(L) 4999.5 median(L) 4999.5 median_low(L) 4999 median_low(L) 4999 median_high(L) 5000 median_high(L) 5000 median_grouped(L) 4999.5 median_grouped(L, interval=2) 4999.0 from random import randint XL = [randint(1,10) for i in range(10000)] mode(XL) 7 分布统计 函数 说明 pstdev() 总体标准差 pvariance() 总体方差 stdev() 样本标准差 variance() 样本方差 from statistics import pstdev,pvariance,stdev,variance pstdev(L) 2886.751331514372 pvariance(L) 8333333.25 stdev(L) 2886.8956799071675 variance(L) 8334166.666666667 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:51:20 "},"标准库中的数学工具/高精度计算.html":{"url":"标准库中的数学工具/高精度计算.html","title":"高精度计算","keywords":"","body":"高精度计算(decimal) 高精度计算模块(decimal)提供了一种可用于代替float的数据类型,这种数据类型并不适合计算,但在需要高精度浮点运算时比较好用,适合用在财务上. 这种数据类型可以由整数,浮点数,数字字符串转化得来 获得当前精度环境 from decimal import getcontext getcontext() Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999, capitals=1, clamp=0, flags=[], traps=[InvalidOperation, DivisionByZero, Overflow]) 设定精度 getcontext().prec = 10 转化为decimal数据类型 from decimal import Decimal Decimal(1) / Decimal(7) Decimal('0.1428571429') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:51:13 "},"标准库中的数学工具/有理数.html":{"url":"标准库中的数学工具/有理数.html","title":"有理数","keywords":"","body":"有理数(fractions) 有理数(fractions)模块提供了一种用来表示有理数的数据类型,它可以用整数,浮点数,高精度数或者数字和除号字符串创建 from fractions import Fraction Fraction(16, -10) Fraction(-8, 5) Fraction(123) Fraction(123, 1) Fraction() Fraction(0, 1) Fraction('3/7') Fraction(3, 7) Fraction('1.414213 \\t\\n') Fraction(1414213, 1000000) Fraction('-.125') Fraction(-1, 8) Fraction('7e-6') Fraction(7, 1000000) Fraction(2.25) Fraction(9, 4) Fraction(1.1) Fraction(2476979795053773, 2251799813685248) from decimal import Decimal Fraction(Decimal('1.1')) Fraction(11, 10) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:51:26 "},"标准库中的数学工具/复数运算.html":{"url":"标准库中的数学工具/复数运算.html","title":"复数运算","keywords":"","body":"复数运算(cmath) 这个模块和math很像,只是面向的操作对象是复数.所以就只写独有的了 from cmath import phase,polar,rect 极坐标转换 phase()求相(相当于求atan2(x.imag, x.real)) phase(-1.0+0.0j) 3.141592653589793 phase(complex(-1.0,-0.0)) -3.141592653589793 polar(x) 转换为极坐标 polar(x) 相当于 (abs(x), phase(x)). polar(complex(-1.0,-0.0)) (1.0, -3.141592653589793) rect(r,phi)已知半径和度数求以两边长为值的复数 r∗(math.cos(phi)+math.sin(phi)∗1j)r * (math.cos(phi) + math.sin(phi)*1j)r∗(math.cos(phi)+math.sin(phi)∗1j) from math import pi rect(1,pi/4) (0.7071067811865476+0.7071067811865475j) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:51:38 "},"随机数据生成工具/":{"url":"随机数据生成工具/","title":"随机数据生成工具","keywords":"","body":"随机数据生成工具 随机数据往往在测试中使用很多,标准库中提供了random,而radar模块可以简单的生成一个随机时间,faker模块可以生成一些符合人类社会规律的随机字符串. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 10:05:48 "},"随机数据生成工具/随机模块/随机模块.html":{"url":"随机数据生成工具/随机模块/随机模块.html","title":"随机模块","keywords":"","body":"随机模块random 常规用法 无论在做测试中还是在做模拟中,随机都是必须的模块,具体这样用: import random random.random() # [0,1)内随机浮点数 0.7824556762411076 random.uniform(1, 10) # [1,10)内随机浮点数 8.901229706407147 random.randint(1, 10) # [1,10]范围内的随机整数 8 random.randrange(0, 101, 2) # 从等差数列中随机挑一个数 88 random.choice('abcdefghij') # 随机选一个 'd' items = [1, 2, 3, 4, 5, 6, 7] random.shuffle(items)#随机排序 random.sample([1, 2, 3, 4, 5], 3) # 随机选3个元素 [5, 2, 4] 随机种子 学过C的都知道伪随机,python也是伪随机,所以可以通过设定seed值来改变随机状态 from matplotlib import pyplot as plt %matplotlib inline 数学上的一些特殊随机 三角分布: 三角分布式是连续概率分布,可以看做是在一个范围中有一个数(众数)它附近有最高的概率密度即最有可能出现在该众数上 random.triangular(low, high, mode)#三角形分布,默认众数(mode)是中值 hight,low,mode = 0,2,0.5 random.triangular(hight,low,mode) 1.2624977374708657 from collections import Counter c = Counter() for nbr in [round(random.triangular(0,2,0.5),2) for i in range(10000)]: c[nbr] = c[nbr] + 1 plt.plot([float(i) for i in c.keys()],[float(i) for i in c.values()],\".\") plt.show() β分布 β分布是在0到1上的特殊分布, 做硬币试验的假定分布，即做伯努利试验的假定分布在确定伯努利试验的分布之前，我们利用试验的少量数据来估计试验的概率（作为先验概率）beta分布涉及两个参数：1、试验成功的次数2、试验失败的次数. 概率密度函数为: $\\begin{align} f(x)=& x^{\\alpha-1}(1-x)^{\\beta-1} \\over \\int_0^1 u^{\\alpha-1}(1-u)^{\\beta-1}du\\ =&{\\frac {\\Gamma(\\alpha+\\beta)} {\\Gamma(\\alpha)\\Gamma(\\beta)}}x^{\\alpha-1}(1-x)^{\\beta-1}\\ =&{\\frac {1} {B(\\alpha-\\beta)}}x^{\\alpha-1}(1-x)^{\\beta-1} \\end{align} $ 累积分布函数: $\\begin{align} F(x;\\alpha,\\beta)=& \\frac {B_x(\\alpha,\\beta)} {B(\\alpha,\\beta)}&=I_x(\\alpha,\\beta) \\end{align} $ 其中${B_x(\\alpha,\\beta)}$是不完全Β函数,${I_x(\\alpha,\\beta)}$ 是正则不完全贝塔函数 是不完全Β函数，$I_x (\\alpha,\\beta)$ 是正则不完全贝塔函数 random.betavariate(alpha, beta)#beta分布 l0=[random.betavariate(0.5,1) for i in range(100000)] l1=[random.betavariate(2,3) for i in range(100000)] l2=[random.betavariate(3,4) for i in range(100000)] l3=[random.betavariate(2,5) for i in range(100000)] r0=[len([1 for j in l0 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r1=[len([1 for j in l1 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r2=[len([1 for j in l2 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r3=[len([1 for j in l3 if i+0.005>j>i-0.005]) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r2,color=\"green\") plt.plot(list(map(lambda x:round(x*0.01,3), range(0,100,1))),r3,color=\"yellow\") plt.show() 指数分布 概率密度函数: 指数分布可以用来表示独立随机事件发生的时间间隔，比如旅客进机场的时间间隔、中文维基百科新条目出现的时间间隔等等。 许多电子产品的寿命分布一般服从指数分布。有的系统的寿命分布也可用指数分布来近似。它在可靠性研究中是最常用的一种分布形式。指数分布是伽玛分布和威布尔分布的特殊情况，产品的失效是偶然失效时，其寿命服从指数分布。 指数分布可以看作当威布尔分布中的形状系数等于1的特殊分布，指数分布的失效率是与时间t无关的常数，所以分布函数简单。 概率密度函数: $ f(x)=\\begin{cases} \\lambda e^{-\\lambda x}&\\text{$x>0$},\\ 0&\\text{$x\\le0$}. \\end{cases} $ 累积分布函数: $ F(x;\\lambda)=\\begin{cases} 1- e^{-\\lambda x}&\\text{$x\\ge0$},\\ 0&\\text{$x 期望值: $ EX=\\lambda^{-1} $ 方差: $D(X)=Var(X)=\\lambda ^{-2}$ random.expovariate(lambd) random.expovariate(3) 0.5578234614537964 c_e3 = Counter() for nbr in [round(random.expovariate(3),2 ) for i in range(10000)]: c_e3[nbr] = c_e3[nbr] + 1 plt.plot([float(i) for i in c_e3.keys()], [float(i) for i in c_e3.values()],\".\") plt.show() 伽玛分布 概率密度函数: 令 $X\\sim \\Gamma(\\alpha,\\beta)$ ; 则有: $f(x)={\\frac {x^{(\\alpha-1)} e^{(-\\lambda x)}} {\\Gamma(\\alpha)\\beta^\\alpha}} ,x>0 $ random.gammavariate(alpha, beta) c_gamma = Counter() for nbr in [round(random.gammavariate(5,0.5),2 ) for i in range(10000)]: c_gamma [nbr] = c_gamma [nbr] + 1 plt.plot([float(i) for i in c_gamma.keys()], [float(i) for i in c_gamma.values()],\".\") plt.show() 高斯分布(正态分布) 概率密度函数: $ f(x)={\\frac 1 {\\sqrt {2\\pi}\\sigma}} e^{-{\\frac {(x-\\mu)^2} {2\\sigma^2}}} $ 其中 $\\mu$ 与 $\\sigma$ 分别是变量对数的平均值与标准差 random.gauss(mu, sigma)#略快于下面的方法 random.normalvariate(mu, sigma) c_gauss = Counter() for nbr in [round(random.gauss(0,1),2 ) for i in range(10000)]: c_gauss[nbr] = c_gauss[nbr] + 1 plt.plot([float(i) for i in c_gauss.keys()], [float(i) for i in c_gauss.values()],\".\") plt.show() 对数正态分布 如果 X 是正态分布的随机变量，则 exp(X) 为对数正态分布；同样，如果 Y 是对数正态分布，则 ln(Y) 为正态分布。 如果一个变量可以看作是许多很小独立因子的乘积，则这个变量可以看作是对数正态分布。 概率密度函数: $ f(x;\\mu,\\sigma) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} e^{-(\\ln x - \\mu)^2/2\\sigma^2} $ 其中 $\\mu$ 与 $\\sigma$ 分别是变量对数的平均值与标准差 random.lognormvariate(mu, sigma) c_log = Counter() for nbr in [round(random.lognormvariate(0.5,0.5),2 ) for i in range(10000)]: c_log[nbr] = c_log[nbr] + 1 plt.plot([float(i) for i in c_log.keys()],[float(i) for i in c_log.values()],\".\") plt.show() 冯·米塞斯分布 冯·米塞斯分布（von Mises distribution）指一种圆上连续概率分布模型，它也被称作循环正态分布 概率密度函数: $ f(x|\\mu,\\kappa)=\\frac{e^{\\kappa\\cos(x-\\mu)}}{2\\pi I_0(\\kappa)} $ 参数μ和1/κ是μ和σ^2（对应正态分布中的均值和方差）的模拟量 μ是位置的度量（分布将围绕μ成簇） κ是集中度的度量（分散度的倒数，所以1/κ是σ^2的模拟量） 如果κ为0，分布是均匀分布，对于κ很小的情形，分布近似均匀分布 如果κ很大，分布紧紧围绕μ集中分布。实际上，随着κ增加，分布将趋于x以μ为均值1/κ为方差的正态分布 random.vonmisesvariate(mu, kappa) c_von = Counter() for nbr in [round(random.vonmisesvariate(10,1),2 ) for i in range(10000)]: c_von[nbr] = c_von[nbr] + 1 plt.plot([float(i) for i in c_von.keys()], [float(i) for i in c_von.values()],\".\") plt.show() 帕累托分布 帕累托法则(2,8定律) 帕累托分布是以意大利经济学家维弗雷多·帕雷托命名的。 是从大量真实世界的现象中发现的幂定律分布。这个分布在经济学以外，也被称为布拉德福分布。 概率密度函数: $ p(x) = \\left { \\begin{matrix} 0, & \\mbox{if }x {\\min}; \\ \\ {\\frac{k \\; x{\\min}^k} {x^{k+1}}}, & \\mbox{if }x > x_{\\min}. \\end{matrix} \\right. $ k是形状参数(shape parameter) random.paretovariate(k) c_par = Counter() for nbr in [round(random.paretovariate(10),2 ) for i in range(10000)]: c_par[nbr] = c_par[nbr] + 1 plt.plot([float(i) for i in c_par.keys()], [float(i) for i in c_par.values()],\".\") plt.show() 韦伯分布 韦伯分布（Weibull distribution），又称韦氏分布或威布尔分布，是可靠性分析和寿命检验的理论基础。 概率密度函数: $ f(x;\\lambda,k) = \\begin{cases} \\frac{k}{\\lambda}\\left(\\frac{x}{\\lambda}\\right)^{k-1}e^{-(x/\\lambda)^{k}} & x\\geq0\\ 0 & x λ＞0是比例参数（scale parameter），k＞0是形状参数（shape parameter） random.weibullvariate(lambda, k) c_wei = Counter() for nbr in [round(random.weibullvariate(2,1),2 ) for i in range(10000)]: c_wei[nbr] = c_wei[nbr] + 1 plt.plot([float(i) for i in c_wei.keys()], [float(i) for i in c_wei.values()],\".\") plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 10:24:58 "},"随机数据生成工具/随机时间生成器.html":{"url":"随机数据生成工具/随机时间生成器.html","title":"随机时间生成器","keywords":"","body":"随机时间生成器--radar radar可以用于生成一个随机的时间点 安装模块 pip install radar 产生一个随机时间 import radar radar.random_datetime() datetime.datetime(1998, 8, 9, 7, 44, 16) 产生一个时间区间内的随机时间 import datetime import radar radar.random_date( start = datetime.datetime(year=2000, month=5, day=24), stop = datetime.datetime(year=2013, month=5, day=24) ) datetime.datetime(2003, 10, 2, 23, 37, 18) 也可以使用字符串定位时间 radar.random_datetime(start='2012-05-24T00:00:00', stop='2013-05-24T23:59:59') datetime.datetime(2012, 6, 28, 8, 23, 34) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 09:59:54 "},"随机数据生成工具/伪造信息生成器.html":{"url":"随机数据生成工具/伪造信息生成器.html","title":"伪造信息生成器","keywords":"","body":"随机名字和名字相关字符串生成器--ForgeryPy 这个小工具可以生成与名字相关的各种值,用来做数据库相关的测试非常合适,官网api在这边. 安装: pip install forgerypy 使用: from forgery_py import name name.first_name() # 名 'Richard' name.last_name() # 姓 'Kim' name.full_name() #全名 'Kathryn Schmidt' name.male_first_name() # 男性名 'Kathleen' name.female_first_name() # 女性名 'Sandra' name.company_name() # 公司名 'Lazzy' name.job_title() # 职位头衔 'Programmer Analyst IV' name.job_title_suffix() # 职位头衔后缀 'II' name.title() # 头衔 'Ms' name.suffix() #后缀 'Jr' name.location() #地址 'Shell Cottage' name.industry() #产业 'Farm & Construction Machinery' 假数据制造工具Faker 我们常常需要利用一些假数据来做测试,这种时候就可以使用Faker来伪造数据从而用来测试. 安装pip install Faker 使用 faker提供一个工厂函数,用来创建数据 from faker import Factory fake1 = Factory.create() 当然了也提供一个Faker类来创建fake实例 from faker import Faker fake2 = Faker() fake1.name() 'Anna Stewart' fake2.name() 'Michelle Beltran' 可以为对象设置本地化信息,只需要在其中添加如下参数中的一个即可: bg_BG - Bulgarian cs_CZ - Czech de_DE - German dk_DK - Danish el_GR - Greek en_AU - English (Australia) en_CA - English (Canada) en_GB - English (Great Britain) en_US - English (United States) es_ES - Spanish (Spain) es_MX - Spanish (Mexico) fa_IR - Persian (Iran) fi_FI - Finnish fr_FR - French hi_IN - Hindi hr_HR - Croatian it_IT - Italian ja_JP - Japanese ko_KR - Korean lt_LT - Lithuanian lv_LV - Latvian ne_NP - Nepali nl_NL - Dutch (Netherlands) no_NO - Norwegian pl_PL - Polish pt_BR - Portuguese (Brazil) pt_PT - Portuguese (Portugal) ru_RU - Russian sl_SI - Slovene sv_SE - Swedish tr_TR - Turkish uk_UA - Ukrainian zh_CN - Chinese (China) zh_TW - Chinese (Taiwan) fake = Faker(\"zh_CN\") 每次调用fake对象的方法比如name(),都会产生一个不同随机内容.这些方法包括: address 地址 barcode 条码 color 颜色 company 公司 credit_card 银行卡号 currency 货币 date_time 日期 file 文件 internet 互联网 job 工作 lorem 乱数假文 misc 杂项 person 人物 phone_number 电话号码 profile 人物profile信息 python python数据 ssn 社会安全码(身份证号码) user_agent 用户代理 同时,我们可以用fake的seed方法设定一个随机种子 fake.seed(4321) 随机选择 fake.random_element(elements=(u'台湾', u'香港', u'澳门'))# 从几个元素中选择 '香港' fake.random_digit()# 随机数字 0 fake.random_digit_or_empty()# 随机数字或者空 1 fake.random_digit_not_null()#随机非null数字 3 fake.random_digit_not_null_or_empty()# 随机非null数字或者空 2 fake.random_int(min=0, max=9999) # 随机整数 694 fake.randomize_nb_elements(number=10, le=False, ge=False)#某数附近的数 9 fake.random_sample(elements=('a', 'b', 'c'), length=None)# 随机可重复元素组合 ['a', 'b', 'b'] fake.random_sample_unique(elements=('a', 'b', 'c'), length=None)# 随机非重复元素组合 {'a', 'c'} fake.random_number(digits=None) # 随机数 688833 fake.random_letter() #随机字母 'B' fake.numerify(text=\"###\")# 数字字符串 '727' fake.lexify(text=\"????\")# 随机字母串 'ahIj' fake.bothify(text=\"## ??\")#用占位符表示字母或数字,随机生成字符串 '73 VP' address 地址 fake.country()#国家 '法国' fake.city()#城市 '桂珍市' fake.latitude()#纬度 Decimal('82.427230') fake.longitude() #经度 Decimal('-62.090808') fake.city_suffix()#城市的后缀,中文就是市了 '市' fake.state()#区 '东丽区' fake.street_address()#街道 '阙路g座' fake.address()#地址 '阳市符街z座 956147' fake.country_code()#国家编码 'BY' fake.building_number() # 楼号 'O座' fake.geo_coordinate(center=None, radius=0.001)# 地理坐标 Decimal('-14.279606') fake.street_suffix()#街道后缀,中文就是路或者街这类了 '街' fake.street_name()#街道名 '封路' fake.postcode()# 邮编 '789068' barcode 条码 fake.ean8()#8位条码 '58133842' fake.ean13()#13位条码 '1198769812909' fake.ean(length=8)#自定义位数条码,可选8或者13 '46438294' color 颜色 fake.hex_color()#16进制表示的颜色 '#7bf862' fake.rgb_css_color()# css用的rgb色 'rgb(96,156,84)' fake.color_name()#颜色名字 'Lime' fake.safe_hex_color()#安全16进制色 '#aa8800' fake.rgb_color()#rgb色字符串 '167,202,48' fake.safe_color_name()#安全颜色名字 'aqua' fake.rgb_color_list()#rgb色元祖 (167, 79, 112) company 公司 fake.company() #公司名 '商软冠联信息有限公司' fake.company_suffix() #公司名后缀 '信息有限公司' credit_card 银行信用卡 fake.credit_card_number(card_type=None)#卡号 '3096904640103331' fake.credit_card_provider(card_type=None)# 卡提供者 'Discover' fake.credit_card_security_code(card_type=None)#卡密码 '197' fake.credit_card_full(card_type=None) #完整卡信息 'Diners Club / Carte Blanche\\n冬梅 吴\\n30532991312113 12/18\\nCVC: 434\\n' currency 货币 fake.currency_code()#货币 'BND' date_time 时间日期 fake.date_time(tzinfo=None)#随机日期时间 datetime(1981, 6, 12, 18, 51, 21) fake.iso8601(tzinfo=None)#以iso8601标准输出的日期 '1999-06-20T20:45:00' fake.date_time_this_month(before_now=True, after_now=False, tzinfo=None)#本月的某个日期 datetime.datetime(2017, 6, 23, 20, 46, 30) fake.date_time_this_year(before_now=True, after_now=False, tzinfo=None)#本年的某个日期 datetime.datetime(2017, 1, 30, 7, 6, 12) fake.date_time_this_decade(before_now=True, after_now=False, tzinfo=None)#本年代内的一个日期 datetime.datetime(2014, 8, 18, 8, 40, 42) fake.date_time_this_century(before_now=True, after_now=False, tzinfo=None)#本世纪一个日期 datetime.datetime(2016, 9, 25, 18, 1, 39) fake.date_time_between_dates(datetime_start=None, datetime_end=None, tzinfo=None)#两个时间间的一个随机时间 datetime.datetime(2017, 6, 30, 23, 31, 21) fake.date_time_between(start_date=\"-30y\", end_date=\"now\", tzinfo=None)#两个时间间的一个随机时间 datetime(1993, 3, 5, 13, 3, 30) fake.timezone()#时区 'Pacific/Tongatapu' fake.time(pattern=\"%H:%M:%S\")#时间 '21:58:56' fake.am_pm()#随机上午下午 'AM' fake.month()#随机月份 '07' fake.month_name()#随机月份名字 'March' fake.century()#随机世纪 'XVIII' fake.year()#随机年 '1976' fake.day_of_week()#随机星期几 'Saturday' fake.day_of_month()#随机月中某一天 '28' fake.time_delta()#随机时间延迟 datetime.timedelta(12792, 56895) fake.date_object()#随机日期对象 date(1976, 12, 15) fake.time_object()#随机时间对象 datetime.time(10, 16, 53) fake.unix_time()#随机unix时间 183659036 fake.date(pattern=\"%Y-%m-%d\")#随机日期 '2014-01-10' fake.date_time_ad(tzinfo=None)#公元后随机日期 datetime.datetime(673, 4, 13, 22, 3, 39) file 文件 help(fake.file_name) Help on method file_name in module faker.providers.file: file_name(category=None, extension=None) method of builtins.type instance :param category: audio|image|office|text|video :param extension: file extension fake.file_name(category=\"image\", extension=\"png\")# 文件名 'accusamus.png' fake.file_extension(category=None)#文件后缀 'png' fake.mime_type(category=None)#mime-type 'multipart/form-data' internet 互联网 fake.image_url(width=None, height=None)#图片url 'http://www.lorempixel.com/751/49' fake.ipv4(network=False)#ipv4地址 '78.254.118.129' fake.ipv6(network=False)#ipv6地址 'fb8:76ba:29b5:31d1:6db4:9167:5db5:31c4' fake.domain_word()#域名主体 'xu' fake.domain_name()#域名 'yang.cn' fake.uri_path(deep=None)#uri地址 'categories/search/explore' fake.tld()#域名后缀 'cn' fake.user_name()#用户名 'dlei' fake.mac_address()#MAC地址 '7b:0b:3f:b7:bc:5b' fake.url()#url 'http://www.qin.cn/' fake.safe_email()#安全邮箱 'napan@example.net' fake.free_email()#免费邮箱 'qianglei@gmail.com' fake.free_email_domain()#免费邮箱域名 'yahoo.com' fake.company_email()#公司邮箱 'jingwu@qin.cn' fake.email()#邮箱 'liyan@kong.com' fake.uri_extension()#uri扩展名 '.html' fake.uri_page()#uri页面 'faq' fake.uri()#uri 'https://jiang.com/categories/wp-content/categories/main.html' fake.slug()#slug 'totam-impedit-harum' job 工作 fake.job()#工作职位 'Animal nutritionist' lorem 乱数假文 fake.text(max_nb_chars=200)#随机生成一篇文章 '发生最后回复质量回复发表游戏以后.影响作者有些准备全国不同还是手机公司.合作经济不能这种.\\n可以合作我们不过价格学生一次是否.主题参加介绍希望可能一直.怎么品牌重要手机更多.发展她的其中成为为什是一那些基本.无法情况加入必须之后问题必须空间.\\n功能相关表示决定汽车部分.希望网上地方积分新闻.威望学习发布有些内容新闻.' fake.word()#随机单词 '大家' fake.words(nb=3)#随机生成几个字 ['软件', '准备', '增加'] fake.sentence(nb_words=6, variable_nb_words=True)#随机生成一个句子 '法律研究销售自己还有我的.' fake.sentences(nb=3)#随机生成几个句子 ['支持价格系列比较公司.', '东西社区发布环境社会的人.', '虽然浏览进入我们国内起来.'] fake.paragraph(nb_sentences=3, variable_nb_sentences=True)#随机成一段文字 '以下游戏地址一起语言.过程游戏注册朋友公司表示.标准销售表示个人业务.' fake.paragraphs(nb=3)#随机成几段文字 ['重要说明选择经营.浏览包括大小虽然功能.觉得评论对于网站工作.如何无法标准游戏评论进行一次.', '介绍次数关于应该最新价格.建设包括其实包括等级作为这些.出现现在报告还有地方现在.销售责任什么进行.', '公司组织上海孩子.政府国家新闻那么准备.起来关于目前威望要求电影.'] misc 杂项 fake.binary(length=10)#随机二进制字符串 b'\\x1b\\xc1\\xf5mM~\\x1ch\\x89\\xa2' fake.language_code()#随机语言代码 'et' fake.md5(raw_output=False)#随机md5 16进制字符串 'adccdc57d1d80d4ff1394f9b64e8b55d' fake.sha1(raw_output=False)#随机sha1 16进制字符串 '1c160e8b39d8c614dba5e14d74dd29861b5fe9ce' fake.sha256(raw_output=False)#随机sha256 16进制字符串 '11ed42b55f926f7caf08f9c5953c0d565e9f1b86d9fb12c7bfdd343f0748c8e5' fake.boolean(chance_of_getting_true=50)#随机真假值 False fake.null_boolean()#随机真假值和null True fake.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True)#随机密码 '^8$xwRzkaY' fake.locale()#随机本地代码 'fur_IT' fake.uuid4()#随机uuid 'f0af08fd-cccc-524e-0e95-7b3b7569ee31' person 人物 fake.name_female()#女性姓名 '华桂芝' fake.last_name_female() #女性姓 '扶' fake.first_name_female() #女性名 '欢' fake.name_male() #男性姓名 '毛丹' fake.last_name_male() #男性姓 '都' fake.first_name_male() #男性名 '洋' fake.name() #姓名 '班慧' fake.last_name() #姓 '逯' fake.first_name() #名 '玉梅' phone_number 电话号码 fake.phone_number() '13027346509' profile 人物profile信息 fake.profile(fields=None, sex=None) {'address': '静市宫街h座 913593', 'birthdate': '1993-09-21', 'blood_group': 'B-', 'company': '中建创业科技有限公司', 'current_location': (Decimal('19.9751845'), Decimal('57.471984')), 'job': 'Social worker', 'mail': 'juan54@hotmail.com', 'name': '商华', 'residence': '亮市雷路V座 732657', 'sex': 'F', 'ssn': '51060019870428913X', 'username': 'yantang', 'website': ['http://wen.cn/', 'https://www.jia.cn/']} s = fake.simple_profile(sex=\"m\") for i,v in s.items(): print(i,v) username jingzhong name 幸涛 sex M address 刚市杜街q座 385733 mail ifan@gmail.com birthdate 1985-04-24 python python数据 fake.pyint()#随机int 9605 fake.pyfloat(left_digits=None, right_digits=None, positive=False)#浮点数 98.414137273 fake.pydecimal(left_digits=None, right_digits=None, positive=False)#随机高精度数 Decimal('-67970964279026.8') fake.pystr(min_chars=None, max_chars=20)#随机字符串 'VCKwOANLGiMriwgAwmto' fake.pybool()#随机bool值 False fake.pystruct()#随机生成3个有10个元素的python数据结构 ([1759, 1706, 'lipeng@hu.com', 'OmnHjHhupbflepPEMqLU', 'oDsaYbnYBnHlzlvHlJUG', 'http://xia.com/wp-content/terms/', 5000, 246407354130820.0, 'KiwNbWEnpddmHRHWTZei', 'LKhKyMSzPpyjWAakEIMx'], {'amet': 4660, 'at': 444063.58774113, 'consequatur': 'hanyan@hotmail.com', 'enim': datetime(2010, 12, 6, 13, 40, 1), 'id': 9999, 'nam': 1640, 'nesciunt': 1970, 'occaecati': -17.18496, 'quia': 352, 'tenetur': 'yanxiang@yahoo.com'}, {'blanditiis': {1: 'mWyRHwssTCPwHQwlbRzw', 2: ['BDwCyYaRAuNaMRhsXCeN', 923, 'https://www.ren.cn/tag/author.jsp'], 3: {1: 'mingdu@gmail.com', 2: 7541, 3: [2502, Decimal('4225.8690732473')]}}, 'deserunt': {4: 'bHiwxuBWgjBCwXZsvWcl', 5: [9229, 'http://www.feng.cn/post/', Decimal('12017301176.414')], 6: {4: 'xFnjrUljdmUiIqHZWcrp', 5: datetime(1979, 11, 8, 4, 18, 36), 6: [datetime(2002, 9, 26, 15, 54, 31), 3695]}}, 'dicta': {3: 'tjVPhHslCvnNoUPfFrOZ', 4: ['rUybmzdXGMVEtEoPOvdc', 1428, 573], 5: {3: 'lutNKFIyegfcHPrjzxrX', 4: 'weizhou@wei.cn', 5: ['iyEYRlQuCBOdHOampimU', Decimal('-5223025.3455904')]}}, 'excepturi': {8: 'AgJsYutllJVQCPZkZwaF', 9: ['xMdaczaQDtVYJKPhoBcY', datetime(1993, 1, 2, 9, 27, 41), 'flai@hotmail.com'], 10: {8: 6686, 9: 'YbjuvGQzGkgApSprKZNq', 10: [2466, Decimal('2956.220391')]}}, 'mollitia': {2: 'zIBluugPYuwLSFslgGGj', 3: ['https://xue.com/index.htm', 738, 'OVPpwXBcxERhUPmknczr'], 4: {2: 'laMntQJKkyQzZDQJikvi', 3: 'sVCRRLzXqcmMbIzEhDxL', 4: ['http://wei.org/register.html', 6814]}}, 'numquam': {6: 340, 7: [6460, 'xiazhang@gmail.com', 'uCTMfthfYKXdGOhlfLRU'], 8: {6: 'YbdQMpbkYXQgIEgzIgZk', 7: 'hegang@hotmail.com', 8: ['sIjaymFwtLXjgQGSRvRc', Decimal('-5619186808.8')]}}, 'odio': {5: Decimal('-4626.3872120135'), 6: ['DrngdnwMJEQpvbZxLSIG', 3152, -5400.25], 7: {5: 'OfAQLtOhbWqUyWLnIQCs', 6: 'HaVgeZEsHlKeZJiwymUm', 7: ['KOxygkQYcxWIrkrNjzkq', 'xjVacjmWNUlaUbmzHvQC']}}, 'recusandae': {0: -89.0, 1: [-753077.8, -637.46273670173, 'HSzleFXjcVfkEbTqZRct'], 2: {0: 691, 1: 'SnWyxNVCnlprPReTsYSZ', 2: ['http://wan.com/home.html', 'bMoABxGYLDjOCDtODJQB']}}, 'rerum': {7: 6444, 8: ['https://www.xiang.com/main/categories/terms.php', datetime(1979, 9, 26, 15, 0, 54), 'SWbhlyUYrEwBthwLJONb'], 9: {7: 879.399476, 8: -91270660024375.4, 9: [3687, 'jejvHnOGMMceoaSwVqZq']}}, 'ullam': {9: 'gObmdFSKQZoLyKyZfgtX', 10: [7566, 'huangming@sun.org', 'FMpbuiFHMssUBfLxZLeX'], 11: {9: 'wWWrQNCmcnoOvlnOVdFy', 10: 'sCkiwZjCYrpwvNDKfpVL', 11: ['xiuying11@yahoo.com', 3191]}}}) fake.pyiterable(nb_elements=10, variable_nb_elements=True)#随机iterable {'http://www.xu.cn/privacy.html', 'TOVsPtJcjILECDejxxoU', 872, Decimal('1489.77792874'), 'eCeIwAvOVwrBCJiUwMCu', 'ping17@cheng.com', 'gDrxRLWpVlZvFvOivCqY', 'ZYkLQRYwPKdDkJPfGSJv', 'HnpQtNSgJrlzLrigKdWq', 5849, 'VWcOVUUccZBwsWsoMsNb'} fake.pylist(nb_elements=10, variable_nb_elements=True )#随机生成一个list ['dvrVimRltqhiaBkQeIeg', datetime(2012, 6, 3, 10, 23, 54), 'https://www.tan.com/', 6628, 'SSqNvBwFwYuJHlvBwIdr', 'http://www.zhao.cn/category.html', 9616, 6752, 'http://www.xu.com/posts/search/index/'] fake.pydict(nb_elements=10, variable_nb_elements=True)#随机字典 {'aut': 'jing85@tian.com', 'commodi': 'cAVNTIrUzrepqUBPHxBi', 'error': Decimal('-165608.34516033'), 'impedit': 'wFNIOlIlspfIUnkMqgPN', 'inventore': 1153, 'iusto': 'fGEIdTQgCsjXDZkxzCri', 'maxime': 'TxGcrNBPhxKvbdLhARwj', 'numquam': 684, 'officia': 'dengxiulan@hotmail.com', 'pariatur': 'YMZzSOyxWRZuLFGaXjDK', 'sunt': 'thlWfUrVBZPtgeqRBJup', 'tempora': Decimal('383395040926944.0'), 'vitae': 203143.28604879} fake.pyset(nb_elements=10, variable_nb_elements=True)#随机set {'eQEeODfeVvcbAjPDBGwz', datetime(1978, 9, 24, 2, 26, 7), 'https://www.wan.org/home.php', 'http://song.com/', 'qZufoiUXLQTZDrVcPLHk', 'uBMhSlVZHMgDHFnFKxTh', 'JEssftPjCKHxYHodydTG', 'jQwNKwDIwzQswxiYQlrs', 'http://www.xiong.cn/explore/category.htm', Decimal('-71.399733')} fake.pytuple(nb_elements=10, variable_nb_elements=True)#随机tuple ('KyXucKXQMXAkcEMSLfnI', 7240, 8264, 4494.5490267, 'https://www.wei.org/main/blog/about.html', datetime(1976, 6, 29, 13, 12, 3), 'https://jia.cn/posts/list/wp-content/search.jsp') ssn 社会安全码(身份证) len(fake.ssn()) 18 len(\"320611198812242615\") 18 user_agent 用户代理 常用在伪造浏览器信息 fake.user_agent() 'Opera/9.79.(Windows CE; li-BE) Presto/2.9.181 Version/11.00' 平台信息伪造 fake.linux_platform_token() 'X11; Linux x86_64' fake.linux_processor() 'x86_64' fake.windows_platform_token() 'Windows NT 5.01' fake.mac_platform_token() 'Macintosh; PPC Mac OS X 10_5_4' fake.mac_processor() 'U; PPC' 浏览器伪造 fake.internet_explorer() 'Mozilla/5.0 (compatible; MSIE 7.0; Windows NT 6.2; Trident/3.1)' fake.opera() 'Opera/8.71.(Windows NT 6.0; dv-MV) Presto/2.9.169 Version/10.00' fake.firefox() 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10_6_9; rv:1.9.3.20) Gecko/2013-03-13 06:43:32 Firefox/12.0' fake.safari() 'Mozilla/5.0 (Windows; U; Windows 98) AppleWebKit/532.21.1 (KHTML, like Gecko) Version/5.0 Safari/532.21.1' fake.chrome() 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/5331 (KHTML, like Gecko) Chrome/14.0.830.0 Safari/5331' 自定义扩展 faker对象可以通过add_provider方法将自定义的Provider添加到对象中,自定义的Provider需要继承自BaseProvider from faker.providers import BaseProvider from enum import Enum # create new provider class class MyProvider(BaseProvider): def cn_day_of_week(self): WEEKDAYS = Enum('WEEKDAYS', ['周一','周二','周三','周四','周五','周六','周日']) from random import choice return choice(list(WEEKDAYS)).name # then add new provider to faker instance fake.add_provider(MyProvider) print(fake.cn_day_of_week()) 周五 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 10:00:02 "},"摘要加密与数字签名/":{"url":"摘要加密与数字签名/","title":"摘要加密与数字签名","keywords":"","body":"摘要加密与数字签名 python标准库hashlib和hmac提供了基本的摘要算法.而加密和签名算法则需要第三方工具如PyCrypto,itsdangerous支持. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:11:56 "},"摘要加密与数字签名/摘要算法.html":{"url":"摘要加密与数字签名/摘要算法.html","title":"摘要算法","keywords":"","body":"摘要算法 摘要算法是将信息压缩提取以作为数据指纹的算法,我们下载东西要确认下的东西有没有下错下漏常用这种算法来做验证,在密码学中这是很多算法的基础 具体摘要算法是怎么样的？摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示） 还有一种应用场景是用来存储用户的密码,大家都知道明文密码存储在数据库里很不安全,之前爆出很多知名网站将用户密码以明文存储,导致信息泄露.可以通过摘要算法给密码加个密存储进去.这样要破解密码除了要知道密码本身,还得知道生成最终摘要文本的算法才可以.也就相对安全多了. 有没有可能两个不同的数据通过某个摘要算法得到了相同的摘要？完全有可能，因为任何摘要算法都是把无限多的数据集合映射到一个有限的集合中。这种情况称为碰撞，比如Bob试图根据你的摘要反推出一篇文章'how to learn hashlib in python - by Bob'，并且这篇文章的摘要恰好和你的文章完全一致，这种情况也并非不可能出现，但是非常非常困难。 hashlib Python的hashlib提供了常见的摘要算法，如MD5，SHA1等等。 import hashlib md5 psw=\"haolaoshixihuandadota2\" md5 = hashlib.md5() #初始化摘要对象 md5.update(psw.encode('utf-8')) #使用md5算法计算这段摘要 print(md5.hexdigest())#输出16进制字符串 acc5d43185d33c88def863ac18704561 SHA1 sha1 = hashlib.sha1() sha1.update(psw.encode(\"utf-8\")) print(sha1.hexdigest()) e53754d171a425b1dbb4a215cd86d568050055c5 sha224, sha256, sha384, sha512 一样的操作,只是时间花费不同而已 sha224 = hashlib.sha224() sha224.update(psw.encode(\"utf-8\")) print(sha224.hexdigest()) 660b6249c5213d05e1df371cf7cae75fd9369a467684bc631c44d0f4 长字符串操作 长字符串或者一个分段的字符串要作摘要可以分段的进行update,结果是一样的 x_md5 = hashlib.md5() x_md5.update('how to use md5 in '.encode('utf-8')) x_md5.update('python hashlib?'.encode('utf-8')) print(x_md5.hexdigest()) d26a53750bc40b38b65a520292f69306 hmac 和hashlib中的算法不同,hmac算法需要一个key作为seed才可以得到散列点.这样的好处是黑客除了要知道密码,算法,还得知道这个key才能够攻破密码,我们完全可以为不同时间注册的用户使用不同的key,这样破解的难度就更大了 具体用法如下: import hmac myhmac = hmac.new(b'key') myhmac.update(u\"我得密码\".encode(\"utf-8\")) myhmac.hexdigest() 'd63cd3fbde648491d690927a7e13fc58' 参数 hamc的new方法可以带参数 hmac.new(key[, msg[, digestmod]]) key 秘钥 msg 需要散列的信息 digestmod 摘要算法,默认为md5,可以是任何hashlib中的算法 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:52:08 "},"摘要加密与数字签名/加密算法.html":{"url":"摘要加密与数字签名/加密算法.html","title":"加密算法","keywords":"","body":"加密算法 加密算法基本可以分为两种: 对称加密 非对称加密 非对称加密有很高的安全性,但是和对称加密比起来,它非常的慢,所以我们还是要用对称加密来传送消息. 但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去. PyCrypto是一个python的密码学工具,它提供了多种加密算法,我们可以直接使用.它有以下这些模块: Crypto.Hash 摘要算法 Crypto.Random 随机模块 Crypto.Cipher 对称加密算法 Crypto.PublicKey 非对称加密 下文为最常见的对称加密和非对称加密算法的例子 对称加密(Symmetric Cryptography) 对称加密是最快速、最简单的一种加密方式，加密（encryption）与解密（decryption）用的是同样的密钥（secret key）对称加密有很多种算法，由于它效率很高，所以被广泛使用在很多加密协议的核心当中。 对称加密通常使用的是相对较小的密钥，一般小于256 bit。因为密钥越大，加密越强，但加密与解密的过程越慢。如果你只用1 bit来做这个密钥，那黑客们可以先试着用0来解密，不行的话就再用1解；但如果你的密钥有1 MB大，黑客们可能永远也无法破解，但加密和解密的过程要花费很长的时间。密钥的大小既要照顾到安全性，也要照顾到效率，是一个trade-off。 最常见的对称加密算法就是AES算法了 一般对称加密有如下几种模式 MODE_ECB 电码本模式(Electronic Codebook) 这种模式是将整个明文分成若干段相同的小段，然后对每一小段进行加密 优点: 简单； 有利于并行计算； 误差不会被传送； 缺点: 1. 不能隐藏明文的模式； 2. 可能对明文进行主动攻击； MODE_CBC = 2 密码分组链接模式（Cipher Block Chaining) 这种模式是先将明文切分成若干小段，然后每一小段与初始块或者上一段的密文段进行异或运算后，再与密钥进行加密。 优点： 不容易主动攻击,安全性好于ECB,适合传输长度长的报文,是SSL、IPSec的标准。 　　 缺点： 不利于并行计算； 误差传递； 需要初始化向量IV MODE_CFB = 3 密码反馈模式（Cipher FeedBack) 优点： 1. 隐藏了明文模式; 2. 分组密码转化为流模式; 3. 可以及时加密传送小于分组的数据; 缺点: 1. 不利于并行计算; 2. 误差传送：一个明文单元损坏影响多个单元; 3. 唯一的IV; MODE_OFB = 5 输出反馈模式(Output FeedBack) 优点: 隐藏了明文模式; 分组密码转化为流模式; 可以及时加密传送小于分组的数据; 缺点: 1. 不利于并行计算; 2. 对明文的主动攻击是可能的; 3. 误差传送：一个明文单元损坏影响多个单元; MODE_CTR = 6 计数器模式（Counter) 计算器模式不常见，在CTR模式中， 有一个自增的算子，这个算子用密钥加密之后的输出和明文异或的结果得到密文，相当于一次一密。这种加密方式简单快速，安全可靠，而且可以并行加密，但是 在计算器不能维持很长的情况下，密钥只能使用一次 MODE_OPENPGP = 7 OpenPGP 模式 AES AES算法,即高级加密标准（英语：Advanced Encryption Standard，缩写：AES），在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。经过五年的甄选流程，高级加密标准由美国国家标准与技术研究院（NIST）于2001年11月26日发布于FIPS PUB 197，并在2002年5月26日成为有效的标准。2006年，高级加密标准已然成为对称密钥加密中最流行的算法之一 from Crypto.Cipher import AES from Crypto import Random key = 'This is a key123' iv = Random.new().read(AES.block_size)#iv,AES需要block_size = 16位的随机bytes iv b'H\\t\\x80X\\xbe|\\x7f\\x1e\\xace8~\\x91?\\xc0P' obj = AES.new(key, AES.MODE_CBC, iv) message = \"The answer is no\" ciphertext = obj.encrypt(message) ciphertext b'\\xf3\\x80L\\x1cV9D\\x17L\\xe1Igb\\xda\\x9c\\xee' obj2 = AES.new(key, AES.MODE_CBC, iv) obj2.decrypt(ciphertext) b'The answer is no' DES DES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，1977年被美国联邦政府的国家标准局确定为联邦资料处理标准（FIPS），并授权在非密级政府通信中使用，随后该算法在国际上广泛流传开来。需要注意的是，在某些文献中，作为算法的DES称为数据加密算法（Data Encryption Algorithm,DEA），已与作为标准的DES区分开来 from Crypto.Cipher import DES key = 'abcdefgh' obj=DES.new(key, DES.MODE_ECB) message=\"Guido van Rossum is a space alien.\" len(message) 34 DES的加密数据长度必须是8的整数倍 ciph=obj.encrypt(message+'XXXXXX')# 加密 ciph b'\\x11,\\xe3Nq\\x8cDY\\xdfT\\xe2pA\\xfa\\xad\\xc9s\\x88\\xf3,\\xc0j\\xd8\\xa8\\xca\\xe7\\xe2I\\xd15w\\x1d61\\xc3dgb/\\x06' obj.decrypt(ciph) b'Guido van Rossum is a space alien.XXXXXX' 非对称加密 非对称加密是当今世界用的最多的一种加密形式,它使用一对秘钥而不是一个秘钥来实现加密解密, 这两个秘钥是公开密钥（public key，简称公钥）和私有密钥（private key，简称私钥） 他们的用法如下图 简单说就是发送方用接收方的公钥加密数据,接收方再用自己的私钥解码数据,因此两个人要加密交流必须各自都有公钥私钥,然后相互交换过公钥才行 RSA 常见的非对称加密算法是RSA RSA算法基于一个十分简单的数论事实：将两个大质数相乘十分容易，但是想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥.具体的算法介绍可以看阮一峰的这篇介绍文 生成秘钥 from Crypto.PublicKey import RSA from Crypto import Random random_generator = Random.new().read random_generator > key = RSA.generate(2048,random_generator)# rsa算法生成实例 # 秘钥对的生成 private_pem = key.exportKey() private_pem b'-----BEGIN RSA PRIVATE KEY-----\\nMIIEpQIBAAKCAQEA4CfM+MJLzygGFes8BtnH6Vu8rYRbWbFQQSTq5v4qU9LNi0bG\\nFHxfKjHleA9i+lwZcPRfvQtv89TC4RN8uudZ4UCKEpYwEli6x+7Bu4xYa1x3PHSg\\nv/YL7yoaeXHl5wrXPE9UoTvgiP4JWJ9+4+FuXRUMApkcKhSckgJXM5yyfFB/Gt9K\\nWbsa29zbKWdI5Q3TklVUaid147rUcQen0yfJ1t5LptcHSnndCYBOfGwttDzv5yAs\\nfaa0q0xq5hDqFlxJvXWx68eqhia24wImpqWu9JzGLZxOgmUwtEzN7x7NdWXTPHql\\ny/bVLu8GqFGdB9D5/MKz4Wku6CpEGCM/duH15wIDAQABAoIBAQDWucnEUnvEihaq\\nUJlEBsNWbCamIbBQj2bNwMu1U6zAd6Om07lUTn/rL7kd9b9fDXLhnXdI5Pftn9a/\\nPaeyc4TKHsUlYPHT4WOruq+jNaJN1lnyc9a5jL2J8c9CnzUYym28vFHZ0j4ZfSD+\\n4GrxaTYLvOmwY3NzbCNASzW1n1nrcnV+OeiG0Lb3lZUJ0TiHXAI1ZMn47ov0LEdP\\nbFxeR3Up7LguKveUc6PLH6b4lviy4Qbf96f8ZdiNJSkHjPm0rL0j3ZPWaE/cZzvE\\nawk+nMZQ/DJq1in1oQvzRQQgsGl81Ix3xpu/ni46uUjMur7Vb5Kev39xmUzMNiVz\\nDpsUOp5BAoGBAONtYqlYmoJkpp4Mhv+ZxhZ4zUaaPwCKIVhli+U/Q/MvWKtiIN5U\\nzpzTrXDdcwPyVolF/tbmgcPKZ+M16h3oWuBDHMds0uMnHpWxodrD0TLH3038hiE7\\nxtZ19ETALn6vGHQihtf4jKEyWn2ECrjxD5+hQGF4dT4XKlriDDJ8UO5vAoGBAPxR\\nL4xu8Zi1iJ9npwqsjnCtZOPi05wDGgykdwffP0eicQykiq8rFyWH1lkDHU2JOpMO\\na16s5UaIAenYJ3HkWgnHfKeKJRUfW4sFA+u+I3VyjpP5I0VzEeSGutP2RbgbA0xb\\n2i51gUaHSlKr2u5EI4c4J5dzHI+6RDsN+zMBGawJAoGAP+6E+KP+sz8GE5Hj9UBO\\nDg0hb4J2yXkLDKVnISeau2cI3wyzvqxKdI2QyRSHe4mJSAeULucXfWmNsLJ8QLIL\\nsdVL5sextMdPcrc/j5bSXRsQrASb1AXQzILWCumXaGdiUWtPSrEFH19fTr9qoDir\\nsq0Kwxuwoaazcl7vHNYTjiMCgYEA7m4hiolEUFQrOMcQOKv7JksULayo3qKnuQ6p\\nVI0IFT9RqOrMCt+jTdnhGdgxlpV4/oH/wEWNm2rms/2IuL1awCb8iq2mgSFStjoV\\nDG5uv4tzZC1nwTcNz2/pmGb+Vw1fvoaF1KVBdk5eU2UGy2UkVaEg+KLUeJVB6LQ7\\njmUZx1ECgYEAxJpbacrbNjEHazmMDmNwqBsqF2qvC+jnPD8QbwqefTUENiJeOzwd\\nQPwvAQAI3GD5FlUF2EjjRR/cNoAnU3UBk3csCvIu/XD40cZABdF+hn3EGQyqko3n\\ntZlgjrxAKu6Pq4eClxqaYuTSNk7dvU0rLmbdZx8C8svfLlLZMeyCvME=\\n-----END RSA PRIVATE KEY-----' public_pem = key.publickey().exportKey() public_pem b'-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4CfM+MJLzygGFes8BtnH\\n6Vu8rYRbWbFQQSTq5v4qU9LNi0bGFHxfKjHleA9i+lwZcPRfvQtv89TC4RN8uudZ\\n4UCKEpYwEli6x+7Bu4xYa1x3PHSgv/YL7yoaeXHl5wrXPE9UoTvgiP4JWJ9+4+Fu\\nXRUMApkcKhSckgJXM5yyfFB/Gt9KWbsa29zbKWdI5Q3TklVUaid147rUcQen0yfJ\\n1t5LptcHSnndCYBOfGwttDzv5yAsfaa0q0xq5hDqFlxJvXWx68eqhia24wImpqWu\\n9JzGLZxOgmUwtEzN7x7NdWXTPHqly/bVLu8GqFGdB9D5/MKz4Wku6CpEGCM/duH1\\n5wIDAQAB\\n-----END PUBLIC KEY-----' 加密 from Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5 import base64 message = 'hello , this is a test text' rsakey = RSA.importKey(public_pem) cipher = Cipher_pkcs1_v1_5.new(rsakey)#加密 cipher_text = base64.b64encode(cipher.encrypt(message.encode(\"utf-8\")))#序列化 cipher_text b'BXD6hPYLRHFZPRKS8k+BLM7MdhVJd95H81AAHOlpDtoiNVY0kx9M6+bovp2lJNnCQQW7SdXgUa3jU3tc75x7lhKWw/+ZqdPZLa7u4lD+cvz4gsT3XzTxvjd7mB0KFnoUrsR/x+3/R1X0IuBksZoQfXhtEd4Mtadikj2NSLEFxYxxfS8iZz0Ds4Cq8/nY2bw9a8o70hXJPyiLTlt2e2sIWQpBUq/lgA6zDrtgt92TQFAAWG+iy9DM8Jmj5O5lEiL47XO2rD5h5GWtTG+mkhUfLkmdw01ekf541AZAPEaGjvkkuju56r77vgVELw9pWbfIriu0BaAXXLk7q+2dnGzPpA==' 解密 rsakey = RSA.importKey(private_pem) cipher = Cipher_pkcs1_v1_5.new(rsakey) text = cipher.decrypt(base64.b64decode(cipher_text), random_generator)#解密 text b'hello , this is a test text' 我们将这对钥匙保存起来 with open('source/private.pem', 'wb') as f: f.write(private_pem) with open('source/public_pem', 'wb') as f: f.write(public_pem) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:51:11 "},"摘要加密与数字签名/数字签名.html":{"url":"摘要加密与数字签名/数字签名.html","title":"数字签名","keywords":"","body":"数字签名 关于什么是数字签名,可以看阮一峰的这篇博客 说简单些就是一个为了确保信息完整性和正确性的技术,他的原理就是在要传输的数据上附带一个经过发件人私钥加密的原文摘要数据,这个摘要可以用发件人的公钥解密,之后与接收到数据的摘要核对就可以验证准确性了. 使用PyCryto创建简单签名 from Crypto.PublicKey import RSA from Crypto.Hash import SHA from Crypto.Signature import PKCS1_v1_5 as Signature_pkcs1_v1_5 import base64 创建签名 #使用自己的秘钥对内容进行签名 message = 'hello , this is a test text' with open('source/private.pem') as f: key = f.read() rsakey = RSA.importKey(key) signer = Signature_pkcs1_v1_5.new(rsakey)# 构建签名 digest = SHA.new() digest.update(message) # 使用SHA算法获得摘要 sign = signer.sign(digest) # 使用摘要签名 signature = base64.b64encode(sign) #序列化 signature 'JrnG0TzTCe+K/VhyiFrmfwmiDDQqSkL5ai7PbBsOfTLee+/XIcPLi906WGYb9pRvLtx5EGa6OStuzomC1mqie96nc/81TjhCq61WUJ6Agg6MZplxhai1eKpN/iOW2jCjrRELfIiuoCgT7IYQ5L0va9C6NeHjURFaDYoR/9Rd88xyYaSFGFA3z4eLDntmI5totWRNUszmL9cWfCC7TRgdTZp5O9eDuoylLkkKVABKSzAtDc2+LJ8Hx1cj+zfT40L2e9RDGYKxvMA5A9mTGh7C4w3r1nlR9nzzEOlnUNTmxQNOnRjfs1vtcDsXAMs8s3RmZosz8WL1/1jKF6P/EuAadQ==' 解码签名 #使用公钥解码签名 with open('source/public_pem') as f: key = f.read() rsakey = RSA.importKey(key) verifier = Signature_pkcs1_v1_5.new(rsakey) digest = SHA.new() # Assumes the data is base64 encoded to begin with digest.update(message) is_verify = signer.verify(digest, base64.b64decode(signature))#对比解码后的签名和原文的摘要已确认 print is_verify True 使用itsdangerous建立签名 itsdangerous是一个序列化数据生成签名的工具,它内部使用hmac和sha1来签名,支持jsonweb签名 一个基本的签名 from itsdangerous import Signer s = Signer('secret-key') l=s.sign('my string') l 'my string.wh6tMHxLgJqB6oY1uT73iMlyrOA' 签名会被加在字符串尾部，中间由句号 (.)分隔。验证字符串，使用 unsign() 方法： s.unsign(l) 'my string' 如果被签名的是一个unicode字符串，那么它将隐式地被转换成utf-8。然而，在反签名时，你没法知道它原来是unicode还是字节串。因此一个好习惯是用统一的字符串形式 使用时间戳 如果你想要可以过期的签名，可以使用 TimestampSigner 类，它会加入时间戳信息并签名。在反签名时，你可以验证时间戳有没有过期： from itsdangerous import TimestampSigner s = TimestampSigner('secret-key') string = s.sign('foo') s.unsign(string, max_age=5) 'foo' s.unsign(string, max_age=5) 'foo' 盐 所有的类都接受一个盐的参数。这名字可能会误导你，因为通常你会认为，密码学中的盐会是一个和被签名的字符串储存在一起的东西，用来防止彩虹表查找。这种盐是公开的。 与Django中的原始实现类似，itsdangerous中的盐，是为了一个截然不同的目的而产生的。你可以将它视为成命名空间。就算你泄露了它，也不是很严重的问题，因为没有密钥的话，它对攻击者没什么帮助。 假设你想签名两个链接。你的系统有个激活链接，用来激活一个用户账户，并且你有一个升级链接，可以让一个用户账户升级为付费用户，这两个链接使用email发送。在这两种情况下，如果你签名的都是用户ID，那么该用户可以在激活账户和升级账户时，复用URL的可变部分。现在你可以在你签名的地方加上更多信息（如升级或激活的意图），但是你也可以用不同的盐： from itsdangerous import URLSafeSerializer s1 = URLSafeSerializer('secret-key', salt='activate-salt') s1.dumps(42) 'NDI.kubVFOOugP5PAIfEqLJbXQbfTxs' s2 = URLSafeSerializer('secret-key', salt='upgrade-salt') s2.dumps(42) 'NDI.7lx-N1P-z2veJ7nT1_2bnTkjGTE' s2.loads(s1.dumps(42)) --------------------------------------------------------------------------- BadSignature Traceback (most recent call last) in () ----> 1 s2.loads(s1.dumps(42)) /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/itsdangerous.pyc in loads(self, s, salt) 580 \"\"\" 581 s = want_bytes(s) --> 582 return self.load_payload(self.make_signer(salt).unsign(s)) 583 584 def load(self, f, salt=None): /Users/huangsizhe/LIB/CONDA/anaconda/envs/py2/lib/python2.7/site-packages/itsdangerous.pyc in unsign(self, signed_value) 372 return value 373 raise BadSignature('Signature %r does not match' % sig, --> 374 payload=value) 375 376 def validate(self, signed_value): BadSignature: Signature 'kubVFOOugP5PAIfEqLJbXQbfTxs' does not match 最常用的生成会过期的用户信息token(序列化) from itsdangerous import TimedJSONWebSignatureSerializer as Serializer s = Serializer('SECRET_KEY', 30) token = s.dumps({'confirm': \"hsz\"}) token 'eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ5ODgzMDU5NiwiaWF0IjoxNDk4ODMwNTY2fQ.eyJjb25maXJtIjoiaHN6In0.4Rrx-XF5XH2fEWitw9eQjEeffcKhNWcSE8s81FYtw1g' data = s.loads(token) data {u'confirm': u'hsz'} data = s.loads(token) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:51:19 "},"数据压缩/":{"url":"数据压缩/","title":"数据压缩","keywords":"","body":"数据压缩 python标准库可以提供简单的压缩解压功能.主要是使用zlib,zipfile和tarfile. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:38:16 "},"数据压缩/数据压缩解压.html":{"url":"数据压缩/数据压缩解压.html","title":"数据压缩解压","keywords":"","body":"数据压缩解压 压缩和解压说白了就是时间换空间,运算换存储的一种解决方案,标准库中的zlib和bz2模块都是数据压缩解压工具,他们的主要应用场景是数据传输. 注意压缩只能是bytes类型 zlib import zlib exa_str=u\"\"\"\\ 网易体育1月5日报道： 国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，\\ 巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友\\ “小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，\\ 排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。 \"\"\" 压缩compress(data[, level]) level是压缩等级(范围0~9),默认是6,1是最快单压缩最少的,9是最慢但压缩最多得,0表示不压缩 z_str=zlib.compress(exa_str.encode()) len(z_str)/len(exa_str.encode()) 0.7527910685805422 可以看到默认level时压缩率在75%的样子 解压 zlib.decompress(z_str).decode(\"utf-8\") '网易体育1月5日报道：\\n\\n国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。\\n' 自定义压缩和解压器 压缩器compressobj([level[, method[, wbits[, memLevel[, strategy]]]]]) level 压缩等级,范围1~9,默认6 method 压缩方法,目前只支持默认方法 wbits 确定窗口缓冲区的大小,范围是8~15,越高效果越好,但占用内存越多 memLevel 内部压缩状态存储等级,范围1~9,数值越大消耗内存越多,但更快压缩率更高 strategy 压缩算法相关,可选值有Z_DEFAULT_STRATEGY, Z_FILTERED,Z_HUFFMAN_ONLY 解压器decompressobj(wbits=15) bz2 bz2和zlib接口差不多,只是使用的不同的算法 import bz2 压缩compress(data[, level]) level是压缩等级(范围1~9),默认是9,1是最快单压缩最少的,9是最慢但压缩最多得 b_str = bz2.compress(exa_str.encode()) len(b_str)/len(exa_str.encode()) 0.8309409888357256 解压decompress(data) bz2.decompress(b_str).decode(\"utf-8\") '网易体育1月5日报道：\\n\\n国际足球历史和统计联合会（IFFHS）今日凌晨在其官网上公布了2015年度世界最佳组织者的评选结果，巴塞罗那前锋梅西问鼎，这也是阿根廷人职业生涯首次当选年度最佳组织核心的荣誉。另外，梅西在巴萨的队友“小白”伊涅斯塔排在第二位，意大利球星皮尔洛力压切尔西王牌阿扎尔占据第三名的位置。值得一提的是，排名前十的球员中有3个来自于皇马。此外，还一同公布了最佳教练的评选，巴萨主帅恩里克力压瓜迪奥拉、阿莱格里等名帅当选。\\n' Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:32:10 "},"数据压缩/压缩归档.html":{"url":"数据压缩/压缩归档.html","title":"压缩归档","keywords":"","body":"压缩归档 如果是用于归档文件,那我们最好的选择就是使用压缩工具,python的标准库自带zipfile和tarfile用来压缩归档文件,还有gzip用来为单一文件进行压缩,另外github上还有一个归档为rar的工具rarfile zipfile zip文件格式由三个部分组成：压缩源文件数据区+压缩源文件目录区+压缩源文件目录结束标志 压缩源文件数据区 在这个数据区中每一个压缩的源文件/目录都是一条记录，记录的格式如下： [文件头+ 文件数据 + 数据描述符] 文件头结构 组成 长度 文件头标记 4 bytes (0x04034b50) 解压文件所需 pkware 版本 2 bytes 全局方式位标记 2 bytes 压缩方式 2 bytes 最后修改文件时间 2 bytes 最后修改文件日期 2 bytes CRC-32校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 文件名长度 2 bytes 扩展记录长度 2 bytes 文件名 （不定长度） 扩展字段 （不定长度） 文件数据 数据描述符 组成 长度 CRC-32校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 这个数据描述符只在全局方式位标记的第３位设为１时才存在，紧接在压缩数据的最后一个字节后。这个数据描述符只用在不能对输出的 ZIP 文件进行检索时使用。例如：在一个不能检索的驱动器（如：磁带机上）上的 ZIP 文件中。如果是磁盘上的ZIP文件一般没有这个数据描述符。 压缩源文件目录区 在这个数据区中每一条纪录对应在压缩源文件数据区中的一条数据 组成 长度 目录中文件文件头标记 4 bytes (0x02014b50) 压缩使用的pkware 版本 2 bytes 解压文件所需 pkware 版本 2 bytes 全局方式位标记 2 bytes 压缩方式 2 bytes 最后修改文件时间 2 bytes 最后修改文件日期 2 bytes ＣＲＣ－３２校验 4 bytes 压缩后尺寸 4 bytes 未压缩尺寸 4 bytes 文件名长度 2 bytes 扩展字段长度 2 bytes 文件注释长度 2 bytes 磁盘开始号 2 bytes 内部文件属性 2 bytes 外部文件属性 4 bytes 局部头部偏移量 4 bytes 文件名 （不定长度） 扩展字段 （不定长度） 文件注释 （不定长度） 压缩源文件目录结束标志 组成 长度 目录结束标记 4 bytes (0x02014b50) 当前磁盘编号 2 bytes 目录区开始磁盘编号 2 bytes 本磁盘上纪录总数 2 bytes 目录区中纪录总数 2 bytes 目录区尺寸大小 4 bytes 目录区对第一张磁盘的偏移量 4 bytes ZIP 文件注释长度 2 bytes ZIP 文件注释 （不定长度） import zipfile 创建归档 创建一个文件的zip归档 with zipfile.ZipFile('source/output/笑傲江湖.zip', 'w',zipfile.ZIP_DEFLATED) as f: f.write(\"source/input/笑傲江湖.txt\") 创建字符串的归档 with open(\"source/input/iris.csv\",\"r\") as f: content = f.read() with zipfile.ZipFile('source/output/iris_str.zip', 'w',zipfile.ZIP_DEFLATED) as f: f.writestr( 'iris_str.csv',content) 创建一个多文件归档 在归档大量文件时,我们可以用allowZip64=True来指定支持超过2Gb的归档 with zipfile.ZipFile('source/output/all_input.zip', 'w',zipfile.ZIP_DEFLATED,allowZip64=True) as f: f.write(\"source/input/笑傲江湖.txt\") f.write(\"source/input/iris.csv\") f.write(\"source/input/people.json\") 查看压缩文件信息 #查看是不是zip压缩文件 zipfile.is_zipfile(\"source/output/all_input.zip\") True # 查看zip中的文件列表 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.namelist()) ['source/input/笑傲江湖.txt', 'source/input/iris.csv', 'source/input/people.json'] # 打开zip中某个文件 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.open('source/input/people.json').read().decode(\"utf-8\")) [{\"name\":\"Michael\"},{\"name\":\"Andy\", \"age\":30},{\"name\":\"Justin\", \"age\":19}] # 查看zip文件的信息列表 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.infolist()) [, , ] # 查看压缩信息 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.printdir()) File Name Modified Size source/input/笑傲江湖.txt 2016-12-23 23:17:44 2989594 source/input/iris.csv 2016-12-23 23:17:44 4606 source/input/people.json 2016-12-23 23:17:44 75 None # 查看zip中某文件的信息 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: info = f.getinfo('source/input/people.json') print(info) # 查看创建时间 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: info = f.getinfo('source/input/people.json') print(info.date_time) (2016, 12, 23, 23, 17, 44) # 检查zip中每个文件的CRC,有错误会返回对应文件作为列表成员 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: print(f.testzip()) None 解压文件 全部解压 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.extractall(\"source/extract\") 单独解压一个 with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.extract(\"source/input/iris.csv\",\"source/exone\") 密码处理 zipfile只能解压带密码的zip包,并不支持创建加密的zip归档,要使用密码只要像这个样: with zipfile.ZipFile('source/output/all_input.zip', 'r',zipfile.ZIP_DEFLATED) as f: f.setpassword() f.extract(\"source/input/iris.csv\",\"source/exone\") 即可 tarfile tar是linux下是常见的归档格式,常见的后缀有tar,tar.bz,tar.gz三种后缀,分别对应三种不同的压缩算法, tarfile的归档用法也与zipfile类似,只是接口有些变化 import tarfile with tarfile.TarFile('source/output/all_input.tar', 'w') as f: f.add(\"source/input/笑傲江湖.txt\") f.add(\"source/input/iris.csv\") f.add(\"source/input/people.json\") #查看是不是zip压缩文件 tarfile.is_tarfile(\"source/output/all_input.tar\") True #查看压缩信息 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.list()) ?rwxr-xr-x huangsizhe/staff 2989594 2016-12-23 23:17:44 source/input/笑傲江湖.txt ?rwxr-xr-x huangsizhe/staff 4606 2016-12-23 23:17:44 source/input/iris.csv ?rwxr-xr-x huangsizhe/staff 75 2016-12-23 23:17:44 source/input/people.json None # 查看zip中的文件列表 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getnames()) ['source/input/笑傲江湖.txt', 'source/input/iris.csv', 'source/input/people.json'] # 查看zip文件的信息列表 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getmembers()) [, , ] # 查看zip中某文件的信息,比如修改时间戳 with tarfile.TarFile('source/output/all_input.tar', 'r') as f: print(f.getmember(\"source/input/iris.csv\").mtime) 1482506264 如果要结合gz或者bz压缩,那么就不能使用这个类,而要使用tarfile.open(name=None, mode='r', fileobj=None, bufsize=10240, **kwargs)函数 其中mode=可选的有: mode 说明 'r' or 'r:*' 使用透明压缩读打开 'r:' 无压缩读打开 'r:gz' gzip压缩读打开 'r:bz2' bzip2压缩读打开 'a' or 'a:' 无需压缩append写打开。如果文件不存在，则创建该文件。 'w' or 'w:' 无压缩写 'w:gz' gzip写打开 'w:bz2' bzip2写打开 创建压缩归档 import os with tarfile.open(\"source/output/all_input.tar.gz\",\"w:gz\") as tar: for root,dir,files in os.walk(\"source/input\"): for file in files: fullpath = os.path.join(root,file) tar.add(fullpath) 解压压缩归档 with tarfile.open(\"source/output/all_input.tar.gz\",\"r:gz\") as tar: names = tar.getnames() for name in names: tar.extract(name,path=\"source/ex_tar\") rarfile python标准库并不支持rar格式的归档,但有个rarfile可以通过pip安装,他的接口与zipfile一样,只是不能写只能读 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 21:32:18 "},"国际化工具/":{"url":"国际化工具/","title":"国际化工具","keywords":"","body":"国际化工具 国际化(internationalization)是设计和制造容易适应不同区域要求的产品的一种方式. 它要求从产品中抽离所有地域语言,国家/地区和文化相关的元素.换言之,应用程序的功能和代码设计考虑在 不同地区运行的需要,其代码简化了不同本地版本的生产.开发这样的程序的过程,就称为国际化. python标准库提供了针对文本翻译和时间的工具gettext,time,datetime和calendar 针对货币国际化的工具则可以使用money模块 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:23:10 "},"国际化工具/时间日期处理.html":{"url":"国际化工具/时间日期处理.html","title":"时间日期处理","keywords":"","body":"时间日期处理 python和时间有关的标准库模块常用的主要有3个 基本时间模块time 日历模块calendar 时间日历模块datetime 基本时间模块time time 模块中一般有三种表示时间的方式: 第一种是时间戳(timestamp)的方式(相对于1970.1.1 00:00:00以秒计算的偏移量),时间戳是惟一的,也是各种语言通用的.有的语言如java,js时间以ms记,所以处理的时候注意下,适当的时候/1000 第二种以数组的形式表示即(struct_time,结构化时间),共有九个元素，分别表示，同一个时间戳的struct_time会因为时区不同而不同 元素属性 范围及说明 year (four digits, e.g. 1998) month (1-12) day (1-31) hours (0-23) minutes (0-59) seconds (0-59) weekday (0-6, Monday is 0) Julian day (一年中的第几天, 1-366) DST (-1, 0 or 1) 是否是夏令时,0说明是不是,1说明是,-1说明不确定 第三种是字符串表述,也就我们可以直接看懂的形式 可以用如下的符号格式化字符串输出: 符号 意思及取值范围 %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %I 12小时制小时数（01-12） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %p 本地A.M.或P.M.的等价符 %U 一年中的星期数（00-53）星期天为星期的开始 %w 星期（0-6），星期天为星期的开始 %W 一年中的星期数（00-53）星期一为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 %Z 当前时区的名称 %% %号本身 import time 时间获取 获取当前时间戳 time() now_timestamp = time.time() now_timestamp 1498831412.6540039 获取当前结构化时间 localtime() now_struct = time.localtime() now_struct time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=22, tm_min=3, tm_sec=33, tm_wday=4, tm_yday=181, tm_isdst=0) 直接获取当前时间字符串 asctime() time.asctime() 'Fri Jun 30 22:03:33 2017' 时间表现形式转化 时间戳=>结构化时间 localtime() gmtime() # 当前时区 time.localtime(now_timestamp) time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=22, tm_min=3, tm_sec=32, tm_wday=4, tm_yday=181, tm_isdst=0) # UTC时区(0时区) time.gmtime(now_timestamp) time.struct_time(tm_year=2017, tm_mon=6, tm_mday=30, tm_hour=14, tm_min=3, tm_sec=32, tm_wday=4, tm_yday=181, tm_isdst=0) 结构化时间=>时间戳 mktime() time.mktime(now_struct) 1498831413.0 结构化时间=>字符串 asctime() strftime() time.asctime(now_struct) 'Fri Jun 30 22:03:33 2017' time.strftime(\"%Y-%m-%d %H:%M:%S\", now_struct) '2017-06-30 22:03:33' 时间戳=>字符串 ctime() time.ctime(now_timestamp) 'Fri Jun 30 22:03:32 2017' 将格式化字符串转化为时间戳 a = \"Sat Sep 24 22:22:22 2015\" b = time.mktime(time.strptime(a,\"%a %b %d %H:%M:%S %Y\")) b 1443104542.0 将格式化字符串转化为结构化时间 c = time.strptime(a,\"%a %b %d %H:%M:%S %Y\") c time.struct_time(tm_year=2015, tm_mon=9, tm_mday=24, tm_hour=22, tm_min=22, tm_sec=22, tm_wday=5, tm_yday=267, tm_isdst=-1) 特殊函数 线程推迟指点时间 sleep(sec) time.sleep(1) 基本的日历模块calendar calendar模块，即日历模块，提供了对日期的一些操作方法，和生成日历的方法。 主要提供的常量(用list查看): 常量 说明 calendar.day_name 一周的星期几名字 calendar.day_abbr 一周的星期几名字的简写 calendar.month_name 月份名字 calendar.month_abbr 月份名字的简写 主要的方法有: 方法 说明 calendar.setfirstweekday(weekday) 设置日历中星期的的第一天是周几 calendar.firstweekday() 查看日历中一星期的第一天是周几(在列表中的位置) calendar.isleap(year) 判断是否是闰年 calendar.leapdays(y1, y2) 获取两个年份之间闰年数 calendar.weekday(year, month, day) 查看某一天是星期几(在列表中的位置) calendar.weekheader(n) 返回星期几的英文缩写,n表示用几位字母 calendar.monthrange(year, month) 返回第一天是周几(列表中位置和月的长度) calendar.monthcalendar(year, month) 返回一个表示日历的二维数组 calendar.prmonth(theyear, themonth, w=0, l=0) 直接打印日历 calendar.month(theyear, themonth, w=0, l=0) 返回某月的日历文本 calendar.prcal(year, w=0, l=0, c=6, m=3) 打印一年的日历 calendar.calendar(year, w=2, l=1, c=6, m=3) 返回一年日历的字符串 calendar.timegm(tuple) 把一个 UTC 的 struct_time 转化为 POSIX 时间戳 其中有三个主要的类型可以实例化: calendar.Calendar(firstweekday=0) 该类提供了许多生成器，如星期的生成器，某月日历生成器. 主要有: iterweekdays() 返回一周几天的生成器 itermonthdates(year, month) 返回某月的每一天的datetime构成的生成器 itermonthdays2(year, month) 返回某月的每一天的(日期,星期)构成的生成器 itermonthdays(year, month) 返回某月的每一天的日期构成的生成器 monthdatescalendar(year, month) 返回某月的每一天的datetime构成的list(每周是一个list) monthdays2calendar(year, month) 返回某月的每一天的(日期,星期)构成的list(每周是一个list) monthdayscalendar(year, month) 返回某月的每一天的日期构成的list(每周是一个list) yeardatescalendar(year, width=3) 返回某年的每一天的datetime构成的list(每月一个list,每周是一个list) yeardays2calendar(year, width=3) 返回某年的每一天的(日期,星期)构成的list(每月一个list,每周是一个list) yeardayscalendar(year, width=3) 返回某年的每一天的日期构成的list(每月一个list,每周是一个list) calendar.TextCalendar(firstweekday=0) 该类提供了按月、按年生成日历字符串的方法。 主要有: 方法 说明 formatmonth(theyear, themonth, w=0, l=0) 返回某月的日历字符串 prmonth(theyear, themonth, w=0, l=0) 打印某月的日历字符串 formatyear(theyear, w=2, l=1, c=6, m=3) 返回某年的日历字符串 pryear(theyear, w=2, l=1, c=6, m=3) 打印某年的日历字符串 子类有: calendar.LocaleTextCalendar(firstweekday=0, locale=None) 用来生成本地日历,主要就是月份和星期的本地语言化,locale默认是计算机的locale calendar.HTMLCalendar(firstweekday=0) 类似TextCalendar，不过生成的是HTML格式日历 主要有: formatmonth(theyear, themonth, withyear=True) 返回某月的日历的html字符串 formatyear(theyear, width=3) 返回某年的日历的html字符串 formatyearpage(theyear, width=3, css='calendar.css', encoding=None) 返回完整的页面代码的字符串 子类有: calendar.LocaleHTMLCalendar(firstweekday=0, locale=None) 用来生成本地日历,主要就是月份和星期的本地语言化,locale默认是计算机的locale import calendar cal = calendar.HTMLCalendar(calendar.MONDAY) with open('calendar.html',\"wb\") as f: f.write(cal.formatyearpage(2016)) 最常用的时间日历模块 datetime datetime同样是python标准库,不过它看起来就很OO很现代了~它用一个叫datetime的类型来表示时间,一般来说,做时间的计算会用它而不是time模块 from datetime import datetime 获取datetime 时间 获取当前日期和时间 datetime.now() now = datetime.now() now datetime.datetime(2017, 6, 30, 22, 3, 39, 535750) now.__str__() '2017-06-30 22:03:39.535750' 获取某一时间datetime() yesterday = datetime(2015,9,23,17,2,4,220475) yesterday datetime.datetime(2015, 9, 23, 17, 2, 4, 220475) datetime => 时间戳 .timestamp() now.timestamp() 1498831419.53575 时间戳 => datetime 本地时间 before_now = datetime.fromtimestamp(now_timestamp) before_now.__str__() '2017-06-30 22:03:32.654004' UTC标准时间 before_now_UTC = datetime.utcfromtimestamp(now_timestamp) before_now_UTC.__str__() '2017-06-30 14:03:32.654004' 格式化字符串 => datetime cday = datetime.strptime('2015-6-1 18:19:59', '%Y-%m-%d %H:%M:%S') cday datetime.datetime(2015, 6, 1, 18, 19, 59) datetime => 格式化字符串 now.strftime('%a, %b %d %H:%M') 'Fri, Jun 30 22:03' 时间计算 from datetime import datetime, timedelta now = datetime.now() print(now) print(now + timedelta(hours=10)) print(now - timedelta(days=1)) print(now + timedelta(days=2, hours=12)) 2017-06-30 22:03:46.561364 2017-07-01 08:03:46.561364 2017-06-29 22:03:46.561364 2017-07-03 10:03:46.561364 tenten = datetime(2015, 10, 1, 0, 0, 0, 0) (tenten - now).__str__() '-639 days, 1:56:13.438636' from datetime import datetime, timedelta now = datetime.now() now datetime.datetime(2017, 6, 30, 22, 3, 47, 327346) now + timedelta(seconds=10) datetime.datetime(2017, 6, 30, 22, 3, 57, 327346) nowonow = datetime.now() nowonow datetime.datetime(2017, 6, 30, 22, 3, 47, 917878) nowonow False 支持链式表达式和时区转换的时间处理模块 moment是一个开源,接口仿照js库moment的时间处理模块,支持链式表达式 他的好处是用链式表达式可以写起来很顺畅 可以使用pip安装,以下是官方的例子,要用的话可以对着例子找接口 import moment from datetime import datetime # Create a moment from a string moment.date(\"12-18-2012\", \"M-D-YYYY\") # Create a moment with strftime format moment.date(\"12-18-2012\", \"%m-%d-%Y\") # By default, the \"%Y-%m-%d\" strftime format is used moment.date(\"2012-12-18\") # Create a moment from the current datetime moment.now() # The moment can also be UTC-based moment.utcnow() # Create a moment with the UTC time zone moment.utc(\"2012-12-18\", \"YYYY-M-D\") # Create a moment from a Unix timestamp moment.unix(13558751536) # Create a moment from a Unix UTC timestamp moment.unix(13558751536, utc=True) # Return a datetime instance moment.date(2012, 12, 18).date # We can do the same thing with the UTC method moment.utc(2012, 12, 18).date # Create and format a moment using Moment.js semantics moment.now().format(\"YYYY-M-D\") # Create and format a moment with strftime semantics moment.date(2012, 12, 18).strftime(\"%Y-%m-%d\") # Update your moment's time zone moment.date(datetime(2012, 12, 18)).locale(\"US/Central\").date # Alter the moment's UTC time zone to a different time zone moment.utcnow().timezone(\"US/Eastern\").date # Set and update your moment's time zone. For instance, I'm on the # west coast, but want NYC's current time. moment.now().locale(\"US/Pacific\").timezone(\"US/Eastern\") # In order to manipulate time zones, a locale must always be set or # you must be using UTC. moment.utcnow().timezone(\"US/Eastern\").date # You can also clone a moment, so the original stays unaltered now = moment.utcnow().timezone(\"US/Pacific\") future = now.clone().add(weeks=2) # Customize your moment by chaining commands moment.date(2012, 12, 18).add(days=2).subtract(weeks=3).date # Imagine trying to do this with datetime, right? moment.utcnow().add(years=3, months=2).format(\"YYYY-M-D h:m A\") # You can use multiple keyword arguments moment.date(2012, 12, 19).add(hours=1, minutes=2, seconds=3) # And, a similar subtract example... moment.date(2012, 12, 19, 1, 2, 3).subtract(hours=1, minutes=2, seconds=3) # In addition to adding/subtracting, we can also replace values moment.now().replace(hours=5, minutes=15, seconds=0).epoch() # And, if you'd prefer to keep the microseconds on your epoch value moment.now().replace(hours=5, minutes=15, seconds=0).epoch(rounding=False) # Years, months, and days can also be set moment.now().replace(years=1984, months=1, days=1, hours=0, minutes=0, seconds=0) # Also, datetime properties are available moment.utc(2012, 12, 19).year == 2012 # Including plural ones (since I'm bad at remembering) moment.now().seconds # We can also manipulate to preferred weekdays, such as Monday moment.date(2012, 12, 19).replace(weekday=1).strftime(\"%Y-%m-%d\") # Or, this upcoming Sunday moment.date(\"2012-12-19\").replace(weekday=7).date # We can even go back to two Sundays ago moment.date(2012, 12, 19).replace(weekday=-7).format(\"YYYY-MM-DD\") # It's also available as a property moment.utcnow().weekday # And, there's an easy way to zero out the hours, minutes, and seconds moment.utcnow().zero Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:14:45 "},"国际化工具/货币处理模块.html":{"url":"国际化工具/货币处理模块.html","title":"货币处理模块","keywords":"","body":"货币处理模块 各国所用货币不同,实时汇率也不同,因此货币处理在国际化上是一个比较麻烦的事儿. python模块money提供了一个相对好的解决方案,可以通过pip安装它,如果想要本地化的显示功能,比如打印出￥ xxx这种,那还需要安装babel作为依赖 单一货币结算 money提供了一个类Money来作为定义货币种类的基类,它很适合用作单货币间的运算工具,它支持的运算有 和同一货币 支持+,-,/ 和比较操作 和常数 支持使用* from money import Money m = Money(amount='2.22', currency='EUR') m EUR 2.22 m.amount Decimal('2.22') m.currency 'EUR' print(m.format('en_US')) €2.22 币种间换算 对不同货币间的运算,我们需要确定比例,这需要使用其中的xrates类 xrates类需要先install一个抽象类来作为后端,常用的是money.exchange.SimpleBackend 之后需要确定以哪种货币作为基准,一般都是以美元为基准 然后就是已定义各种货币对美元的比例了 from decimal import Decimal from money import xrates xrates.install('money.exchange.SimpleBackend') xrates.base = 'USD' #注意是1美元兑换目标货币的值 xrates.setrate('EUR', Decimal('0.9279')) xrates.setrate('CNY', Decimal('6.8785')) a = Money(1, 'EUR') b = Money(1, 'CNY') a.to('CNY') CNY 7.412975536156913460502209290 更灵活的换算 在前面已经定义好了换算比例的情况下,可以使用XMoney类来直接计算不同货币种类 from money import XMoney xrates.install('money.exchange.SimpleBackend') xrates.base = 'USD' #注意是1美元兑换目标货币的值 xrates.setrate('EUR', Decimal('0.9279')) xrates.setrate('CNY', Decimal('6.8785')) a = XMoney(1, 'EUR') b = XMoney(1, 'CNY') a+b EUR 1.134898597077851275714181871 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:14:57 "},"国际化工具/字符编码判断.html":{"url":"国际化工具/字符编码判断.html","title":"字符编码判断","keywords":"","body":"字符编码判断 计算机字符编码最初最原始的编码就是广为人知ascii编码了,不过它只能表示数字和英文字母和一些标点符号,数量非常有限,后来各个国家各种语言设定了各自的编码方式来对应自己的语言文字,而现在广泛使用utf-8或者utf-16来统一编码所有字符.因为种种历史原因,文本的编码格式非常混乱,这种时候就可以使用chardet工具来判别使用的是何种字符编码,这个工具我们已经在前文提及 chardet可以使用pip安装.安装后可以使用命令行工具 chardetect 来辨别文件的字符编码类型. 作为模块使用 import requests rawdata = requests.get('http://www.baike.com/wiki/%E6%9C%9F%E6%9C%9B').content import chardet chardet.detect(rawdata) {'confidence': 0.99, 'encoding': 'utf-8'} 结果的encoding表示判断是哪种编码,confidence表示确信度 复杂情况的辨别 如果处理大量文本，您可以逐步调用检测器，当有足够的信心报告其结果，它就会停止。 import requests from chardet.universaldetector import UniversalDetector usock = requests.get('http://yahoo.co.jp/') detector = UniversalDetector() for line in usock.iter_lines(): detector.feed(line) if detector.done: break detector.close() usock.close() print(detector.result) {'encoding': 'utf-8', 'confidence': 0.99} 如此一来我们就不需要把整个文本用于辨别,这就减少了时间 如果要检测多个文本（例如单独文件）的编码，可以重复使用单个UniversalDetector对象。 只需在每个文件的开头调用detect.reset(),调用detect.feed多次，然后调用detect.close()并检查检测器.result字典为文件的结果。 import glob from chardet.universaldetector import UniversalDetector detector = UniversalDetector() for filename in glob.glob('src/*.py'): print(filename.ljust(60),end=\"\") detector.reset() for line in open(filename, 'rb'): detector.feed(line) if detector.done: break detector.close() print(detector.result) src/gettext_te.py {'encoding': 'ascii', 'confidence': 1.0} src/international.py {'encoding': 'ascii', 'confidence': 1.0} src/pygettext.py {'encoding': 'ISO-8859-2', 'confidence': 0.8550385660653095} src/srcgettext_te.py {'encoding': 'ascii', 'confidence': 1.0} src/transfer.py {'encoding': 'ascii', 'confidence': 1.0} Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:14:34 "},"国际化工具/国际化文本翻译.html":{"url":"国际化工具/国际化文本翻译.html","title":"国际化文本翻译","keywords":"","body":"国际化文本翻译 我们写app希望可以适应本地化需求,也就是当换一种语言的时候可以自动转成翻译好的对应文本.我们当然可以每个语言些一个版本,代码相同只是修改其中的文本. 一个简单的解决方案是使用一个函数包裹字符串,让函数负责找到对应翻译.比如 spanishStrings = {'Hello world!': 'Hola Mundo!'} frenchStrings = {'Hello world!': 'Bonjour le monde!'} germanStrings = {'Hello world!': 'Hallo Welt!'} def trans(s): if LANGUAGE == 'English': return s if LANGUAGE == 'Spanish': return spanishStrings.get(s) if LANGUAGE == 'French': return frenchStrings.get(s) if LANGUAGE == 'German': return germanStrings.get(s) LANGUAGE = 'French' print(trans(\"Hello world!\")) Bonjour le monde! 但是很明显,一旦文本量变大了就会无法管理了~ Python提供了gettext模块用于解决这类问题 gettext的使用 创建国际化文档的文件夹目录 ----| |-src-| |-locale-| |-en-| | |-LC_MESSAGES | |-cn-| | |-LC_MESSAGES | |-fr-| |-LC_MESSAGES gettext初始化 使用脚本工具pygettext初始化gettext设置(如果安装的python中没有的话可以来这里下载) !src/pygettext.py -p src/ File \"src/pygettext.py\", line 516 except getopt.error, msg: ^ SyntaxError: invalid syntax !cat src/messages.pot # SOME DESCRIPTIVE TITLE. # Copyright (C) YEAR ORGANIZATION # FIRST AUTHOR , YEAR. # msgid \"\" msgstr \"\" \"Project-Id-Version: PACKAGE VERSION\\n\" \"POT-Creation-Date: 2016-12-08 20:34+CST\\n\" \"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\\n\" \"Last-Translator: FULL NAME \\n\" \"Language-Team: LANGUAGE \\n\" \"MIME-Version: 1.0\\n\" \"Content-Type: text/plain; charset=CHARSET\\n\" \"Content-Transfer-Encoding: ENCODING\\n\" \"Generated-By: pygettext.py 1.5\\n\" 我们修改它的 \"Content-Type: text/plain; charset=CHARSET\\n\" \"Content-Transfer-Encoding: ENCODING\\n\" 两个字段,并为其添加要翻译的内容 %%writefile src/transfor.pot # SOME DESCRIPTIVE TITLE. # Copyright (C) YEAR ORGANIZATION # FIRST AUTHOR , YEAR. # msgid \"\" msgstr \"\" \"Project-Id-Version: PACKAGE VERSION\\n\" \"POT-Creation-Date: 2016-12-08 20:34+CST\\n\" \"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\\n\" \"Last-Translator: FULL NAME \\n\" \"Language-Team: LANGUAGE \\n\" \"MIME-Version: 1.0\\n\" \"Content-Type: text/plain; charset=gb2312\\n\" \"Content-Transfer-Encoding: utf-8\\n\" \"Generated-By: pygettext.py 1.5\\n\" msgid \"hello\" msgstr \"\" msgid \"Python now\" msgstr \"\" Overwriting src/transfor.pot 接着我们就可以使用poedit来逐条翻译了这边有一个基本教程操作 我们用poedit为写一份中文的翻译,放在locale/cn/LC_MESSAGES中,其中包含两份文件,zh_CN.po和zh_CN.mo,同样的也弄一份英文的 !cat src/locale/cn/zh_CN.po cat: src/locale/cn/zh_CN.po: No such file or directory 注册国际化文本 %%writefile src/transfer.py #!/usr/bin/env python # -*- coding: utf-8 -*- import gettext langen = gettext.translation('en', './src/locale', languages=['en']) langcn = gettext.translation('zh_CN', './src/locale', languages=['cn']) Overwriting src/transfer.py 其中: gettext_te.py是要翻译模块或app名 ./locale是存放翻译文件的路径, languages参数指定要使用的语言存放的子目录,这里cn表示使用./locale/cn/LC_MESSAGES/路径下的翻译文件. 这样我们就有了一个_()方法来翻译文本 编辑主模块 %%writefile src/gettext_te.py #!/usr/bin/env python # -*- coding: utf-8 -*- from __future__ import print_function from transfer import * langcn.install() print(_(\"Hello world!\")) langen.install() print(_(\"Hello world!\")) Overwriting src/gettext_te.py %run src/gettext_te.py Hello world! Hello world! 这样每次只要修改对应文件夹的mo文件就可以实现本地化翻译了 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-30 22:14:23 "},"人机交互/":{"url":"人机交互/","title":"人机交互","keywords":"","body":"人机交互 人机交互历史发展概览 自人类发明计算机以来,人机交互就是一个课题,在”远古时期”,人机交互靠打孔纸片,因此只有专业人员才能利用计算机做各种各样的事儿. 再后来有了通用计算机,有了unix,大家通过terminal在shell里用命令行工具与计算机交互.再到后来mac,windows的出现以及鼠标的诞生带来了交互的革命, 人们可以通过点击屏幕上的对应位置来与计算机交互了,这就是gui,再到后来互联网革命,机器交互成了人与人交互的一个媒介,在交互设计思路上产生了很大的变革, 而现如今的移动端交互革命又带来了新的挑战,小屏幕以及各种传感器的引入大大增加了交互的可用维度,降低了交互成本,现在前沿的VR,AR,MR技术也同样无疑的会带来更低的交互成本和更好的交互体验. 但更加明显的是,人机交互的革命既是一个交互成本降低的过程,又是一个程序复杂度和计算机硬件要求指数级增加的过程. 越是人易于使用的交互方式越是需要复杂的程序结构和高性能的硬件支撑.而设计和美学也在人机交互中占有越来越大的比例. 以至于不懂计算机的小白往往把人机交互作为设计,美工的研究课题.学计算机科学的同学们表示相当无奈. 可以看到人机交互的发展历史就是一个机器迁就用户,程序员迁就机器的发展过程. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 21:49:49 "},"人机交互/使用python编写命令行工具.html":{"url":"人机交互/使用python编写命令行工具.html","title":"使用python编写命令行工具","keywords":"","body":"命令行工具 计算机最基础的应用就是命令行工具了,众所周知的linux便是因为拥有shell和一众方便好用的命令行工具而备受程序员和geek喜欢. 这种交互方式优缺点都很显而易见,因此喜欢的人非常喜欢,不喜欢的人非常不喜欢. 优点 功能简单单一,使用灵活 一般命令行工具都是很小巧简单,专注只做一件事 形式统一,对开发人员更友好 命令行工具只接收固定的参数运作,以一问一答的形式或者指派开始进程,指派结束进程的方式与人交互,几乎可以说没有太多的交互可言,因此便于开发 便于自动化 可以通过脚本将多个工具串联实现复杂功能 缺点 交互不友好 命令行工具几乎没有交互可言,因此看起来比较丑陋而且不连贯 选择困难 对于一般不熟悉的用户,众多的工具会让人无从下手 跨平台学习成本高 linux,windows都有各自的系统接口和语言环境,他们往往并不通用,因此工具可移植性比较差,不同平台要记不同的命令增加了学习成本. 使用脚本语言编写命令行工具 静态语言编写命令行工具虽然便于分发,但写起来太过费事因此往往不是快速开发最好的选择 现在的很多工具都是用脚本语言写的,为了让脚本语言写的工具用起来像静态语言编写的那样,不用声明使用的是什么解释器, 在unix和它的衍生平台上,我们常在脚本开头写上比如: #!/usr/bin/env python 这样的标识,这叫Shebang (Unix), 之后再使用chmod +x 为全局赋予执行权限,或者使用chmod u+x 为当前用户提供执行权限. 而在windows上,我们可以通过后缀选择运行的工具. 使用python编写命令行工具 python的简易语法和很多很\"魔法\"的语言工具,非常适合编写命令行工具.其标准库就已经提供了足够好用的命令行参数解析工具,而社区很多有才的开发者又设计了许多对开发人员更加友好的同类工具,本文将对几个典型的工具做说明. 标准库中的命令行解析工具(argparse) python标准库中的argparse模块是官方推荐的命令行工具.它可以解析命令行参数,可以生成次级菜单等 基本命令 argparse模块的命令可以归结为就3条 parser = argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True) 创建命令行解析对象 其中的参数: prog - 程序的名字（默认：sys.argv[0]） usage - 描述程序用法的字符串（默认：从解析器的参数生成） description - 参数帮助信息之前的文本（默认：空） epilog - 参数帮助信息之后的文本（默认：空） parents - ArgumentParser 对象的一个列表，这些对象的参数应该包括进去 像有时候需要解析非常复杂的关键字参数,比如像git那样的, import argparse parent_parser = argparse.ArgumentParser(add_help=False) parent_parser.add_argument('--parent', type=int) foo_parser = argparse.ArgumentParser(parents=[parent_parser]) foo_parser.add_argument('foo') foo_parser.parse_args(['--parent', '2', 'XXX']) Namespace(foo='XXX', parent=2) bar_parser = argparse.ArgumentParser(parents=[parent_parser]) bar_parser.add_argument('--bar') bar_parser.parse_args(['--bar', 'YYY']) Namespace(bar='YYY', parent=None) formatter_class - 定制化帮助信息的类 prefix_chars - 可选参数的前缀字符集（默认：‘-‘） fromfile_prefix_chars - 额外的参数应该读取的文件的前缀字符集（默认：None） argument_default - 参数的全局默认值（默认：None） conflict_handler - 解决冲突的可选参数的策略（通常没有必要） add_help - 给解析器添加-h/–help 选项（默认：True） parser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) 增加命令行参数,方法的参数说明如下: name or flags 命令行参数名或者选项，如上面的address或者-p,--port.其中命令行参数如果没给定，且没有设置defualt，则出错。但是如果是选项的话，则设置为None,add_argument() 方法必须知道期望的是可选参数，比如-f 或者--foo，还是位置参数，比如一个文件列表。传递给add_argument() 的第一个参数因此必须是一个标记序列或者一个简单的参数名字。例如，一个可选的参数可以像这样创建： action action 关键字参数指出应该如何处理命令行参数。支持的动作有: 'store' - 只是保存参数的值。这是默认的动作 'store_const' - 保存由const关键字参数指出的值。（注意const关键字参数默认是几乎没有帮助的None。）'store_const'动作最常用于指定某种标记的可选参数 'store_true'和'store_false' - 它们是'store_const' 的特殊情形，分别用于保存值True和False。另外，它们分别会创建默认值False 和True。 'append' - 保存一个列表，并将每个参数值附加在列表的后面。这对于允许指定多次的选项很有帮助。示例用法： 'append_const' - 保存一个列表，并将const关键字参数指出的值附加在列表的后面。（注意const关键字参数默认是None。）'append_const' 动作在多个参数需要保存常量到相同的列表时特别有用。例如： 'count' - 计算关键字参数出现的次数。例如，这可用于增加详细的级别： 'help' - 打印当前解析器中所有选项的完整的帮助信息然后退出。默认情况下，help动作会自动添加到解析器中。参见ArgumentParser以得到如何生成输出信息。 'version' - 它期待version=参数出现在add_argument()调用中，在调用时打印出版本信息并退出： nargs 命令行参数的个数，一般使用通配符表示，其中，'?'表示只用一个，'*'表示0到多个，'+'表示至少一个 default 默认值 type 参数的类型，默认是字符串string类型，还有float、int,file等类型 choices 可以看做是default的扩展,参数的值必须在choices的范围内 required 一般情况下，argparse模块假定-f和--bar标记表示可选参数，它们在命令行中可以省略。如果要使得选项是必需的，可以指定True作为required=关键字参数的值给add_argument() help 和ArgumentParser方法中的参数作用相似，出现的场合也一致 parser.parse_args() 执行解析命令行参数 一个简单的例子 我们来写一个实现求整数开根的命令行工具,它有--help(-h)和--version(-v)两个参数信息 代码如下: %%writefile src/python/std/sqrt_std.py #!/usr/bin/env python # -*- coding:utf-8 -*- from __future__ import print_function import argparse from math import sqrt __version__=\"0.1.0\" def sqrtarg(number): return sqrt(number) def version(): return \"version:\"+__version__ def main(): parser = argparse.ArgumentParser() parser.add_argument(\"number\", type=int, help=u\"求开根的参数\") parser.add_argument(\"-v\",\"--version\", help=u\"查看版本号\",action=\"store_true\") args = parser.parse_args() if args.version: print(version()) if args.number: print(sqrtarg(args.number)) if __name__ == '__main__': main() Overwriting src/python/std/sqrt_std.py !python src/python/std/sqrt_std.py usage: sqrt_std.py [-h] [-v] number sqrt_std.py: error: too few arguments !python src/python/std/sqrt_std.py -h usage: sqrt_std.py [-h] [-v] number positional arguments: number 求开根的参数 optional arguments: -h, --help show this help message and exit -v, --version 查看版本号 !python src/python/std/sqrt_std.py 36 6.0 运行细节 type参数只是类型检验,传入的参数还是字符串 不需要写usage 有nargs参数的话获取的对应是一个list 参数传入实际上是被存入了一个namespace的空间中这个空间有俩参数,其中一个是方法名命名的一个list,要调用使用即可: args.方法名 如果参数中有只能接受一个的情况,可以加入判断 if args.methodname1 == args.methodname1: print 'usage: ' + __file__ + ' --help' sys.exit(2) 来判断两个参数,要么都存在， 要么都不存在， 即可满足要求 子解析 如果要写一个类似git那样复杂的有子命令如add,push pull等的工具,单单用上面的解析工具是不够的,需要使用add_subparsers([title][, description][, prog][, parser_class][, action][, option_string][, dest][, help][, metavar])命令 其中: title - 在输出的帮助中子解析器组的标题；默认情况下，如果提供description参数则为“subcommands”，否则使用位置参数的标题 description - 在输出的帮助中子解析器组的描述，默认为None prog - 与子命令的帮助一起显示的使用帮助信息，默认为程序的名字和子解析器参数之前的所有位置参数 parser_class - 用于创建子解析器实例的类，默认为当前的解析器（例如ArgumentParser） dest - 子命令的名字应该存储的属性名称；默认为None且不存储任何值 help - 在输出的帮助中子解析器中的帮助信息，默认为None metavar - 在帮助中表示可用的子命令的字符串；默认为None并以{cmd1, cmd2, ..}的形式表示子命令 parser = argparse.ArgumentParser() parser.add_argument('--foo', action='store_true', help='foo help') subparsers = parser.add_subparsers(help='sub-command help') parser_a = subparsers.add_parser('a', help='a help') parser_a.add_argument('bar', type=int, help='bar help') parser_b = subparsers.add_parser('b', help='b help') parser_b.add_argument('--baz', choices='XYZ', help='baz help') parser.parse_args(['a', '12']) Namespace(bar=12, foo=False) parser.parse_args(['--foo', 'b', '--baz', 'Z']) Namespace(baz='Z', foo=True) 处理子命令的一个特别有效的方法是将add_subparsers()方法和set_defaults() 调用绑在一起使用，这样每个子命令就可以知道它应该执行哪个Python 函数。例如： def foo(args): print args.x * args.y def bar(args): print '((%s))' % args.z parser = argparse.ArgumentParser() subparsers = parser.add_subparsers() parser_foo = subparsers.add_parser('foo') parser_foo.add_argument('-x', type=int, default=1) parser_foo.add_argument('y', type=float) parser_foo.set_defaults(func=foo) parser_bar = subparsers.add_parser('bar') parser_bar.add_argument('z') parser_bar.set_defaults(func=bar) args = parser.parse_args('foo 1 -x 2'.split()) args Namespace(func=, x=2, y=1.0) args.func(args) 2.0 args = parser.parse_args('bar XYZYX'.split()) args Namespace(func=, z='XYZYX') args.func(args) ((XYZYX)) 这样的话，你可以让parse_args()在参数解析完成之后去做调用适当的函数的工作。像这种方式将函数和动作关联起来是最简单的方法来处理你每个子命令的不同动作。然而，如果需要检查调用的子命令的名字，用dest关键字参数调用add_subparsers()就行 parser = argparse.ArgumentParser() subparsers = parser.add_subparsers(dest='subparser_name') subparser1 = subparsers.add_parser('1') subparser1.add_argument('-x') subparser2 = subparsers.add_parser('2') subparser2.add_argument('y') parser.parse_args(['2', 'frobble']) Namespace(subparser_name='2', y='frobble') 参数分组 很多时候参数是相互配合使用的,这就可以用add_argument_group(title=None, description=None)分组 parser = argparse.ArgumentParser(prog='PROG', add_help=False) group1 = parser.add_argument_group('group1', 'group1 description') group1.add_argument('foo', help='foo help') group2 = parser.add_argument_group('group2', 'group2 description') group2.add_argument('--bar', help='bar help') _StoreAction(option_strings=['--bar'], dest='bar', nargs=None, const=None, default=None, type=None, choices=None, help='bar help', metavar=None) parser.print_help() usage: PROG [--bar BAR] foo group1: group1 description foo foo help group2: group2 description --bar BAR bar help 要一组参数互斥,可以使用add_mutually_exclusive_group(required=False) required 参数，用于指示互斥分组中至少有一个参数是必需的 parser = argparse.ArgumentParser(prog='PROG') group = parser.add_mutually_exclusive_group(required=True) group.add_argument('--foo', action='store_true') group.add_argument('--bar', action='store_false') parser.parse_args([\"--foo\",\"--bar\"]) usage: PROG [-h] (--foo | --bar) PROG: error: argument --bar: not allowed with argument --foo An exception has occurred, use %tb to see the full traceback. SystemExit: 2 parser.parse_args([]) usage: PROG [-h] (--foo | --bar) PROG: error: one of the arguments --foo --bar is required An exception has occurred, use %tb to see the full traceback. SystemExit: 2 parser.parse_args([\"--foo\"]) Namespace(bar=True, foo=True) 更加pythonic的替代品 实话说python的标准库还是比较有C/C++语言的风格残留的,而现如今的python代码风格会更加'魔法'一些,会用到比较多的装饰器工具. click就是一个比较符合现在python编程风格的工具.它是一个比较重的命令行解析工具,它还包括了参数类型检验等复杂的功能,很适合构建复杂的命令行工具.不过命令行工具做的太复杂就不太符合它的定位了,因此这边不多讲. 他的用法也不复杂,使用python的装饰器声明参数,并自动构建帮助文档,具体的细节可以看官方文档. 所见即所得的命令行的工具(docopt) docopt的特色是利用文件的__doc__,解析命令行参数构建参数组成的字典来自动识别.它可以使用pip安装,并完全支持pypy 我们用docopt改写上面的开方工具 %%writefile src/python/doc/sqrt_doc.py #!/usr/bin/env python # coding:utf-8 u\"\"\" Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) Options: -h --help 帮助 -v --version 显示版本号. -a --all 显示全部参数 \"\"\" from docopt import docopt from math import sqrt __version__=\"0.1.0\" def version(): return \"version:\"+__version__ def main(): args = docopt(__doc__) if args.get(\"-h\") or args.get(\"-help\"): print(__doc__) elif args.get(\"-v\") or args.get(\"--version\"): print(__version__) elif args.get(\"-a\") or args.get(\"--all\"): print(args) elif args.get(\"\"): print(\" \".join(map(lambda x :str(sqrt(float(x))),args.get(\"\")))) else: print(\"wrong args!\") print(__doc__) if __name__ == '__main__': main() Overwriting src/python/doc/sqrt_doc.py !python src/python/doc/sqrt_doc.py Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) !python src/python/doc/sqrt_doc.py -a {u'--all': True, u'--help': False, u'--version': False, u'': [], u'option': False} !python src/python/doc/sqrt_doc.py -v 0.1.0 !python src/python/doc/sqrt_doc.py -h Usage: test1.py [option] ... test1.py (-v|--version) test1.py (-a|--all) test1.py (-h|--help) Options: -h --help 帮助 -v --version 显示版本号. -a --all 显示全部参数 !python src/python/doc/sqrt_doc.py 36 6.0 细节 用<>包裹表示参数,如果参数后面有...则表示参数是列表 用[]包裹选项 用()包裹必选内容 用|区分选项 这边有一个详细的匹配细节和测试工具 docopt写起来并不会省代码,但它所见即所得,更加直观,当你写完注释的时候你的命令行解析也实现了. 补充:命令行显示循环美化 tqdm是一个进度条工具,除了可以给命令行工具增加进度条看出进度外,还可以用于jupyter-notebook tqdm模块的tqdm类是这个包的核心,所有功能都是在它上面衍生而来 tqdm类 可以包装可迭代对象,它的实例化参数有: desc : str, optional 放在bar前面的描述字符串 total : int, optional 显示多长 leave : bool, optional 结束时时保留进度条的所有痕迹。 file : io.TextIOWrapper or io.StringIO, optional 输出到文件 ncols : int, optional 自定义宽度 mininterval : float, optional 更新最短时间 maxinterval : float, optional 更新最大时间 miniters : int, optional 每次更新最小值 ascii : bool, optional 使用ascii碼显示 disable : bool, optional 是否禁用整个progressbar unit : str, optional 显示的更新单位 unit_scale : bool, optional 根据单位换算进度 dynamic_ncols : bool, optional 可以不断梗概ncols的环境 smoothing : float, optional 用于速度估计的指数移动平均平滑因子（在GUI模式中忽略）。范围从0（平均速度）到1（当前/瞬时速度）[默认值：0.3]。 bar_format : str, optional 指定自定义栏字符串格式。可能会影响性能 initial : int, optional 初始计数器值。重新启动进度条时有用[默认值：0]。 position : int, optional 指定打印此条的线偏移（从0开始）如果未指定，则为自动。用于一次管理多个条 基础的循环 from tqdm import tqdm for i in tqdm(range(int(9e6)),desc=\"test:\"): pass test:: 100%|██████████| 9000000/9000000 [00:07for i in tqdm(range(int(9e6)),desc=\"test\",dynamic_ncols=True): pass test: 100%|██████████| 9000000/9000000 [00:07使用with语句手工更新 with tqdm(total=100) as bar: for i in range(10): bar.update(10) 100%|██████████| 100/100 [00:00补充: python命令行工具的发布 我的用python写的脚本直接运行当然是可以,用Shebang结合权限设定也可以在一般的情况下使用,但如果我们的希望它成为可以随时使用的工具,更好的方式是将它用setuptool安装到python的脚本位置(当然也可以上传到pyp上供大家使用), 这边给出两个的setup.py文件作为参考 %%writefile src/python/doc/setup.py from distutils.core import setup import os pathroot = os.path.split(os.path.realpath(__file__))[0] setup( name='sqrt_doc', version='0.1.0', scripts=[pathroot+'/sqrt_doc.py'] ) Overwriting src/python/doc/setup.py !python src/python/doc/setup.py install running install running build running build_scripts copying and adjusting /Users/huangsizhe/WORKSPACE/Blog/Docs/Human-Computer_nteraction_interface/commandline_tool/src/python/doc/sqrt_doc.py -> build/scripts-2.7 running install_scripts copying build/scripts-2.7/sqrt_doc.py -> /Users/huangsizhe/Lib/CONDA/anaconda/bin changing mode of /Users/huangsizhe/Lib/CONDA/anaconda/bin/sqrt_doc.py to 755 running install_egg_info Removing /Users/huangsizhe/Lib/CONDA/anaconda/lib/python2.7/site-packages/sqrt_doc-0.1.0-py2.7.egg-info Writing /Users/huangsizhe/Lib/CONDA/anaconda/lib/python2.7/site-packages/sqrt_doc-0.1.0-py2.7.egg-info !sqrt_doc.py 48 6.92820323028 将std文件夹中文件结构改成 |-lib\\ | |-__init__.py | |-sqrt_std.py |-setup.py %%writefile src/python/std/setup.py from setuptools import setup,find_packages import os pathroot = os.path.split(os.path.realpath(__file__))[0] setup( name='sqrt_std', version='0.1.0', packages = find_packages(), entry_points = { 'console_scripts': ['sqrt_std=lib.sqrt_std:main'], } ) Overwriting src/python/std/setup.py 之后到目录下开始编译 python setup.py install !sqrt_std 36 6.0 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 21:47:02 "},"人机交互/GUI.html":{"url":"人机交互/GUI.html","title":"GUI","keywords":"","body":"GUI 鼠标和微软苹带来了GUI这种交互方式,它的最大特点是图像化,依靠点击来选择指令,而且一般除了主页面外,还会有多层的子页面.交互模式开始复杂了起来. 从GUI诞生开始,设计和美学开始进入这个领域,而对用户的友好程度成为了一个软件的衡量标准之一. GUI的设计原则 GUI的图形化特点带了了用户学习难度的降低,因此GUI包括后来的各种交互模式的设计最重要的就是以人为本,关注用户体验 必须考虑目标用户群体是个什么样的群像 必须考虑用户的学习成本,突出简化最主要的需求的操作,并尽量让用户用更少的步骤完成需求 设计应该符合常识习惯 避免频繁的切换界面,界面间应该风格统一和谐 python的GUI编程(Tk) GUI也就是图形界面啦,Python有不少GUI框架,而tkinter是自带的,为啥选这个呢,因为一般用Python写GUI都不会写多复杂,也就是够用就好.最符合这一要求的就是tkinter了,Python自带,逻辑简单,模块少而够用. 第一个例子 %%writefile src/first.py import tkinter tkinter._test() Overwriting src/first.py 运行这个脚本,是不是跳出了一个小框框.这是tk的自带例子 %exec_py3 src/first.py 第一个例子 + 我们来自己写个例子,体会下tk的逻辑 %%writefile src/firstGUI.py #coding:utf-8 from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/firstGUI.py %exec_py3 src/firstGUI.py 运行后出现如图小对话框 可以看出,主类继承自Frame基类 每个Button、Label、输入框等，都是一个Widget。Frame则是可以容纳其他Widget的Widget，所有的Widget组合起来就是一棵树。 pack()方法把Widget加入到父容器中，并实现布局。pack()是最简单的布局，grid()可以实现更复杂的布局。 在createWidgets()方法中，我们创建一个Label和一个Button，当Button被点击时，触发self.quit()使程序退出 组件 tkinter的控件主要有这些: Label 标签 Button 按钮 Toplevel Canvas Checkbutton Entry Frame LabelFrame Listbox Menu Menubutton Message OptionMenu PaneWindow Radiobutton Scale Scrollbar Spinbox Text Bitmap Image ScrolledText.frame ScrolledText.vbar 标签 Label 标签可以定义的属性主要有: text 标签的内容,文本信息 font 字体 background 背景色 按钮 Button 按钮算是最常用的控件之一了,它的属性主要有: 宽度 width 高度 height 背景色 background 显示文字 text 但是说到按钮当然最重要的是触发事件了 命令 command 接受一个函数名,注意是函数名,没有括弧 输入框 Entry 属性: get() 获取输入(返回一个str) 例:一个用户登录界面 %%writefile src/entry.py from tkinter import Frame,Label,Button,Entry class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.userLabel = Label(self, text='用户名:') self.userLabel.grid(row = 0,column = 0,sticky=\"w\") self.userEntry = Entry(self) self.userEntry.grid(row = 0,column = 1,sticky=\"e\") self.pwLabel = Label(self, text='密码:') self.pwLabel.grid(row = 1,column = 0,sticky=\"w\") self.pwEntry = Entry(self) self.pwEntry.grid(row = 1,column = 1,sticky=\"e\") self.enterButton = Button(self,text = \"登录\",command = self.reg) self.enterButton.grid(row = 2,column = 1,sticky = \"e\") self.logLabel = Label(self, text='') self.logLabel.grid(row = 3) def reg(self): s1 = self.userEntry.get() s2 = self.pwEntry.get() if s1 == \"www.google.com\" and s2 == \"www.bing.com\": self.logLabel[\"text\"]=\"登录成功\" else: self.logLabel[\"text\"]=\"用户名或密码错误\" self.userEntry.delete(0,len(s1)) self.pwEntry.delete(0,len(s1)) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('登录界面') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/entry.py %exec_py3 src/entry.py 单选按钮 Radiobutton 一般是几个里面选一个用 直接看代码: %%writefile src/radiobutton.py from tkinter import Frame,Label,Button,Radiobutton class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!\\n') self.helloLabel.pack() self.c1 = Radiobutton(self,text = \"1\",command = lambda : self.helloLabel.config( text = \"1被选中了奇数次\\n\") ) self.c1.pack() self.c2 = Radiobutton(self,text = \"2\",command = lambda : self.helloLabel.config( text = \"2被选中了奇数次\\n\") ) self.c2.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/radiobutton.py %exec_py3 src/radiobutton.py 复选框 Checkbutton 复选框通常是用来选择信息的时候的一种选择,它前面 有个小正方形的方块,如果选中则有一个对号,也可以再 次点击以取消该对号来取消选中。 看个例子 %%writefile src/checkbutton.py from tkinter import Frame,Label,Button,Checkbutton class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!\\n') self.helloLabel.pack() self.c1 = Checkbutton(self, text = \"1\", command = lambda : self.helloLabel.config( text = self.helloLabel[\"text\"]+\"1被选中了奇数次\\n\")) self.c1.pack() self.c2 = Checkbutton(self, text = \"2\", command = lambda : self.helloLabel.config( text = self.helloLabel[\"text\"]+\"2被选中了奇数次\\n\")) self.c2.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/checkbutton.py %exec_py3 src/checkbutton.py 文本域 Text 也就是用来存放字符串的大空间 基本的定义也就是宽度width和高度height了 %%writefile src/text.py from tkinter import * root = Tk() text = Text(root) text.pack() # INSERT 索引表示插入光标当前的位置 text.insert(INSERT, \"I love \") text.insert(END, \"Python!\") mainloop() Overwriting src/text.py %exec_py3 src/text.py 画布 Canvas 和html5中的画布一样,tk中的画布也是用来绘图的,直接看代码吧: %%writefile src/canvas.py from tkinter import Frame,Canvas class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.can = Canvas(self,width = 400,height=300,bg = \"#233333\") self.can.create_line((0,0),(200,200),width = 8) self.can.create_text(300,30,text = \"一个画板\") self.can.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') # 主消息循环: app.mainloop() Overwriting src/canvas.py %exec_py3 src/canvas.py 多窗口 Toplevel %%writefile src/toplevel.py from tkinter import Frame,Label,Button,Toplevel class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world1!') self.helloLabel.pack() class App2(Toplevel): def __init__(self, master=None): Toplevel.__init__(self, master) self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world2!') self.helloLabel.pack() if __name__ ==\"__main__\": app1 = Application() # 设置窗口标题: app1.master.title('Hello World1') app1.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app2 = App2() app2.title(\"helloword2\") app1.mainloop() Overwriting src/toplevel.py %exec_py3 src/toplevel.py 菜单 Menu Menu 和其他的组件一样,第一个是 parent,这里通常可以为窗口。 然后我们可以用 add_commmand 方法来为它添加菜单项, 如果该菜单是顶层菜单,则添加的菜单项依次向右添加。 如果该菜单时顶层菜单的一个菜单项,则它添加的是下拉菜单的菜单项。 add_command 中的参数常用的有: label 属性,用来指定的是菜单项的名称 command 属性用来指定被点击的时候调用的方法 acceletor 属性指定的是快捷键 underline 属性 是是否拥有下划线。 最后可以用窗口的 menu 属性指定我们使用哪一个作为它 的顶层菜单. 子菜单 如果有子菜单,我们需则需要使用 add_cascade cascade 可以理解为“级联”,即它 的作用只是为了引出后面的菜单。 add_cascade属性: menu 属性,它指明了要把那个菜单级联到该菜单项上 label 属性,用于指定该菜单项的名称。 弹出菜单 一般弹出菜单是右键点击后出现的菜单,tk中的弹出菜单比较原始的,具体思路是这样: 我们先新建一个菜单, 然后向菜单项中添加各种功能, 最后我们监听鼠标右键消息,如果是鼠标 右键被单击, 此时可以根据需要判断下鼠标位置来确定是哪个弹出菜单被弹出, 然后使用 Menu 类的 pop 方法来弹出 菜单。 Menu 类里面有一个post方法,它接收两个参数,即 x 和 y 坐标,它会在相应的位置弹出菜单。 插入分割线 .add_separator() 插入单选菜单和复选菜单 单选菜单: .add_radiobutton() 复选菜单: .add_checkbutton() 例子: 一个菜单栏 %%writefile src/menu.py from tkinter import Frame,Label,Button,Menu class Application(Frame): def __init__(self, master=None,): Frame.__init__(self, master) #窗口大小位置 self.pack() self.createWidgets() self.creatMenu() def creatMenu(self): #主菜单 menubar = Menu(self) #子菜单 menufile = Menu(menubar) for item in [\"新建\",\"打开\",\"保存\",\"另存为\"]: menufile.add_radiobutton(label = item) menuedit = Menu(menubar) for item in [\"复制\",\"黏贴\",\"剪切\"]: menuedit.add_checkbutton(label = item) #子菜单与主菜单关联 for name,submenu in zip([\"文件\",\"编辑\"],[menufile,menuedit]): menubar.add_cascade(label=name,menu=submenu) #最关键的一步,主菜单与app关联 self.master.config(menu=menubar) #右键菜单 menu = Menu(self.master) for i in ('One', 'Two', 'Three'): menu.add_command(label=i) #插入分割线 menu.add_separator() for i in ('1', '2', '3'): menu.add_command(label=i) #绑定鼠标右键呼出 if (self.master.tk.call('tk', 'windowingsystem')=='aqua'): self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) else: self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel[\"background\"] =\"green\" self.helloLabel.pack() self.quitButton = Button(self, text='Quit',fg=\"red\", command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/menu.py %exec_py3 src/menu.py 对话框 Dialog 和消息盒子 messagebox 对话框 对话框就是那个点击以后跳出来的框框,让你选几个选项,选完给程序一个返回值,一般用来做问卷调查呀啥的,我们拿原来登录界面做做修改,把账号密码错误提示弄成对话框 %%writefile src/dialog.py from tkinter import Frame,Label,Button,Entry from tkinter.dialog import Dialog class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.userLabel = Label(self, text='用户名:') self.userLabel.grid(row = 0,column = 0,sticky=\"w\") self.userEntry = Entry(self) self.userEntry.grid(row = 0,column = 1,sticky=\"e\") self.pwLabel = Label(self, text='密码:') self.pwLabel.grid(row = 1,column = 0,sticky=\"w\") self.pwEntry = Entry(self) self.pwEntry.grid(row = 1,column = 1,sticky=\"e\") self.enterButton = Button(self,text = \"登录\",command = self.reg) self.enterButton.grid(row = 2,column = 1,sticky = \"e\") self.logLabel = Label(self, text='') self.logLabel.grid(row = 3) def reg(self): s1 = self.userEntry.get() s2 = self.pwEntry.get() if s1 == \"www.google.com\" and s2 == \"www.bing.com\": self.logLabel[\"text\"]=\"登录成功\" else: self.logLabel[\"text\"]=\"用户名或密码错误\" self.userEntry.delete(0,len(s1)) self.pwEntry.delete(0,len(s1)) d = Dialog(None,title = \"错误信息\",text = \"用户名或密码错误\", default=0,strings = (\"重来\",\"放弃\")) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('登录界面') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/dialog.py %exec_py3 src/dialog.py 消息盒子 消息盒子就是提示错误的那种弹窗,同样的还拿那个改 %%writefile src/messagebox.py from tkinter import Frame,Label,Button,Entry from tkinter.messagebox import showinfo class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.userLabel = Label(self, text='用户名:') self.userLabel.grid(row = 0,column = 0,sticky=\"w\") self.userEntry = Entry(self) self.userEntry.grid(row = 0,column = 1,sticky=\"e\") self.pwLabel = Label(self, text='密码:') self.pwLabel.grid(row = 1,column = 0,sticky=\"w\") self.pwEntry = Entry(self) self.pwEntry.grid(row = 1,column = 1,sticky=\"e\") self.enterButton = Button(self,text = \"登录\",command = self.reg) self.enterButton.grid(row = 2,column = 1,sticky = \"e\") self.logLabel = Label(self, text='') self.logLabel.grid(row = 3) def reg(self): s1 = self.userEntry.get() s2 = self.pwEntry.get() if s1 == \"www.google.com\" and s2 == \"www.bing.com\": self.logLabel[\"text\"]=\"登录成功\" else: self.logLabel[\"text\"]=\"用户名或密码错误\" self.userEntry.delete(0,len(s1)) self.pwEntry.delete(0,len(s1)) showinfo(title = \"错误\",message=\"用户名或密码错误\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('登录界面') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/messagebox.py %exec_py3 src/messagebox.py 大小和位置 对于窗口,大小可以通过geometry函数来控制 'width x height + xoffset + yoffset' 控件布局 有3种方式可以为控件布局: pack() grid() place() pack() pack()默认会一个一个从上往下堆叠,但同样也可以接受几个参数 side (left,top,right,bottom) fill ( X,Y,BOTH 和 NONE)水平方向填充,竖直方向填充,水平和竖直方向填充和不填充。 expand 参数可以是 YES 和 NO anchor (n, ne, e, se, s, sw, w, nw, or center)NESW 表示上右下左以及他们的组合或者是 CENTER(表示中 间)。 ipadx 表示的是内边距的 x 方向 ipady 表示 的是内边距的 y 方向 padx 表示的是外边距的 x 方向 pady 表示的是外边距的 y 方向。 %%writefile src/pack.py from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.LabelL = Label(self, text='左边') self.LabelL.pack(side=\"left\") self.LabelR = Label(self, text='右边') self.LabelR.pack(side=\"right\") self.LabelT = Label(self, text='顶') self.LabelT.pack(side=\"top\") self.LabelB = Label(self, text='底') self.LabelB.pack(side=\"bottom\") self.LabelN = Label(self, text='N') self.LabelN.pack(anchor=\"n\") self.LabelE = Label(self, text='E') self.LabelE.pack(anchor=\"e\") self.LabelS = Label(self, text='S') self.LabelS.pack(anchor=\"s\") self.LabelW= Label(self, text='W') self.LabelW.pack(anchor=\"w\") self.LabelCENTER= Label(self, text='CENTER') self.LabelCENTER.pack(anchor=\"center\") self.quitButton = Button(self, text='Quit',background=\"red\", command=self.quit) self.quitButton.pack(side=\"bottom\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('pack布局测试') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/pack.py %exec_py3 src/pack.py grid() 最常用布局 grid()里的参数: row 表示行(从0开始) column 表示列(从0开始) sticky (N,E,S,W) 表 示上右下左,它决定了这个组件是从哪个方向开始的 ipadx,ipady,padx,pady,它们 的意思和 pack 函数是一样的,默认边距是 0。 rowspan 表示跨越的行数 columnspan 表示跨越的列数。 %%writefile src/grid.py from tkinter import Frame,Label,Button class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) self.pack() self.createWidgets() def createWidgets(self): self.Label00 = Label(self, text='00') self.Label00.grid(row=0,column=0) self.Label10 = Label(self, text='10') self.Label10.grid(row=1,column=0) self.Label11 = Label(self, text='11') self.Label11.grid(row=1,column=1) self.Label30 = Label(self, text='30') self.Label30.grid(row=3,column=0) self.quitButton = Button(self, text='Quit',background=\"red\", command=self.quit) self.quitButton.grid(row=2,column=2) if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('pack布局测试') #窗口大小位置 #app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/grid.py %exec_py3 src/grid.py place() 最好不要用....不优雅 事件 事件绑定和解绑 bind() unbind() 绑定bind() bind 函数的调用规则: 窗体对象.bind(事件类型,回调函数) 事件类型: 事件类型是一组字符串,它采用的描述方式是这 样的: MODIFIER 即修饰符,它的全部取值如下: Control Mod1, M1, Command Alt Mod2, M2, Option Shift Mod3, M3 Lock Mod4, M4 Extended Mod5, M5 Button1, B1 Meta, M Button2, B2 Double Button3, B3 Triple Button4, B4 Quadruple Button5, B5 --- TYPE 表示类型,它的全部取值如下: Activate Destroy Map ButtonPress, Button Enter MapRequest ButtonRelease Expose Motion Circulate FocusIn MouseWheel CirculateRequest FocusOut Property Colormap Gravity Reparent Configure KeyPress, Key ResizeRequest ConfigureRequest KeyRelease Unmap Create Leave Visibility Deactivate --- --- DETAIL 表示细节,其实也就是对第二个参数的一些辅助说明。 常用事件类型: 表示鼠标左键单击,其中的 1 换成 3 表示右 键被单击,为 2 的时候表示鼠标中键 表示 A 键被按下,其中的 A 可以换成其他的键位。 表示按下的是 Ctrl 和 V 键,V 可以换成其他 键位。 表示按下的是 F1 键,对于 Fn 系列的,都可以随便 换。 更加具体的可以看http://www.tcl.tk/man/tcl8.5/TkCmd/bind.htm#M23 bind()可以绑定所有继承自Misc类的组件,也就是说即便是标签也可以绑定动作. bind()有两个扩展 窗体对象.bind_all(事件类型,回调函数)全程序级别绑定事件 窗体对象.bind_class(类名,事件类型,回调函数)类级别绑定事件,比如所有标签这样 解绑 unbind() 窗体对象.unbind(事件类型) ttk ttk是tk的扩展,主要是美化和新增了几个控件 还是看例子: %%writefile src/ttk.py from tkinter import * from tkinter.ttk import * class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.createWidgets() def createWidgets(self): self.helloLabel = Label(self, text='Hello, world!') self.helloLabel.pack() self.quitButton = Button(self, text='Quit', command=self.quit) self.quitButton.pack() if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('Hello World') app.master.geometry(\"600x400+100+400\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/ttk.py %exec_py3 src/ttk.py gui 界的 helloworld, 一个记事本 %%writefile src/editer.py import os from tkinter import * from tkinter.messagebox import * from tkinter.filedialog import * class Application(Frame): def __init__(self, master=None): Frame.__init__(self, master) #窗口大小位置 self.master.geometry(\"600x400+100+400\")#长x宽+x+y self.pack() self.filename = \"\" self.creatMenu() self.createWidgets() def creatMenu(self): #主菜单 menubar = Menu(self) #子菜单 menufile = Menu(menubar) menufile.add_command(label = \"打开\",accelerator = \"Ctrl + O\",command = self.myopen) menufile.add_command(label = \"新建\",accelerator = \"Ctrl + N\",command = self.new) menufile.add_command(label = \"保存\",accelerator = \"Ctrl + S\",command = self.save) menufile.add_command(label = \"另存为\",accelerator = \"Ctrl + Shift + S\",command = self.saveas) menuedit = Menu(menubar) menuedit.add_command(label = \"剪切\",accelerator = \"Ctrl + X\",command = self.cut) menuedit.add_command(label = \"复制\",accelerator = \"Ctrl + C\",command = self.copy) menuedit.add_command(label = \"黏贴\",accelerator = \"Ctrl + V\",command = self.paste) menuedit.add_separator() menuedit.add_command(label = \"全选\",accelerator = \"Ctrl + A\", command = lambda :self.textPad.tag_add('sel',1.0,\"end\")) menuaboutme = Menu(menubar) menuaboutme.add_command(label = \"作者\",command = self.author) menuaboutme.add_command(label = \"版权\",command = self.power) #子菜单与主菜单关联 for name,submenu in zip([\"文件\",\"编辑\",\"关于\"],[menufile,menuedit,menuaboutme]): menubar.add_cascade(label=name,menu=submenu) #最关键的一步,主菜单与app关联 self.master.config(menu=menubar) #右键菜单 menu = Menu(self.master) menu.add_command(label = \"剪切\",command = self.cut) menu.add_command(label = \"复制\",command = self.copy) menu.add_command(label = \"黏贴\",command = self.paste) #绑定鼠标右键呼出 if (self.master.tk.call('tk', 'windowingsystem')=='aqua'): self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) else: self.master.bind('', lambda e: menu.post(e.x_root, e.y_root)) def createWidgets(self): self.shortcutbar = Frame(self,height = 25,bg = \"light sea green\") self.shortcutbar.pack(expand = NO,fill =X) self.lnlabel = Label(self,width = 2,bg = \"antique white\") self.lnlabel.pack(side = LEFT,anchor = 'nw',fill = Y) self.textPad = Text(self,bg = \"antique white\") self.textPad.pack() self.textPad.insert(INSERT,\"Hello\") self.textPad.insert(END,\"world\") self.textPad.bind(\"\",self.new) self.textPad.bind(\"\",self.new) self.textPad.bind(\"\",self.myopen) self.textPad.bind(\"\",self.myopen) self.textPad.bind(\"\",self.save) self.textPad.bind(\"\",self.save) self.textPad.bind(\"\",lambda : self.textPad.tag_add('sel',1.0,\"end\")) self.textPad.bind(\"\",lambda : self.textPad.tag_add('sel',1.0,\"end\")) def myopen(self): self.filename = askopenfilename(defaultextension = \".txt\") if self.filename == \"\": self.filename = None else: self.master.title(\"一个记事本\"+os.path.basename(self.filename)) self.textPad.delete(\"1.0\",\"end\") with open(self.filename,\"r\") as f: s = f.read() self.textPad.insert(\"1.0\",s) def new(self): self.master.title(\"未命名文件\") self.filename = None self.textPad.delete(\"1.0\",END) def save(self): try: with open(self.filename,\"w\") as f: msg = self.textPad.get(1.0,\"end\") f.write(msg) except : self.saveas() def saveas(self): f = asksaveasfilename(initialfile = \"未命名. txt\",defaultextension = \".txt\") self.filename = f with open(f,\"w\") as fh: msg = self.textPad.get(1.0,\"end\") fh.write(msg) self.master.title(\"一个记事本\"+os.path.basename(f)) def cut(self): self.textPad.event_generate(\">\") def copy(self): self.textPad.event_generate(\">\") def paste(self): self.textPad.event_generate(\">\") def author(self): self.shouinfo(\"作者黄思喆\") def power(self): self.showinfo(\"本软件使用BSD许可证\") if __name__ ==\"__main__\": app = Application() # 设置窗口标题: app.master.title('一个记事本') #app.master.geometry(\"300x300+100+100\")#长x宽+x+y # 主消息循环: app.mainloop() Overwriting src/editer.py %exec_py3 src/editer.py Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-01 21:31:57 "},"python性能优化/":{"url":"python性能优化/","title":"python性能优化","keywords":"","body":"python性能优化 python的性能是比较让人诟病的,但它却是最好的胶水语言之一,因此很多高性能工具将其作为前端使用,比如tensorflow. 有gil的python擅长的并不是cpu密集型的任务而是io密集型的任务的快速开发,即便不依赖其他语言也是可以在快速开发的同时满足大部分性能要求的.当需要进行cpu密集型任务时,可以使用多进程实现.或者使用C/C++编写扩展模块.本篇主要就是讲如何使用Cython编写基于C/C++的扩展模块. Cython的基本使用流程 Cython的纯净模式 Cython的基本模式 Cython的包装模式 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:33:31 "},"python性能优化/什么时候优化python程序.html":{"url":"python性能优化/什么时候优化python程序.html","title":"什么时候优化python程序","keywords":"","body":"过早优化是万恶之源 过早指的不是在开发过程的早期，而是在还没弄清楚需求未来的变化的走向的时候.你的优化不仅可能导致你无法很好地实现新的需求，而且你对优化的预期的猜测有可能还是错的，导致实际上你除了把代码变复杂以外什么都没得到. 就像我们小时候穿的衣服，妈妈总给我们买大一号的，可我的生长速度没那么快，每次都是穿烂了都还大.这就是过早优化的一个最典型例子.我们要评价一个东西好不好用,优不优秀,要先看它的使用场景,再结合场景讨论其功能效率.比如大家说日本刀好,但如果对抗重甲骑兵,日本刀就完全没法发挥.比如大家说f2隐形轰炸机好,先进.但如果让刚果这样的穷国家用他们更不用不起,也就谈不上好不好的问题了. 针对性能瓶颈优化项目 在工程上往往是够用就好,真正需要考虑性能的情况很少,真需要的时候往往也不是全盘优化,而是需要先分析性能瓶颈,再针对这些瓶颈进行优化重构. 往往这种方式20%的改善可以带来80%的速度提升. 定位瓶颈的方法可以看工具链部分的相关内容 优先优化数据结构和算法 python虽慢但多数情况下想要达到它的性能极限是很困难的.语言本身往往并不是性能最大的瓶颈/更多的还是看算法和数据结构.python自带了很多优质的算法和数据结构实现,关于不同数据结构和算法可以看数据结构与算法部分的结语 如果任务是io密集型可以使用协程解决.如果任务是计算密集型的可以使用多进程并行的计算. 使用Cython改造特定代码 Cython实际上是一门用于沟通python和C/C++两种语言的编程语言，融合了python的灵活和C的静态快速.但是要注意python和C数据结构的区别，比如C的int和long有位数限制，而python的integer则无，为了表示较大的数，定义cython时long可用doubles来替换. Cython的工作分为两种模式: 为python模块做静态化声明,再通过翻译器将其翻译为C或者C++语言的源码,最后编译为python可调用的动态链接库作为python模块 将C或者C++编写的模块接口封装成python可调用的动态链接库 正确的优化顺序 有质量地实现你的需求,稳定需求和接口 写够testcase 做profile去找到性能的瓶颈 检查是否使用了合适的数据结构和算法,有没有不利于性能的算法在其中 如果是io密集型可以使用协程解决,如果是计算密集型任务考虑使用多进程重构. 如果觉得依然效率达不到要求,可以使用Cython将需要改造的部分python代码静态化 再还不行,可以使用C/C++重构需要优化部分的代码,然后通过Cython包装起来. 如果是计算密集型,并且有大量矩阵运算,可以考虑使用gpu运算 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:22:01 "},"python性能优化/Cython的基本流程.html":{"url":"python性能优化/Cython的基本流程.html","title":"Cython的基本流程","keywords":"","body":"Cython的编译 Cython是针对模块的,它并不使用jit技术,因此它的使用使用局限性的. Cython需要编译,本质上来说Cython只是把Cython代码编译成C/C++代码而已. Cython项目的文件组成 Cython解释器可以识别.py,.cpp,.c,.h,.pyx,.pxd,.pxi,其中 .py是python的源码,一般用在纯净模式下 .cpp,.c,.h是c/c++的源码,一般用在包装模式下 .pyx,.pxd,.pxi是cython源文件,用在一般模式下. 而cython源文件中 .pyx 为实现文件 pxd为申明文件 申明文件可以包含: 任何一种C型声明 extern C函数或变量声明 模块实现的声明 扩展类型的定义部分 外部函数库的所有声明等 申明文件不能包含: + 任何非外部C变量声明 + C或Python功能的实现 + Python类定义和Python可执行语句 + 任何被定义为公共的声明即申明可以被其他Cython模块访问.这是没有必要的，因为它是自动的.而且公共声明只需要使外部C代码可以访问. .pxi为包含文件 任何Cython代码,因为整个文件都是文字嵌入在引入处的位置,类似于c++中#include的机制 Cython项目的基本流程 Cython语法上像python,但执行上更像C++它基本上有如下几个步骤: 编写符合Cython语法的.pyx源文件 (可选)用.pxd申明.pyx源文件或者c++源文件的接口,它类似c++中的.h文件 编写setup.py安装文件,其中使用Cython.Build.cythonize函数构建模块 命令行使用python setup.py build_ext --inplace来编译源文件生成模块 使用模块只需要正常的使用import语句即可 hellowold %%writefile helloworld.pyx def run(): print(\"Hello World\") return True Overwriting helloworld.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( ext_modules = cythonize(\"helloworld.pyx\",language=\"c++\") ) Overwriting setup.py ! python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling helloworld.pyx because it changed. [1/1] Cythonizing helloworld.pyx running build_ext building 'helloworld' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tphelloworld.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\helloworld.obj helloworld.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_helloworld build\\temp.win-amd64-3.6\\Release\\helloworld.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的基本工作流程\\helloworld.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\helloworld.cp36-win_amd64.lib helloworld.obj : warning LNK4197: export 'PyInit_helloworld' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\helloworld.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\helloworld.cp36-win_amd64.exp Generating code Finished generating code import helloworld helloworld.run() Hello World True 更加丰富的编译设置 如果你的模块像上面的例子中只有一个源文件.那么helloworld中的setup.py就已经可以了,但如果不止一个,或者有一些针对编译器的设置,那么如下的写法是更好的选择 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from distutils.extension import Extension from Cython.Distutils import build_ext extension = Extension( \"helloworld\", sources=[\"helloworld.pyx\"], #include_dirs=[numpy.get_include()], # 如果用到numpy language=\"c++\" ) setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(extension), ) Overwriting setup.py !python setup.py build_ext --inplace running build_ext 可选的编译器设置包括: cythonize 用来确定所要编译的内容,它的参数可以有: ext_modules = cythonize(\"src/*.pyx\"[, include_path = [...][,compiler_directives={=}]]) include_path是编译所需的源文件,这里可以是.py文件,.pyx文件,.pxd文件,.c文件,.h文件等,也可以是几个扩展类 型distutils.extension.Extension的对象,而Extension对象又可以这样定义: Extension(name, [source...], include_dirs = [...], libraries = [...], library_dirs = [...]) compiler_directives则是编译的选项,有如下关键字: boundscheck (True / False) 如果设置为False，Cython可以自由地假定代码中的索引操作,将不会导致任何IndexErrors被抛出。 只有当索引可以被确定为非负数（或者wraparound为False），列表，元组和字符串才会受影响。 通常触发IndexError的条件可能会导致segfault或数据损坏，如果这被设置为False。 默认值为True。 wraparound (True / False) 在Python中，数组可以相对于结束索引(负索引)。而在C中是不支持负索引的。 如果设置为False，Cython既不检查也不正确处理负索引，可能导致段错误或数据损坏。 默认值为True。 initializedcheck (True / False) 如果设置为True，Cython会在访问或分配内存视图时检查它是否被初始化。 将此设置为False将禁用这些检查。 默认值为True。 nonecheck (True / False) 如果设置为False，Cython可以自由地假定 对变量类型的本地字段访问为扩展类型,或者 当变量被设为None时,对缓冲区变量的缓冲区访问永远不会发生。否则插入一个检查并引发适当的异常。 由于性能原因，默认情况下关闭。 默认值为False。 overflowcheck (True / False) 如果设置为True，当溢出的C整数算术运算上引发了异常时，会执行适度的运行时惩罚,但即便如此还是比python的int运算快很多,默认为False overflowcheck.fold (True / False) 如果设置为True，并且overflowcheck为True，则检查嵌套的溢出位,和有副作用的算术表达式,而不是每个步骤都检查。 依赖于不同的编译器，体系结构和优化设置，这项选项可能有助于提高性能也可能损害性能。 默认值为True。 embedsignature (True / False) 如果设置为True，Cython将在所有Python可见函数和类的docstring中嵌入调用签名的文本副本。 像IPython和epydoc这样的工具可以显示签名，否则编译后就无法检索。 默认值为False。 cdivision (True / False) 如果设置为False，Cython将调整余数和商值运算符C类型以匹配Python的int（当操作数具有相反的符号时不同），并且当右操作数为0时产生ZeroDivisionError。这将会有超过35％的性能损失. 如果设置为True，则不执行任何检查。 cdivision_warnings (True / False) 如果设置为True，当使用负操作数执行除法时，Cython将发出运行时警告。 默认值为False. always_allow_keywords (True / False) 在构造取零或一个参数的函数/方法时，METH_NOARGS和METH_O置空。 对具有多个参数的特殊方法和函数没有影响。 METH_NOARGS和METH_O签名提供了更快的调用约定，但不允许使用关键字 profile (True / False) 为编译成的C代码写上python分析的钩子,默认为False linetrace (True / False) 为编译后的C代码写入Python分析器或覆盖报告的跟踪钩子。 这也会启用profile。 默认值为False。 infer_types (True / False) 推断函数体中未声明类型变量的类型。默认值为None，表示只允许安全（语义上不变的）推断。特别地，推断用于算术表达式中的变量的整数类型被认为是不安全的（由于可能的溢出），并且必须被明确请求。 language_level (2/3) 全局设置要用于模块编译的Python语言级别。默认为与Python 2兼容。要启用Python 3源代码语义，请在模块开头将其设置为3，或将“-3”命令行选项传递给编译器。请注意，cimport和包含的源文件从正在编译的模块继承此设置，除非他们明确设置自己的语言级别。 c_string_type (bytes / str / unicode) 从char *或std :: string全局设置隐式强制的类型 c_string_encoding (ascii, default, utf-8, etc.) 全局设置在将char *或std：string隐式强制转化为unicode对象时使用的编码。从unicode对象到C类型的强制只允许设置为ascii或默认，后者意思是在Python 3中是utf-8 type_version_tag (True / False) 通过设置类型标志Py_TPFLAGS_HAVE_VERSION_TAG，在CPython中启用扩展类型的属性缓存。 默认值为True，表示为Cython实现的类型启用了缓存。 在类型需要在内部与其tp_dict进行协调而不关注缓存一致性的罕见情况下禁用它，可以将此选项设置为False。 unraisable_tracebacks (True / False) 是否在抑制不可取消的异常时打印回溯。 在Cython源文件中声明编译设置 上面的方法将编译设置都放在setup.py中,这样做略繁琐,也无法在源文件中体现.一个更加优雅的方法是使用类似python中声明编码一样,在源文件的初始几行中.这种方式也是现在官方推荐的写法,使用这种方式也可以更加方便的在jupyter notebook中使用C++的一些特性 %load_ext Cython %%cython # distutils: language=c++ def f(double x): return x**2-x def integrate_f(double a, double b, int N): cdef int i cdef double s, dx s = 0 dx = (b-a)/N for i in range(N): s += f(a+i*dx) return s * dx 这种方式的setup.py文件也更加简单,只需用cythonize函数指定所有.pyx文件即可 from distutils.core import setup from Cython.Build import cythonize setup( ext_modules = cythonize(\"*.pyx\") ) 分析 Cython 程序瓶颈 Cython 中类型声明非常重要，但是我们不加类型标注它依然是一个合法的Cython程序,所以自然而然地,我们会担心漏加类型声明.不过好在 Cython 提供了一个很好的工具,可以方便地检查 Cython 程序中哪里可能可以进一步优化. !cython -a helloworld.pyx 之后我们的文件夹下就会看到一个html文件,其中黄色的部分就是与python交互的部分,也就是性能瓶颈 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:22:43 "},"python性能优化/Cython纯净模式.html":{"url":"python性能优化/Cython纯净模式.html","title":"Cython纯净模式","keywords":"","body":"Cython纯净模式 所谓的纯净模式就是cython直接编译.py文件的模式. 在某些情况下,希望加速Python代码,而不会失去与Python解释器一起运行的能力.可以使用Cython编译纯Python脚本,但通常只能以20％-50％的速度增长. 为了超越此范围,Cython提供了语言结构,为Python模块添加静态类型和cythonic功能,使其在编译时运行得更快,同时仍然允许它被解释.有两种方案可以实现这一需求: 通过导入cython模块后使用其中的特殊功能和装饰器完成 通过扩展的.pxd文件 尽管通常不建议在.pyx文件中直接编写Cython代码,但更容易的测试,可以方便的与纯Python开发人员的协作等特点也为其提供了合理性. 在纯净python源文件下，你或多或少受限于在Python中的语法表达,如果希望跳过python语法,只能用具有扩展语言语法的.pyx文件完成,因为它依赖于Cython编译器的特性. cython可以使用cython.compiled来反射是否运行的是被编译的版本 .pxd文件中可以申明使用C/C++扩展,因此可以在.py文件中根据需要使用c/c++的编写的函数. 通过cython模块中的特殊功能和装饰器扩展 这种方式相比前面的使用pxd申明扩展的方式更加方便,所有这些特殊功能和装饰器都是非侵入式的,加上去掉都不会影响原本.py源代码在python解释器中的工作. 可用于申明的C类型 cython中常用的C语言类型有: cython中类型 类型说明 cython.int 整形 cython.long 长整形 cython.double 双精度浮点型 cython.char 字符型 其他的包括无符号整形之类的C语言中的基础类型也都有,这边不再复述. 另外一个特殊的类型就是指针,cython中指针类型就是基础类型前面加上p_,如整形数指针就是cython.p_int 常用的声明函数和装饰器有 不同于.pyx文件,.py文件需要符合python语法,因此很多申明和关键字需要使用函数或者类等对象来代替,纯净模式更多的是静态化参数以此来提高效率.下面是用于申明的函数和装饰器 cython.declare(**kws) 用于申明变量 cython.struct(**kws) 申明一个结构体 cython.union(**kws) 申明一个联合体 @cython.locals(**kws) 用于声明函数或者方法的参数和内部变量,即便是python方法也可以声明变量类型,这样静态化也可以获得提速 @cython.returns([cython_type]) 用于申明函数或者方法的参数和内部变量 @cython.ccall 申明可被python解释器调用的cython函数.相当于.pyx中的cpdef定义的函数或方法 @cython.cfunc 申明c/c++语言函数,这种函数会跳过运行时直接执行,而且隐藏在python解释器之下,只有模块中才可以调用 @cython.inline 申明函数为inline函数 常用的特殊函数 处理C语言函数时,我们很有可能需要使用一些关于内存指针的操作,这些操作python自己是没有的,因此Cython也提供一些这种特殊的函数 cython.address(x) 获取变量的指针地址 cython.sizeof(x) 获取变量的地址空间大小 cython.typedef(x) 用于获取一个给定指针名称下的变量类型的类型 cython.cast(T,x,typecheck=True) 用于将变量指定为某一类型,类似C/C++语言中的t.注意这个函数是不安全的,容易内存泄漏.可选参数typecheck=True相当于t 常用编译指示装饰器 @cython.boundscheck(bool) 用于设定是否进行边界检查,默认值为True。 @cython.wraparound(bool) 用于设定是否进行数组负索引检查,默认值为True。 @cython.initializedcheck(bool) 用于设定访问或分配内存视图时是否检查它是否被初始化.默认值为True。 @cython.overflowcheck 如果设置为True，当溢出的C整数算术运算上引发了异常时，会执行适度的运行时惩罚,但即便如此还是比python的int运算快很多,默认为False @cython.overflowcheck.fold 如果设置为True，并且overflowcheck为True，则检查嵌套的溢出位,和有副作用的算术表达式,而不是每个步骤都检查。 依赖于不同的编译器，体系结构和优化设置，这项选项可能有助于提高性能也可能损害性能。 默认值为True。 @cython.nonecheck 如果设置为False，Cython可以自由地假定 对变量类型的本地字段访问为扩展类型,或者 当变量被设为None时,对缓冲区变量的缓冲区访问永远不会发生。否则插入一个检查并引发适当的异常。 这些装饰器可以放在函数上标记好 常用的编译器指示注释 编译器可以识别在源文件开始部分的注释为全局的编译器指示,常见的有 #cython: language_level=3标记编译目标为python3 #cython: boundscheck = False设置全局不进行边界检查 编译器设置的参数可以在前面的Cython基本流程部分看到 %%writefile B.py #cython: language_level=3 import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") @cython.boundscheck(False) @cython.ccall @cython.returns(cython.int) @cython.locals(x=cython.int, y=cython.int,a = cython.int) def myfunction(x, y=2): a = x-y return a + x * y @cython.cfunc @cython.returns(cython.double) @cython.locals(a = cython.double) def _helper(a): return a + 1 @cython.cclass class A: cython.declare(a=cython.int, b=cython.int) def __init__(self, b=0): self.a = 3 self.b = b @cython.ccall @cython.locals(x=cython.double) def foo(self, x): print(x + _helper(1.0)) Overwriting B.py import B Just a lowly interpreted script. B.myfunction(10) 28 a = B.A() a.foo(2.7) 4.7 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"B.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling B.py because it changed. [1/1] Cythonizing B.py running build_ext building 'B' extension creating build creating build\\temp.win-amd64-3.6 creating build\\temp.win-amd64-3.6\\Release C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpB.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\B.obj B.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_B build\\temp.win-amd64-3.6\\Release\\B.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\B.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.lib B.obj : warning LNK4197: export 'PyInit_B' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\B.cp36-win_amd64.exp Generating code Finished generating code import B Yep, I'm compiled. B.myfunction(10) 28 a = B.A() a.foo(2.7) 4.7 !cython -a B.py cython纯净模式福利--类型自动转换 C 类型 从pyhton中获得 返回到python中 [unsigned] char, [unsigned] short, int, long int int unsigned int, unsigned long, [unsigned] long long int int float, double, long double int, float float char* bytes bytes struct, union --- dict 除此之外同构定长列表/元组可以与c中数组自动转化 import cython @cython.locals(counts=cython.int[10], digit=cython.int) def count_digits(digits): \"\"\" >>> digits = '01112222333334445667788899' >>> count_digits(map(int, digits)) [1, 3, 4, 5, 3, 1, 2, 2, 3, 2] \"\"\" counts = [0] * 10 for digit in digits: assert 0 纯python文件扩展的局限性 这种方式的缺点在于: 语法不优雅,堆叠3个装饰器来装饰一个函数看起来很不美观 默认无法使用type hint,测试结果看cython解释器无法支持type hint,这个特性会在后续的版本中改善 使用.pxd申明要用的C/C++函数 使用上面这种方式有个很大的缺陷就是无法使用C/C++写好的函数,要让这个可行需要有一个.pxd文件用于声明用到的函数,并将其包装为cpdef的形式 %%writefile C.py #cython: language_level=3 import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") from math import sin @cython.boundscheck(False) @cython.ccall @cython.returns(cython.int) @cython.locals(x=cython.int, y=cython.int,a = cython.int) def myfunction(x, y=2): a = x-y return a + x * y @cython.cfunc @cython.returns(cython.double) @cython.locals(a = cython.double) def _helper(a): return a + 1 @cython.returns(cython.double) @cython.locals(x=cython.double) def echo_sin(x): return sin(x) @cython.cclass class A: cython.declare(a=cython.int, b=cython.int) def __init__(self, b=0): self.a = 3 self.b = b @cython.ccall @cython.locals(x=cython.double) def foo(self, x): print(x + _helper(1.0)) Overwriting C.py %%writefile C.pxd #cython: language_level=3 cdef extern from \"math.h\": cpdef double sin(double x) Overwriting C.pxd import C Just a lowly interpreted script. %timeit C.echo_sin(3) The slowest run took 26.72 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 249 ns per loop %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"C.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling C.py because it changed. [1/1] Cythonizing C.py running build_ext building 'C' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpC.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\C.obj C.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_C build\\temp.win-amd64-3.6\\Release\\C.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\C.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.lib C.obj : warning LNK4197: export 'PyInit_C' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\C.cp36-win_amd64.exp Generating code Finished generating code import C Yep, I'm compiled. %timeit C.echo_sin(3) The slowest run took 51.80 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 134 ns per loop 将所有申明迁移至.pxd文件 像上面这种写法已经引入了一个新的文件,既然如此为什么不把申明用的这些个装饰器都移到.pxd文件中增加可读性呢 下面是一个纯python源文件 %%writefile A.py import cython if cython.compiled: print(\"Yep, I'm compiled.\") else: print(\"Just a lowly interpreted script.\") from math import sin def myfunction(x, y=2): a = x-y return a + x * y def echo_sin(x): return sin(x) def _helper(a): return a + 1 class A: def __init__(self, b=0): self.a = 3 self.b = b def foo(self, x): print(x + _helper(1.0)) Overwriting A.py import A Just a lowly interpreted script. A.myfunction(10) 28 %timeit A.echo_sin(2.7) The slowest run took 25.54 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 225 ns per loop 使用.pxd为其申明 %%writefile A.pxd #cython: language_level=3 cdef extern from \"math.h\": cpdef double sin(double x) cpdef int myfunction(int x, int y=*) cdef double _helper(double a) cdef class A: cdef public int a,b cpdef foo(self, double x) Overwriting A.pxd 那么Cython将会将A.py编译成如下： cdef extern from \"math.h\": cpdef double sin(double x) cpdef int myfunction(int x, int y=2): a = x-y return a + x * y def double echo_sin(double x): return sin(x) cdef double _helper(double a): return a + 1 cdef class A: cdef public int a,b def __init__(self, b=0): self.a = 3 self.b = b cpdef foo(self, double x): print x + _helper(1.0) 注意: 使用*通配符可以将Python的参数默认值包装给.pxd中的定义，即可以从Python访问 cpdef int myfunction(int x, int y=*) 内部函数的C函数签名可以声明为cdef cdef double _helper(double a) cdef class用于申明扩展类型 如果属性有读取/写入Python访问权限，则cdef类属性必须声明为cdef public，cdef readonly为只读Python访问，或者是纯Cdef为内部C级属性 cdef class 中方法必须声明为 cpdef Python可见方法 cdef用于内部C方法 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( cmdclass = {'build_ext': build_ext}, ext_modules = cythonize(\"A.py\",language=\"c++\") ) Overwriting setup.py !python setup.py build_ext --inplace Please put \"# distutils: language=c++\" in your .pyx or .pxd file(s) Compiling A.py because it changed. [1/1] Cythonizing A.py running build_ext building 'A' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpA.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\A.obj A.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_A build\\temp.win-amd64-3.6\\Release\\A.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython纯净模式\\A.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.lib A.obj : warning LNK4197: export 'PyInit_A' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\A.cp36-win_amd64.exp Generating code Finished generating code import A Yep, I'm compiled. A.myfunction(12) 34 %timeit A.echo_sin(2.7) The slowest run took 90.59 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 120 ns per loop 使用.pxd申明扩展纯python的局限性 使用.pxd扩展.py源文件的方式最大的缺点在于可维护性,一旦有改动那么无论.py和.pxd文件都得改动.而且因为使用cython语法定义.pxd文件,所以对于不会cython的用户很不友好. 另一局限性在于使用c/c++函数或者标准库时只能在.pxd文件下申明,因此必须在.py文件中判断是否被编译,而且必须实现一个同名的python对象来为纯python环境提供支持. 纯净模式的局限性 无论是否要使用.pxd申明文件,纯净模式都无法在实现上使用C++中STL容器和算法,也有很多cython语言特性无法实现. 展望 在python3.5发布后,cython社区也提出了使用type hint来申明cython纯净模式的提议-- Python Typing Proposal.而且cython分支目录下也已经有了相关的分支我想在之后的版本中这将称为cython的一个新语法.这样无疑会为纯净模式带来更多的便利 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:23:38 "},"python性能优化/Cython的基本模式.html":{"url":"python性能优化/Cython的基本模式.html","title":"Cython的基本模式","keywords":"","body":"使用.pyx改写python程序 在纯净模式中,我的代码实现手段很有限: 只能直接使用python模块和对象 无法使用c++的容器和算法 无法使用cimport %load_ext Cython %%cython # distutils: language=c++ from libcpp.vector cimport vector from libcpp.string cimport string #from libc.stdio cimport printf cpdef print_vect(string content): cdef vector[int] vect cdef int i for i in range(10): vect.push_back(i) for i in vect: #printf(\"%d\",vect[i]) print(vect[i]) for i in content: #printf(\"%d\",vect[i]) print(i) print_vect(\"黑龙江\".encode()) 0 1 2 3 4 5 6 7 8 9 -23 -69 -111 -23 -66 -103 -26 -79 -97 Cython语法 Cython是python的超集,所以python解释器无法解释cython代码,必须编译才可以. 静态化参数 Cython是一个Python编译器。这意味着它可以编译普通的Python代码，而不会有任何改变（除了一些尚未支持的语言功能之外，还有一些明显的例外）.然而，对于性能关键代码，添加静态类型声明通常是有帮助的，因为它们将允许Cython退出Python代码的动态特性，并生成更简单更快的C代码.但是，必须注意的是，类型声明会使源代码更加冗长，因而可读性更低.因此，不要在没有正当理由的情况下使用它们，例如基准测试证明他们在性能关键部分真正使代码更快速地使用它们是不鼓励的.通常在正确的地方有几种类型可以走很长的路.所有C类型都可用于类型声明:整数和浮点类型，复数，结构体，联合和指针类型. Cython可以在分配类型之间自动正确地进行转换.这也包括Python的任意大小的整数类型，其中转换为C类型的值溢出会在运行时引发Python OverflowError.(但是，在进行算术时，不会检查是否溢出).在这种情况下，生成的C代码将正确安全地处理C类型的依赖于平台的大小. 在python函数中使用c语言的类型指明翻译为C语言后的参数类型 由于这些参数被传递到Python声明的函数中，它们会转换为指定的C类型值.但这只适用于数字和字符串类型 %%cython def f(double x): return x**2-x def integrate_f(double a, double b, int N): cdef int i cdef double s, dx s = 0 dx = (b-a)/N for i in range(N): s += f(a+i*dx) return s * dx f(1.2) 0.24 C级别申明 作为一种动态语言，Python鼓励了一种根据方法和属性考虑类和对象的编程风格，而不仅仅局限于类层次结构中.这可以使Python成为一种非常轻松和舒适的语言，用于快速开发，但有一个代价 -- 管理数据类型的\"繁文缛节\"被转储到翻译器上.在运行时，解释器在搜索命名空间，获取属性和解析参数和关键字元组方面做了大量工作。与\"早期绑定\"语言（如C++）相比，这种运行时\"后期绑定\"是Python相对较慢的主要原因.然而使用Cython可以通过使用\"早期绑定\"编程技术获得显着的加速. cdef语句用于创建C级声明 申明变量 cdef int i, j, k cdef float f, g[42], *h 申明结构体 cdef struct Grail: int age float volume 申明联合体 cdef union Food: char *spam float *eggs 申明枚举 cdef enum CheeseType: cheddar, edam, camembert 申明函数 cdef int eggs(unsigned long l, float f): cdef关键字指定早期绑定,默认是私有的,只有在申明时指定public才会暴露 类型转换 在cython中使用yyy操作符来进行类型转换,其使用方式与C中类似. cdef char *p, float *q p = q 值得注意的是cython中python的bool类型会转化为bint,而python中的自定义类的实例则对应的object 类型检测 和C中类似,类型转换时使用yyy会先进行检测 字符串 C级别无论是字符数组还是c++的string,都只接收python的bytes作为转换来源.返回的也只会转换为bytes.因此需要注意. 函数,方法申明 Cython中有三种类型的函数声明. Python的可调用对象(def) 这种类型的函数特点: 使用def申明 可以被Python解释器调用 可以被Python对象调用 返回Python对象 参数可以静态化 C的可调用对象 (cdef) 这种类型的函数特点: 用cdef语句声明 无法在python解释器中访问 可以被Python对象或C值调用 内部变量必须申明 可以返回Python对象或C值 Python和C的可调用(cpdef) 这种类型的函数特点: 用cpdef语句声明. 可以从任何地方调用 当从其他Cython代码调用时,使用更快的C调用约定 cython的内置函数 Cython将对大多数内置函数的调用编译为对相应的Python / C API例程的直接调用,使它们特别快。 只有使用这些名称的直接函数调用已优化.如果你使用这些名称中的一个假设它是一个Python对象，例如将它分配给一个Python变量，然后调用它，那么该调用将作为一个Python函数调用. 内置函数 返回类型 相当于Python/C API中的类型 abs(obj) object, double, ... PyNumber_Absolute, fabs, fabsf, ... callable(obj) bint PyObject_Callable delattr(obj, name) None PyObject_DelAttr exec(code, [glob, [loc]]) object dir(obj) list PyObject_Dir divmod(a, b) tuple PyNumber_Divmod getattr(obj, name, [default]) object PyObject_GetAttr hasattr(obj, name) bint PyObject_HasAttr hash(obj) int / long PyObject_Hash intern(obj) object Py*_InternFromString isinstance(obj, type) bint PyObject_IsInstance issubclass(obj, type) bint PyObject_IsSubclass iter(obj, [sentinel]) object PyObject_GetIter len(obj) Py_ssize_t PyObject_Length pow(x, y, [z]) object PyNumber_Power reload(obj) object PyImport_ReloadModule repr(obj) object PyObject_Repr setattr(obj, name) void PyObject_SetAttr 类申明(扩展类型) cython扩展类型可以使用cdef class来定义. 属性 其中的元素可以使用cdef来定义,默认是私有的,但可以使用public或者readonly关键字指定其封装形式. %%cython cdef class Rectangle: cdef public int x0 cdef readonly int y0 cdef int x1, y1 def __init__(self, int x0, int y0, int x1, int y1): self.x0 = x0; self.y0 = y0; self.x1 = x1; self.y1 = y1 cdef int _area(self): cdef int area area = (self.x1 - self.x0) * (self.y1 - self.y0) if area r = Rectangle(1, 2, 3, 1) r.x0 1 r.y0 2 r.x1 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r.x1 AttributeError: '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rec' object has no attribute 'x1' r.x0=2 r.x0 2 r.y0 = 4 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r.y0 = 4 AttributeError: attribute 'y0' of '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rectangle' objects is not writable r.area() 1 r._area() --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () ----> 1 r._area() AttributeError: '_cython_magic_31443cea76eb5b8780ecd933e92cc406.Rec' object has no attribute '_area' 特性 cython特性除了一般python语句一样的装饰器语法外,还可以使用如下特殊定义方式,两者效果一致. cdef class Spam: property cheese: \"A doc string can go here.\" def __get__(self): # This is called when the property is read. ... def __set__(self, value): # This is called when the property is written. ... def __del__(self): # This is called when the property is deleted. __get__()，__set__()和__del__()方法都是可选的.如果省略，属性访问会引发异常. 不推荐这种写法,因为看起来和python差别太大 %%cython cdef class CheeseShop: cdef object cheeses def __cinit__(self): self.cheeses = [] property cheese: # note that this syntax is deprecated def __get__(self): return \"We don't have: %s\" % self.cheeses def __set__(self, value): self.cheeses.append(value) def __del__(self): del self.cheeses[:] shop = CheeseShop() print(shop.cheese) shop.cheese = \"camembert\" print(shop.cheese) shop.cheese = \"cheddar\" print(shop.cheese) del shop.cheese print(shop.cheese) We don't have: [] We don't have: ['camembert'] We don't have: ['camembert', 'cheddar'] We don't have: [] 方法 Rectangle中_area是C级别的函数,不可被访问,所以需要使用area方法来封装.不过通常是使用cpdef直接实现的 %%cython cdef class Rectangle: cdef int x0, y0 cdef int x1, y1 def __init__(self, int x0, int y0, int x1, int y1): self.x0 = x0; self.y0 = y0; self.x1 = x1; self.y1 = y1 cpdef int area(self): cdef int area area = (self.x1 - self.x0) * (self.y1 - self.y0) if area r = Rectangle(1, 2, 3, 1) 方法重载 在扩展类型中同一申明方式的可以相互重载,而不同申明方式的则有一套优先级: cpdef可以重载cdef,而反过来就不行 def可以重载cpdef,而反过来就不行 %%cython cdef class A: cdef foo(self): print(\"A\") cdef class AA(A): cdef foo(self): print(\"AA\") cpdef bar(self): self.foo() AA().bar() AA %%cython cdef class A: cdef foo(self): print(\"A\") cdef class B(A): cpdef foo(self, x=None): print(\"B\", x) class C(B): def foo(self, x=True, int k=3): print(\"C\", x, k) B(12).foo() B None C().foo() C True 3 继承 基类的完整定义必须可用于Cython，因此如果基类是内置类型，它必须先前已声明为extern扩展类型.如果基类型在另一个Cython模块中定义，则必须声明为extern扩展类型或使用cimport语句导入. 一个扩展类型只能有一个基类(cython的扩展类不支持多重继承).但可以被python类继承,这种继承支持多继承. 有一种方法可以防止扩展类型在Python中被子类化.这是通过final指令完成的，通常使用装饰器在扩展类型上设置 cimport cython @cython.final cdef class Parrot: def done(self): pass 扩展类型快速实例化 Cython提供了两种方法来加速扩展类型的实例化. 第一个是直接调用__new__()特殊静态方法，如从Python中所知。对于例子扩展类型Penguin，可以使用以下代码： %%cython cdef class Penguin: cdef public object food def __cinit__(self, food): self.food = food def __init__(self, food): print(\"eating!\") normal_penguin = Penguin('fish') eating! normal_penguin.food 'fish' fast_penguin = Penguin.__new__(Penguin, 'wheat') fast_penguin.food 'wheat' __new__()实例化的对象会不运行__init__()只会运行__cinit__() 第二个性能改进适用于经常在一行中创建和删除的类型，以便他们可以从freelist中受益. Cython为此提供了装饰器@cython.freelist(N)，它为给定类型创建了一个静态大小的N个实例的freelist.例： %%cython cimport cython @cython.freelist(8) cdef class Penguin: cdef object food def __cinit__(self, food): self.food = food penguin = Penguin('fish 1') penguin = None penguin = Penguin('fish 2') 特殊方法 cython也支持特殊方法,它支持的特殊方法可在这里看到 扩展类型的特殊方法必须用def，而不是cdef声明,这不会影响他们的性能 -- Python使用不同的调用约定来调用这些特殊方法. 这边列举几个比较中要的: 初始化方法：__cinit__() 和__init__() 有两种方法与初始化对象有关. __cinit__() 方法是应该执行对象的基本C级初始化，包括对象将拥有的任何C数据结构的分配.你需要小心你在__cinit__()方法中做什么，因为对象可能还不是完全有效的Python对象.因此，你应该小心调用任何Python可能触摸对象的操作,特别是其方法. 在调用__cinit__()方法时，已经为对象分配了内存，并且任何C属性已初始化为0或null。(任何Python属性也被初始化为None，但是你可能不应该依赖它.)你的__cinit__()方法一定只会被调用一次. 如果扩展类型有基类，那么在调用__cinit __()方法之前，将自动调用基类的__cinit__()方法,你不能显式调用基类的__cinit__()方法。如果需要将修改的参数列表传递给基类,则必须在__init__()方法中执行初始化的相关部分(其中调用继承方法的正常规则适用). __init__() 在__cinit__()方法中不能安全完成的任何初始化都应该在__init__()方法中完成.当调用__init __()时，对象是一个完全有效的Python对象，所有操作都是安全的.在某些情况下,__init__()可能被多次调用或根本不被调用. 传递给构造函数的任何参数都将传递给__cinit __()方法和__init__()方法。如果你预计在Python中继承扩展类型,可能会将参数以*和**参数的形式传给__cinit__()方法，以便它可以接受和忽略额外的参数.否则，任何具有带有不同签名的__init __()的Python子类都必须覆盖__new __()以及__init __()，明显这样很不友好.或者，为了方便起见，如果你声明你的__cinit__()方法没有参数(除了self)，它将简单地忽略传递给构造函数的任何额外的参数.这种方式可能更加保险. 析构方法：__dealloc__() 与__cinit__()方法的逆向方法是__dealloc__()方法。__cinit__()方法中显式分配内存的任何C数据(例如通过malloc分配的空间)应在__dealloc__()方法中释放.你需要小心你在__dealloc __()方法中的操作.在调用__dealloc__()方法时，对象可能已经被部分销毁，并且对于Python而言可能不处于有效状态，如果你坚持只是释放C数据是最好的选择. 你不需要担心释放对象的Python属性，因为在__dealloc __()方法返回后，它将由Cython完成. 当子类化扩展类型时,请注意，超类的__dealloc__()方法将始终被调用，即使它被覆盖.这与典型的Python行为不同. 注意： 扩展类型没有__del__()方法。 逻辑运算方法 算术运算符方法(如__add__())的行为与Python对应方法不同。这些方法没有单独的“反转”版本(__radd __()等).相反，如果第一个操作数不能执行操作，则调用第二个操作数的相同方法，操作数的顺序相同. 运算比较操作 对于不同的比较操作(__eq__()，__le__()等等)Cython没有单独的方法.而是有一个方法__richcmp __()，它接受一个整数，指示要执行哪种操作，如下所示: 操作 指示 0 == 2 > 4 1 != 3 >= 5 错误处理 如果你不做任何特殊的事情，用cdef声明的函数不返回任何Python对象，这样这个cdef函数就没有办法向其调用者报告其Python异常.如果在此类函数中检测到异常，则会打印一条警告消息，并忽略该异常. 如果你想要一个不返回Python对象的C函数能够将异常传播给它的调用者，你需要声明一个异常值。这里是一个例子： cdef int spam() except -1: ... 使用此声明，每当spam()函数内发生异常时，它将立即返回值-1.此外，每当对spam()的调用返回-1时，将假定异常已经发生并将被传播. 当为函数声明异常值时，不应显式或隐式返回该值.特别是，如果异常返回值是一个False值，那么你应该确保函数永远不会通过隐式或空返回终止. 如果所有可能的返回值都是合法的，并且你不能完全保留一个用于信号错误，则可以使用异常值声明的替代形式： cdef int spam() except? -1: ... '?'号表示-1是个异常值，在这种情况下，Cython通过生成一个函数PyErr_Occurred()进行返回，从而知道该函数发生了异常值. 还有第三种定义方式： cdef int spam() except *: ... 这种形式导致Cython在每次调用spam()后生成对PyErr_Occurred()的调用，而不管它返回什么值。如果你有一个函数返回void需要传播错误，你将不得不使用这种形式，因为没有任何返回值来测试.否则这种形式的定义应该尽量少用. 需要注意的是： 异常值只能为返回 整数， 枚举， 浮点 指针类型的函数声明. 并且该值必须是常量表达式。 void函数只能使用except *形式. 异常值规范是函数签名的一部分。如果将指针作为参数传递给函数或将其指定给变量，则声明的参数或变量的类型必须具有相同的异常值规范(或缺少).下面是一个具有异常值的指针到函数声明的示例： int (*grail)(int, char*) except -1 模块导入 cython中的导入方式有3种: python的import 用于导入python模块,一般只在实现文件中导入 cython的cimport 用于导入cpython中.pxd文件中申明的内容和一些cpython封装好的标准模块,可以在申明文件或者实现文件中导入 cython的include include语句用于导入.pxi文件.这种语法类似C/C++中的#include,是直接将目标文件内容复制到当前位置 使用C++的stl和C标准库 大多数C++标准库的容器已在位于/Cython /Includes/libcpp的pxd文件中声明.这些容器是： deque 双向队列 list 列表 map 映射 pair 对 queue 队列 set集合 stack栈 vector 向量 这些容器的使用方法可以看C++的stl部分. 因此现在想用这些容器只需简单的cimport进来即可 %%cython # distutils: language = c++ from libcpp.vector cimport vector cdef vector[int] vect cdef int i for i in range(10): vect.push_back(i) for i in range(10): print(vect[i]) 0 1 2 3 4 5 6 7 8 9 现在在Cython中STL容器会从相应的Python内建类型中强制转换。转换通过对类型化变量（包括类型化函数参数）的赋值或显式转换触发，例如： %%cython # distutils: language = c++ from libcpp.string cimport string from libcpp.vector cimport vector cdef string s = b'py_bytes_object' print(s) cpp_string = 'py_unicode_object'.encode('utf-8') cdef vector[int] vect = xrange(1, 10, 2) print(vect) # [1, 3, 5, 7, 9] cdef vector[string] cpp_strings = b'ab cd ef gh'.split() print(cpp_strings[1]) # b'cd' b'py_bytes_object' [1, 3, 5, 7, 9] b'cd' 以下强制可用： Python type => C++ type => Python type bytes std::string bytes iterable std::vector list iterable std::list list iterable std::set set iterable (len 2) std::pair tuple (len 2) 所有转换都会创建一个新的容器并将数据复制到该容器中.容器中的项目会自动转换为相应的类型,包括递归转换容器内的容器,例如字符串map转换为vector. 支持在stl容器(或实际上任何类与begin()和end()方法返回支持递增,取消引用和比较的对象)通过for语法支持.包括列表解析.例如如下代码: %%cython # distutils: language = c++ from libcpp.vector cimport vector cdef func(value): return value**2 cdef vector[int] v = [1,2,3,4,5,6,7,8] for value in v: print(func(value)) y = [x*x for x in v if x % 2 == 0] 1 4 9 16 25 36 49 64 y [4, 16, 36, 64] Cython中的array Python有一个内置1维数组的原始类型的动态数组模块.可以从Cython中访问Python数组的底层C数组.同时,它们是普通的Python对象，可以存储在列表中并在多进程之间进行序列化. 与malloc()和free()的手动控制内存方法相比，这提供了对Python的安全和自动内存管理，与Numpy数组相比,无需安装依赖关系,因为数组模块内置于cPython和cython中. 使用内存视图的安全使用方式 注意：cython中需要同时导入cython级别的数组和常规Python数组对象引入到命名空间中. 当一个Python数组被分配给一个类型为内存视图的变量时，构造内存视图将会有一些微小的开销.但是,从这个角度来看,变量可以传递给其他函数而不需要开销,只要它被输入: %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef int[:] ca = a print(ca[0]) 1 %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef int[:] ca = a cdef int overhead(object a): cdef int[:] ca = a return ca[0] cdef int no_overhead(int[:] ca): return ca[0] print(overhead(a)) # new memory view will be constructed, overhead print(no_overhead(ca)) # ca is already a memory view, so no overhead 1 1 零开销，不安全访问原始C指针 为了避免任何开销，并且能够将C指针传递给其他函数，可以以底层的连续数组作为指针.没有类型或边界检查,所以要小心使用正确的类型和签名. 请注意,数组对象上的任何长度变化操作都可能使指针无效. %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) # access underlying pointer: print(a.data.as_ints[0]) from libc.string cimport memset memset(a.data.as_voidptr, 0, len(a) * sizeof(int)) 1 克隆，扩展数组 为避免使用Python模块中的数组构造函数，可以创建与模板类型相同的新数组,并预先分配给定数量的元素.数组在请求时初始化为零. %%cython from cpython cimport array import array cdef array.array int_array_template = array.array('i', []) cdef array.array newarray # create an array with 3 elements with same type as template newarray = array.clone(int_array_template, 3, zero=False) 一个数组也可以被扩展和调整大小;这避免了重复的内存重新分配,如果元素被逐个附加或删除,则会发生这种重新分配. %%cython from cpython cimport array import array cdef array.array a = array.array('i', [1, 2, 3]) cdef array.array b = array.array('i', [4, 5, 6]) # extend a with b, resize as needed array.extend(a, b) # resize a, leaving just original three elements array.resize(a, len(a) - len(b)) 相关接口 将内容强制转换 data.as_voidptr data.as_chars data.as_schars data.as_uchars data.as_shorts data.as_ushorts data.as_ints data.as_uints data.as_longs data.as_ulongs data.as_longlongs # requires Python >=3 data.as_ulonglongs # requires Python >=3 data.as_floats data.as_doubles data.as_pyunicodes 操作的相关函数 int resize(array self, Py_ssize_t n) except -1 快速调整大小/ realloc.不适合重复，小增量;将底层数组调整到正确的请求量. int resize_smart(array self, Py_ssize_t n) except -1 小增量更加有效;使用提供摊销线性时间附加的增长模式. cdef inline array clone(array template, Py_ssize_t length, bint zero) 给定一个模板数组，快速创建一个新数组.类型将与模板相同.如果为零,则将使用零初始化新数组. cdef inline array copy(array self) 复制一个数组 cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1 对相同类型的新数据(例如，相同数组类型),高效附加n个元素数量的长度 cdef inline int extend(array self, array other) except -1 使用另一个数组的数据扩展数组;类型必须匹配。 cdef inline void zero(array self) 将数组内容全部置0 Memoryviews内存视图 类型化的内存视图可以有效地访问内存缓冲区,例如NumPy数据库中的缓冲区,而不会导致任何Python开销. Memoryview类似于当前的NumPy数组缓冲区支持(np.ndarray [np.float64_t，ndim = 2]),但它们具有更多的功能和更清晰的语法.内存访问比旧的NumPy数组缓冲区支持更通用,因为它们可以处理更多种类的数组数据源.例如,他们可以处理C数组和Cython数组类型(Cython数组).可以在任何上下文(函数参数，模块级，cdef类属性等)中使用内存视图,并且可以从几乎任何通过PEP 3118缓冲区接口暴露可写缓冲区的对象获得. 如果习惯使用NumPy，以下示例应该让您开始使用Cython内存视图. %%cython from cython.view cimport array as cvarray import numpy as np # Memoryview on a NumPy array narr = np.arange(27, dtype=np.dtype(\"i\")).reshape((3, 3, 3)) cdef int [:, :, :] narr_view = narr # Memoryview on a C array cdef int carr[3][3][3] cdef int [:, :, :] carr_view = carr # Memoryview on a Cython array cyarr = cvarray(shape=(3, 3, 3), itemsize=sizeof(int), format=\"i\") cdef int [:, :, :] cyarr_view = cyarr # Show the sum of all the arrays before altering it print(\"NumPy sum of the NumPy array before assignments: %s\" % narr.sum()) # We can copy the values from one memoryview into another using a single # statement, by either indexing with ... or (NumPy-style) with a colon. carr_view[...] = narr_view cyarr_view[:] = narr_view # NumPy-style syntax for assigning a single value to all elements. narr_view[:, :, :] = 3 # Just to distinguish the arrays carr_view[0, 0, 0] = 100 cyarr_view[0, 0, 0] = 1000 # Assigning into the memoryview on the NumPy array alters the latter print(\"NumPy sum of NumPy array after assignments: %s\" % narr.sum()) # A function using a memoryview does not usually need the GIL cpdef int sum3d(int[:, :, :] arr) nogil: cdef size_t i, j, k cdef int total = 0 I = arr.shape[0] J = arr.shape[1] K = arr.shape[2] for i in range(I): for j in range(J): for k in range(K): total += arr[i, j, k] return total # A function accepting a memoryview knows how to use a NumPy array, # a C array, a Cython array... print(\"Memoryview sum of NumPy array is %s\" % sum3d(narr)) print(\"Memoryview sum of C array is %s\" % sum3d(carr)) print(\"Memoryview sum of Cython array is %s\" % sum3d(cyarr)) # ... and of course, a memoryview. print(\"Memoryview sum of C memoryview is %s\" % sum3d(carr_view)) NumPy sum of the NumPy array before assignments: 351 NumPy sum of NumPy array after assignments: 81 Memoryview sum of NumPy array is 81 Memoryview sum of C array is 451 Memoryview sum of Cython array is 1351 Memoryview sum of C memoryview is 451 基本语法 内存视图使用Python切片语法，与NumPy类似。要在一维int缓冲区上创建一个完整的视图： 一维视图: cdef int[:] view1D = exporting_object 三维视图: cdef int[:,:,:] view3D = exporting_object 2D视图将缓冲区的第一维度限制为从第二个(索引1)开始的100行，然后每秒(奇数)行跳过： cdef int[1:102:2,:] partial_view = exporting_object 这也可以方便地作为函数参数 def process_3d_buffer(int[1:102:2,:] view not None): ... 该参数的not None声明自动拒绝无值作为输入,否则将允许.默认情况下允许None的原因是它方便地用于返回参数: def process_buffer(int[:,:] input not None, int[:,:] output = None): if output is None: output = ... # e.g. numpy.empty_like(input) # process 'input' into 'output' return output Cython将自动拒绝不兼容的缓冲区，例如将三维缓冲区传递到需要二维缓冲区的函数将引发ValueError。 索引 在Cython中，内存视图上的索引访问将自动转换为内存地址。以下代码向其中请求一个二维内存视图的C类型的项目和索引： cdef int[:,:] buf = exporting_object print(buf[1,2]) 负指数也从各自的维度结束起计算： print(buf[-1,-2]) 以下函数循环遍历2D数组的每个维度，并为每个项添加1： def add_one(int[:,:] buf): for x in xrange(buf.shape[0]): for y in xrange(buf.shape[1]): buf[x,y] += 1 可以使用或不使用GIL进行索引和切片。它基本上像NumPy一样工作.如果为每个维指定了索引，您将获得基本类型的元素(例如int).否则将获得一个新的视图.省略号意味着可以为每个未指定维度获得连续的切片： cdef int[:, :, :] my_view = exporting_object # These are all equivalent my_view[10] my_view[10, :, :] my_view[10, ...] 复制 内存视图可以复制 cdef int[:, :, :] to_view, from_view ... # copy the elements in from_view to to_view to_view[...] = from_view # or to_view[:] = from_view # or to_view[:, :, :] = from_view 它们也可以用copy（）和copy_fortran（）方法复制 转置 在大多数情况下内存视图可以以与NumPy切片相同的方式进行转置： cdef int [:, :: 1] c_contig = ... cdef int [:: 1，：] f_contig = c_contig.T 这一操作会给出一个新的，转置过的数据视图。调换要求存储器视图的所有维度都具有直接访问存储器布局(即，通过指针不存在任何指令). 内存视图与数组 这些类型对象的内存视图可以转换为Python memoryview对象(cython.view.memoryview).这些Python对象是可索引的，可切片的并且以与原始内存访问相同的方式进行转座。它们也可以随时转换回Cython-space memoryviews. 它们具有以下属性： shape: size in each dimension, as a tuple. strides: stride along each dimension, in bytes. suboffsets ndim: number of dimensions. size: total number of items in the view (product of the shape). itemsize: size, in bytes, of the items in the view. nbytes: equal to size times itemsize. base T 当然还有上述的T属性（Transpose）。这些属性具有与NumPy相同的语义.例如，要检索原始对象： %%cython import numpy cimport numpy as cnp cdef cnp.int32_t[:] a = numpy.arange(10, dtype=numpy.int32) a = a[::2] print(a) print(numpy.asarray(a)) print(a.base) [0 2 4 6 8] [0 1 2 3 4 5 6 7 8 9] 请注意，此示例返回从中获取视图的原始对象，同时视图已被重新生成. 每当复制Cython内存视图（使用任何copy或copy_fortran方法）时，都会获得新创建的cython.view.array对象的新内存视图.这个数组也可以手动使用,并会自动分配一个数据块.它可以随后被分配给C或Fortran连续片(或跨片).它可以像下面: from cython cimport view my_array = view.array(shape=(10, 2), itemsize=sizeof(int), format=\"i\") cdef int[:, :] my_slice = my_array 它还需要一个可选的参数模式（'c'或'fortran'）和一个布尔的allocate_buffer，它指示当超出范围时是否应该分配和释放缓冲区： cdef view.array my_array = view.array(..., mode=\"fortran\", allocate_buffer=False) my_array.data = my_data_pointer # define a function that can deallocate the data (if needed) my_array.callback_free_data = free 还可以将数组的指针或C数组转换为数组： cdef view.array my_array = my_data_pointer cdef view.array my_array = my_c_array 当然，也可以立即将cython.view.array指定给类型化的内存视图切片.可以将C数组直接分配给内存视图切片： cdef int[:, ::1] myslice = my_2d_c_array 数组可以像Python空间一样可索引和可切换，就像memoryview对象一样，并且具有与memoryview对象相同的属性. cython.view.array的替代方法是Python标准库中的数组模块。在Python 3中，array.array类型本身支持缓冲区接口，所以在没有额外的设置的情况下，memoryviews就可以工作. %%cython cimport cpython.array def sum_array(int[:] view): \"\"\" >>> from array import array >>> sum_array( array('i', [1,2,3]) ) 6 \"\"\" cdef int total for i in range(view.shape[0]): total += view[i] return total 请注意，cimport还为阵列类型启用旧的缓冲区语法.因此,以下内容也起作用: from cpython cimport array def sum_array(array.array[int] arr): # using old buffer syntax 内存控制 动态内存分配大多时候在Python中不是一个问题.一切都是一个对象,引用计数系统和垃圾收集器会在不再使用系统时自动返回内存.当涉及到更低级别的数据缓冲区时,Cython通过NumPy,内存视图或Python的stdlib数组类型,为简单类型的(多维)数组提供了特殊的支持.它们是全功能,带垃圾收集,比C中的裸指针更容易工作;同时仍然保持速度和静态类型的好处.然而,在某些情况下,这些对象仍然会产生不可接受的开销,从而可以在C中进行手动内存管理. 简单的C语言值和结构(例如局部变量cdef double x)通常分配在堆栈上并通过值传递.但是对于较大和更复杂的对象(例如动态大小的双精度列表),必须手动请求内存并发布. C为此提供了malloc()，realloc()和free()的功能，可以从clibc.stdlib导入cython.他们的签名是： void* malloc(size_t size) void* realloc(void* ptr, size_t size) void free(void* ptr) 下面是一个简单的例子: %%cython import random from libc.stdlib cimport malloc, free def random_noise(int number=1): cdef int i # allocate number * sizeof(double) bytes of memory cdef double *my_array = malloc(number * sizeof(double)) if not my_array: raise MemoryError() try: ran = random.normalvariate for i in range(number): my_array[i] = ran(0,1) return [ my_array[i] for i in range(number) ] finally: # return the previously allocated memory to the system free(my_array) random_noise(10) [-1.6609585787562682, 0.2930416975778874, 1.0867854313042287, 0.4215754219750379, -0.020794290445162556, -0.9283056817997914, 1.1385359763229776, -0.6051526240377219, -0.6630213916869704, -0.14696302042299017] 请注意，在Python堆上分配内存的C-API函数通常比上面的低级C函数更为优先,因为它们提供的内存实际上是在Python的内部存储器管理系统中解决的.它们还对较小的内存块进行了特殊优化,从而通过避免昂贵的操作系统调用来加快其分配. C-API函数可以在cpython.mem标准声明文件中找到： from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free 它们的接口和用法与相应的低级C函数的接口和用法相同. 需要记住的一个重要的事情是,使用malloc()或PyMem_Malloc()获取的内存块必须在不再使用时对其调用free()或PyMem_Free()进行手动释放(并且必须始终使用匹配类型的自由功能).否则，直到python进程退出才会被回收.这被称为内存泄漏. 如果一块内存需要比可以由try...finally块管理的更长的生命周期，另一个有用的习惯是将其生命周期与Python对象相结合，以利用Python运行时的内存管理，例如： %%cython from cpython.mem cimport PyMem_Malloc, PyMem_Realloc, PyMem_Free cdef class SomeMemory: cdef double* data def __cinit__(self, size_t number): # allocate some memory (uninitialised, may contain arbitrary data) self.data = PyMem_Malloc(number * sizeof(double)) if not self.data: raise MemoryError() def resize(self, size_t new_number): # Allocates new_number * sizeof(double) bytes, # preserving the current content and making a best-effort to # re-use the original data location. mem = PyMem_Realloc(self.data, new_number * sizeof(double)) if not mem: raise MemoryError() # Only overwrite the pointer if the memory was really reallocated. # On error (mem is NULL), the originally memory has not been freed. self.data = mem def __dealloc__(self): PyMem_Free(self.data) # no-op if self.data is NULL 去除gil限制 Cython提供了解除和使用全局锁（GIL）的设施。当从多线程代码调用（外部C）代码可能会阻止或希望从（本地）C线程回调使用Python时，这可能很有用.显然，释放GIL应该只对线程安全的代码或使用其他防止种族条件和并发问题的保护措施的代码进行.注意，获取GIL是一个阻塞线程同步操作，因此是潜在的昂贵开销。可能不值得发布GIL进行微小的计算。通常，并行代码中的I / O操作和实质性计算将从中受益. 释放GIL 可以使用nogil语句释放GIL周围的一段代码： with nogil: 在语句正文中的代码不得以任何方式引发异常或操纵Python对象，并且不得先调用任何操作Python对象的操作，从而无需先重新获取GIL.例如，Cython在编译时验证这些操作，但不能查看外部C函数.它们必须被正确声明为要求或不要求GIL（见下文），以使Cython的检查生效. 获得GIL 要用作没有GIL执行的C代码的回调的C函数需要在操作Python对象之前获取GIL。这可以通过在函数头中指定gil来完成： cdef void my_callback(void *data) with gil: ... 如果可以从另一个非Python线程调用回调函数，则必须首先通过调用PyEval_InitThreads()来初始化GIL。如果你已经在你的模块中使用cython.parallel，这个已经被照顾了.GIL也可以通过gil语句获得： with gil: 声明一个可调用的不受gil限制的的函数 您可以在C函数头或函数类型中指定nogil，以声明在没有GIL的情况下可以安全地调用： cdef void my_gil_free_func(int spam) nogil: ... 当您在Cython中实现这样的函数时，它不能有任何Python参数或Python对象返回类型.此外,涉及Python对象(包括调用Python函数)的任何操作必须首先明确获取GIL,例如:通过使用gil块或调用已经用gil定义的函数.这些限制由Cython检查,如果在nogil代码部分找到任何Python交互,您将收到编译错误. 注意nogil函数注释声明在没有GIL的情况下调用该函数是安全的.完全可以在持有GIL的同时执行它.如果调用者持有该功能,本身并不释放GIL. 用gil来声明一个函数（即获取输入的GIL）也隐含地使它的签名nogil. 并行编程(使用openmp) Cython通过cython.parallel模块支持本机并行.要使用这种并行性,必须释放GIL（请参阅释放GIL）.它目前支持OpenMP，但后来可能会支持更多后端. cython.parallel.prange([start,] stop[, step][, nogil=False][, schedule=None[, chunksize=None]][, num_threads=None]) 此功能可用于并行循环.OpenMP自动启动一个线程池，并根据所使用的时间表分配工作.步骤不能为0.此功能只能与GIL一起使用.如果nogil为真，则循环将包裹在nogil部分。针对变量自动推断线程位置和裁减。如果您分配给一个prange块中的变量，它将变为lastprivate，这意味着该变量将包含上一次迭代中的值。如果在一个变量上使用一个inplace操作符，那么它会减少，这意味着该变量的线程本地副本的值将随着操作符而减少，并在循环后分配给原始变量。索引变量始终为lastprivate.与块并行分配的变量将在块之后是私有的和不可用的，因为没有连续的最后一个值的概念. schedule参数会传递给OpenMP，可以是以下之一： static静态的：如果提供了一个chunksize，迭代将在给定的chunksize块中提前分发给所有线程。如果没有给出chunksize，则迭代空间被分成大小相等的块，并且至多一个块预先分配给每个线程。当调度开销重要时，这是最合适的，并且可以将问题减少到已知具有大致相同运行时的大小相同的块. dynamic动态的:迭代被分发给线程，因为它们请求它们，默认块大小为1.当每个块的运行时间不同而不是预先知道时，这是适用的，因此使用较大数量的较小块来保持所有线程忙. guided有指导的:与动态调度一样,迭代被分配给线程,因为它们请求它们,但是随着块大小的减小.每个块的大小与未分配迭代次数除以参与线程数减少到1(或者提供的chunksize)成比例.这已超过纯动态调度的优势,事实证明,当最后一个块需要比预期或以其他方式被严重计划更多的时间,使大部分线程开始运行闲置而最后块正在只有线程数量较少的制作. runtime运行时的：调度和块大小取自运行时调度变量，可以通过openmp.omp_set_schedule()函数调用或OMP_SCHEDULE环境变量进行设置.请注意,这基本上禁用了调度代码本身的任何静态编译时间优化，因此可能会显示比在编译时静态配置相同调度策略时更差的性能. cython.parallel.threadid() 返回线程的ID。对于n个线程，ids的范围为0到n-1 cython.parallel.parallel(num_threads=None) 该指令可以作为with语句的一部分，并行执行代码序列.这对于设置由prange使用的线程本地缓冲区目前是有用的.一个包含的prange将是一个并行的工作共享循环，因此在并行部分中分配的任何变量对于prange也是私有的.并行块中私有的变量在并行块之后不可用. %%writefile testomp.pyx from cython.parallel import prange import numpy as np cimport numpy as np from math import exp from libc.math cimport exp as c_exp def array_f(X): Y = np.zeros(X.shape) index = X > 0.5 Y[index] = np.exp(X[index]) return Y def c_array_f(double[:] X): cdef int N = X.shape[0] cdef double[:] Y = np.zeros(N) cdef int i for i in range(N): if X[i] > 0.5: Y[i] = c_exp(X[i]) else: Y[i] = 0 return Y def c_array_f_multi(double[:] X): cdef int N = X.shape[0] cdef double[:] Y = np.zeros(N) cdef int i for i in prange(N, nogil=True): if X[i] > 0.5: Y[i] = c_exp(X[i]) else: Y[i] = 0 return Y Overwriting testomp.pyx %%writefile setup.py from distutils.core import setup from distutils.extension import Extension from Cython.Build import cythonize import numpy ext_modules = [ Extension( \"testomp\", [\"testomp.pyx\"], #extra_compile_args=['-fopenmp'], #extra_link_args=['-fopenmp'], include_dirs=[numpy.get_include()], extra_compile_args=['/openmp'], extra_link_args=['-/openmp'], ) ] setup( name='hello-parallel-world', ext_modules=cythonize(ext_modules), ) Overwriting setup.py ! python setup.py build_ext --inplace Compiling testomp.pyx because it changed. [1/1] Cythonizing testomp.pyx running build_ext building 'testomp' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /Tctestomp.c /Fobuild\\temp.win-amd64-3.6\\Release\\testomp.obj /openmp testomp.c c:\\users\\87\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h(12) : Warning Msg: Using deprecated NumPy API, disable it by #defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION testomp.c(2411): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data testomp.c(2675): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data testomp.c(2660): warning C4101: '__pyx_t_10': unreferenced local variable testomp.c(2663): warning C4101: '__pyx_t_13': unreferenced local variable testomp.c(2664): warning C4101: '__pyx_t_14': unreferenced local variable testomp.c(2661): warning C4101: '__pyx_t_11': unreferenced local variable testomp.c(2662): warning C4101: '__pyx_t_12': unreferenced local variable testomp.c(2665): warning C4101: '__pyx_t_15': unreferenced local variable testomp.c(21358): warning C4244: 'initializing': conversion from 'double' to 'float', possible loss of data testomp.c(21364): warning C4244: 'initializing': conversion from 'double' to 'float', possible loss of data C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_testomp build\\temp.win-amd64-3.6\\Release\\testomp.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的基本模式\\testomp.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.lib -/openmp LINK : warning LNK4044: unrecognized option '//openmp'; ignored testomp.obj : warning LNK4197: export 'PyInit_testomp' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\testomp.cp36-win_amd64.exp Generating code Finished generating code warning: testomp.pyx:37:12: Use boundscheck(False) for faster access warning: testomp.pyx:38:13: Use boundscheck(False) for faster access warning: testomp.pyx:38:26: Use boundscheck(False) for faster access warning: testomp.pyx:40:13: Use boundscheck(False) for faster access from testomp import c_array_f_multi,c_array_f import numpy as np X = -1 + 2*np.random.rand(10000000) %timeit c_array_f_multi(X) 10 loops, best of 3: 52.3 ms per loop %timeit c_array_f(X) 10 loops, best of 3: 81.3 ms per loop Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:23:06 "},"python性能优化/Cython的包装模式.html":{"url":"python性能优化/Cython的包装模式.html","title":"Cython的包装模式","keywords":"","body":"用Cython包装C++代码 Cython最大的作用其实是作为C/C++代码和python代码的桥梁,比如我们已经有一个C++写的程序了,但我们希望让python可以调用它,传统的做法是使用ctypes或者cffi作为桥,但这种方式需要有相当的C/C++知识.Cython的话基本可以无痛进行C++代码的包装,这是通过使用外部声明来声明库函数和要使用的库中的C函数来实现的. Cython现在原生的支持大多数的C++语法. 尤其是: 现在可以使用new和del关键字动态分配C++对象. C++对象可以进行堆栈分配 C++类可以使用新的关键字cppclass声明 支持模板化类和函数 支持重载函数 支持C++操作符(例如operator +,operator [],...)的重载 我们通过包装一个例子来看看cython是如何包装c/c++代码的 封装步骤 封装C/C++的步骤大致有如下几步: 在setup.py脚本中或在源文件中本地指定C ++语言。 使用cdef extern from 头文件创建一个或多个.pxd文件.在pxd文件中，以cdef cppclass来声明类并且声明公共名称(变量,方法和构造函数） 通过cimport引入pxd文件，进行pxd的实现代码，也就是.pyx文件。 最简单的一个例子 这个例子用来介绍Cython包装C/C++代码的步骤.例子是一个长方形类,C++代码部分如下: %load_ext Cython %%writefile Rectangle.h namespace shapes { class Rectangle { public: static int do_something(); int x0, y0, x1, y1; Rectangle(); Rectangle(int x0, int y0, int x1, int y1); ~Rectangle(); int getArea(); void getSize(int* width, int* height); void move(int dx, int dy); }; } Overwriting Rectangle.h %%writefile Rectangle.cpp #include \"Rectangle.h\" namespace shapes { Rectangle::Rectangle() { } int Rectangle::do_something(){ return 0; } Rectangle::Rectangle(int X0, int Y0, int X1, int Y1) { x0 = X0; y0 = Y0; x1 = X1; y1 = Y1; } Rectangle::~Rectangle() { } int Rectangle::getArea() { return (x1 - x0) * (y1 - y0); } void Rectangle::getSize(int *width, int *height) { (*width) = x1 - x0; (*height) = y1 - y0; } void Rectangle::move(int dx, int dy) { x0 += dx; y0 += dy; x1 += dx; y1 += dy; } } Overwriting Rectangle.cpp 用于包装的pyx文件 要包装C++文件,我们得先在cython中声明出这个C++的类,在cython中申明C或者C++的内容(接口)需要使用cdef extern from ....这种语法(外部声明). 在 %%writefile rect.pyx #cython: language_level=3 # distutils: language = c++ # distutils: sources = Rectangle.cpp cdef extern from \"Rectangle.h\" namespace \"shapes\": cdef cppclass Rectangle: Rectangle() except + Rectangle(int, int, int, int) except + int x0, y0, x1, y1 int getArea() void getSize(int* width, int* height) void move(int, int) @staticmethod int do_something() cdef class PyRectangle: cdef Rectangle c_rect # hold a C++ instance which we're wrapping def __cinit__(self, int x0, int y0, int x1, int y1): self.c_rect = Rectangle(x0, y0, x1, y1) def get_area(self): return self.c_rect.getArea() def get_size(self): cdef int width, height self.c_rect.getSize(&width, &height) return width, height def move(self, dx, dy): self.c_rect.move(dx, dy) @staticmethod def do_something(): return Rectangle.do_something() Overwriting rect.pyx 这样，我们就完成了C++的封装。而且从Python的开发角度来看，这个扩展类型看起来和感觉就像一个本地定义的Rectangle类。 需要注意的是，如果我们需要额外的属性设置方法，可以自己再添加. setup.py的写法 我们的setup.py和之前差不多的写法 %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"rectangleapp\", ext_modules = cythonize('*.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling rect.pyx because it changed. [1/1] Cythonizing rect.pyx running build_ext building 'rect' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tprect.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\rect.obj rect.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /TpRectangle.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\Rectangle.obj Rectangle.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_rect build\\temp.win-amd64-3.6\\Release\\rect.obj build\\temp.win-amd64-3.6\\Release\\Rectangle.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\rect.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.lib rect.obj : warning LNK4197: export 'PyInit_rect' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\rect.cp36-win_amd64.exp Generating code Finished generating code import rect pyRect = rect.PyRectangle(100, 100, 300, 500) width, height = pyRect.get_size() print(\"size: width = %d, height = %d\" % (width, height)) size: width = 200, height = 400 pyRect.get_area() 80000 pyRect.do_something() 0 外部声明 默认情况下,在模块级声明的C函数和变量对模块是本地的(即它们具有C静态存储类).它们也可以声明为extern，以指定它们在其他位置定义，例如： cdef extern int spam_counter cdef extern void order_spam(int tons) Cython包装C/C++就是依赖这种外部申明 引用头文件 当你使用一个extern定义时，Cython在生成的C文件中包含一个声明.如果声明与其他C代码将看不到的声明不完全匹配，这可能会导致问题.例如，如果要封装现有的C库，那么生成的C代码必须与库的其余部分具有完全相同的声明. 为了实现这一点，你可以告诉Cython声明将在C头文件中找到，如下所示： cdef extern from \"spam.h\": int spam_counter void order_spam(int tons) 引用头文件用于引入C/C++中的声明,但我们依然需要手动将其中被声明的内容用cython语法重新写一遍,这样cython才可以识别. 这个cdef extern代码块定义了如下三件事情： 它指示Cython为生成的C代码中的命名头文件放置一个#include语句. 它阻止Cython为相关块中的声明生成任何C代码 它处理块中的所有声明，就像它们以cdef extern开头 重要的是要理解Cython本身不读取C头文件，所以你仍然需要提供Cython版本你要使用的声明.然而，Cython声明并不总是必须完全匹配C，在某些情况下，它们不应该或不能。尤其是： 不要使用任何平台特定的C语言扩展，例如__declspec() 如果头文件声明一个大结构，并且你只想使用几个成员，你只需要声明你感兴趣的成员.留下余下的没有任何危害，因为C编译器将使用头文件中的完整定义. 在某些情况下，你可能不需要任何struct的成员，在这种情况下，你可以只传递在struct声明的主体，例如： cdef extern from \"foo.h\": struct spam: pass 注意：你只能在一个cdef extern从块里面这样做;任何其他地方的struct声明必须是非空的。 如果头文件使用typedef名称（如word）来引用与平台相关的数值类型的风格，则需要一个相应的ctypedef语句，但不需要完全匹配类型,只是使用一些正确的一般类型(int，float等). 例如： ctypedef int word 将工作正常无论实际大小的单词是(提供的头文件正确定义它).与Python类型(如果有)之间的转换也将用于此新类型. 如果头文件使用宏来定义常量，则将它们转换为正常的外部变量声明。如果它们包含正常的int值，也可以将它们声明为枚举。请注意，Cython认为枚举等同于int，因此不要对非int值执行此操作. 如果头文件使用宏定义了一个函数，那么声明它就像是一个普通的函数，具有适当的参数和结果类型 如果你想包含一个C头，因为它是另一个头需要的，但不想使用它的任何声明，在extern-from块中放入pass关键字： cdef extern from \"spam.h\": pass 如果要包括系统标题，请在引号中加上尖括号： cdef extern from \"\": ... 如果你想包含一些外部声明，但不想指定一个头文件（因为它包含了你已经包含的其他头文件），你可以用*代替头文件名： cdef extern from *: ... 在C/C++中实现 另一种简单的写法是直接使用外部声明声明C/C++实现 %%writefile spam.c #include static int order_spam(int tons) { printf(\"Ordered %i tons of spam!\\n\", tons); return tons; } Overwriting spam.c %%writefile pyspam.pyx cdef extern from \"spam.c\": int order_spam(int tons) cpdef pyorder_spam(int tons): return order_spam(tons) Overwriting pyspam.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"pyspam\", ext_modules = cythonize('pyspam.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling pyspam.pyx because it changed. [1/1] Cythonizing pyspam.pyx running build_ext building 'pyspam' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /Tcpyspam.c /Fobuild\\temp.win-amd64-3.6\\Release\\pyspam.obj pyspam.c C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_pyspam build\\temp.win-amd64-3.6\\Release\\pyspam.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\pyspam.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.lib pyspam.obj : warning LNK4197: export 'PyInit_pyspam' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\pyspam.cp36-win_amd64.exp Generating code Finished generating code import pyspam pyspam.pyorder_spam(1) 1 需要注意的是这种方式函数必须是static 结构，联合和枚举声明的样式 在C头文件中可以使用两种主要方法来声明结构，联合和枚举： 使用标签名称 使用typedef 基于这些的各种组合也存在一些变化.重要的是使Cython声明与头文件中使用的样式相匹配,以便Cython能够对其生成的代码中的类型发出正确的引用. 为了实现这一点,Cython提供了两种不同的语法来声明结构,联合或枚举类型.上面介绍的样式对应于标签名的使用.要获得另一个样式,您需要在声明前面加上ctypedef,如下图所示. 下表显示了可以在头文件中找到的各种可能的样式，以及应该放在cdef extern from块中的相应Cython声明。用结构体声明作为例子;这同样适用于联合和枚举声明. 静态成员方法 如果开头我们定义的C++类Rectangle类具有静态成员,那么如上面的做法..就像python中一样,使用@staticmethod装饰器装饰对应的成员方法即可 运算符重载 这个例子是一个vector2d,实现了加和乘. %%writefile vector2d.h namespace algebra { class Vec2d { public: double x, y; Vec2d(); Vec2d(double x, double y); ~Vec2d(); Vec2d operator+(const Vec2d& b); Vec2d operator*(double k); }; } Overwriting vector2d.h %%writefile vector2d.cpp #include \"vector2d.h\" namespace algebra { Vec2d::Vec2d() { x=0; y=0; } Vec2d::Vec2d(double x, double y) { this->x = x; this->y = y; } Vec2d::~Vec2d() { } Vec2d Vec2d::operator+(const Vec2d& other){ Vec2d r = Vec2d(this->x+other.x,this->y+other.y); return r; } Vec2d Vec2d::operator*(double k){ Vec2d r = Vec2d(this->x*k,this->y*k); return r; } } Overwriting vector2d.cpp %%writefile vec2d_main.cpp #include \"vector2d.h\" #include using algebra::Vec2d; using std::cout; using std::endl; int main(){ Vec2d v1 = Vec2d(2.1,2.2); Vec2d v2 = Vec2d(2.3,2.4); Vec2d v3 = v1+v2; cout Overwriting vec2d_main.cpp !g++-7 -o a.out vec2d_main.cpp vector2d.cpp !./a.out 4.4 4.6 %%writefile vec2d.pyx #cython: language_level=3 # distutils: language = c++ # distutils: sources = vector2d.cpp cdef extern from \"vector2d.h\" namespace \"algebra\": cdef cppclass Vec2d: Vec2d() except + Vec2d(double, double) except + double x, y Vec2d operator+(Vec2d) Vec2d operator*(float) cdef class PyVec2d: cdef Vec2d c_vec2d # hold a C++ instance which we're wrapping def __cinit__(self, float x, float y): self.c_vec2d = Vec2d(x, y) @property def x(self): return self.c_vec2d.x @property def y(self): return self.c_vec2d.y cpdef add(self,PyVec2d other): cdef Vec2d c c = self.c_vec2d+other.c_vec2d return PyVec2d(c.x,c.y) cpdef mul(self,float k): cdef Vec2d c c = self.c_vec2d*k return PyVec2d(c.x,c.y) def __add__(self,PyVec2d other): return self.add(other) def __mul__(self,float k): return self.mul(k) Overwriting vec2d.pyx %%writefile setup.py from distutils.core import setup from Cython.Build import cythonize setup( name = \"vec2dapp\", ext_modules = cythonize('vec2d.pyx') ) Overwriting setup.py !python setup.py build_ext --inplace Compiling vec2d.pyx because it changed. [1/1] Cythonizing vec2d.pyx running build_ext building 'vec2d' extension C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tpvec2d.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\vec2d.obj vec2d.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\87\\Anaconda3\\include -IC:\\Users\\87\\Anaconda3\\include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt\" /EHsc /Tpvector2d.cpp /Fobuild\\temp.win-amd64-3.6\\Release\\vector2d.obj vector2d.cpp C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\87\\Anaconda3\\libs /LIBPATH:C:\\Users\\87\\Anaconda3\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64\" /EXPORT:PyInit_vec2d build\\temp.win-amd64-3.6\\Release\\vec2d.obj build\\temp.win-amd64-3.6\\Release\\vector2d.obj /OUT:C:\\Users\\87\\Documents\\GitHub\\my\\TutorialForPython\\ipynbs\\python性能优化\\Cython的包装模式\\vec2d.cp36-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.lib vec2d.obj : warning LNK4197: export 'PyInit_vec2d' specified multiple times; using first specification Creating library build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.lib and object build\\temp.win-amd64-3.6\\Release\\vec2d.cp36-win_amd64.exp Generating code Finished generating code import vec2d v1 = vec2d.PyVec2d(2.1,2.2) v2 = vec2d.PyVec2d(2.3,2.4) (v1+v2).x 4.399999618530273 模板 Cython使用括号语法进行模板化。下面是一个包装C ++ Vector的简单示例 %%cython #cython: language_level=3 # distutils: language = c++ # import dereference and increment operators from cython.operator cimport dereference as deref, preincrement as inc cdef extern from \"\" namespace \"std\": cdef cppclass vector[T]: cppclass iterator: T operator*() iterator operator++() bint operator==(iterator) bint operator!=(iterator) vector() void push_back(T&) T& operator[](int) T& at(int) iterator begin() iterator end() cdef vector[int] *v = new vector[int]() cdef int i for i in range(10): v.push_back(i) cdef vector[int].iterator it = v.begin() while it != v.end(): print(deref(it)) inc(it) del v 0 1 2 3 4 5 6 7 8 9 多个模板参数可以定义为列表，如[T，U，V]或[int，bool，char].可以通过写入[T，U，V = *]来指示可选的模板参数. 如果Cython需要显式引用不完整模板实例化的默认模板参数的类型,它将编写MyClass :: V，所以如果类为其模板参数提供了typedef，那么最好在这里使用该名称. 模板函数的定义与类模板类似，模板参数列表跟随函数名称： %%cython # cython: language_level=3 # distutils: language = c++ cdef extern from \"\" namespace \"std\": T max[T](T a, T b) print(max[long](3, 4)) print(max(1.5, 2.5)) # simple template argument deduction 4 2.5 使用默认构造函数简化包装 如果扩展类型使用默认构造函数(不传递任何参数)来实例化包装的C++类，则可以通过将其直接绑定到Python包装器对象的生命周期来简化生命周期处理。取代声明一个指针，我们可以声明一个实例 %%cython #cython: language_level=3 # distutils: language = c++ from libcpp.vector cimport vector cdef class VectorStack: cdef vector[int] v def push(self, x): self.v.push_back(x) def pop(self): if self.v.empty(): raise IndexError() x = self.v.back() self.v.pop_back() return x v = VectorStack() v.push(10) v.push(120) v.pop() 120 v.pop() 10 当Python对象被创建时，Cython将自动生成实例化C ++对象实例的代码，并在Python对象被垃圾回收时将其删除。 异常Exception处理 Cython不能抛出C++异常,或者使用try-except语句来捕获它们,但是有可能通过在声明函数时在其后加上except +来声明一个函数可能引发C++异常并将其转换为Python异常.例如长方体例子中的 Rectangle() except + Rectangle(int, int, int, int) except + 这将将try和C++错误翻译成适当的Python异常。根据下表执行翻译（C++标识符中省略了std ::前缀）： C++异常 Python异常 bad_alloc MemoryError bad_cast TypeError bad_typeid TypeError domain_error ValueError invalid_argument ValueError ios_base::failure IOError out_of_range IndexError overflow_error OverflowError range_error ArithmeticError underflow_error ArithmeticError (all others) RuntimeError 如果except +后面加上指定的python错误类型,则会将捕获到的C++异常转化为指定的python错误 cdef int bar() except +MemoryError 就会指定bar()函数报错后转化为MemoryError 同时也可以通过实现一个函数来指定捕获的错误转化为何种python异常 cdef int raise_py_error() cdef int something_dangerous() except +raise_py_error 如果有不可预知的错误代码引发了一个C++异常，那么raise_py_error将被调用，这允许一个人自定义C++到Python的错误“translations”.如果raise_py_error实际上并不引发一个异常，则会引发一个RuntimeError. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:20:04 "},"python性能优化/结语.html":{"url":"python性能优化/结语.html","title":"结语","keywords":"","body":"结语 Cython是最流行的python扩展方式,虽然它还有很多不足之处,但其易用性,简单的语法以及对C++的支持已经非常够用. Cython本身还在发展,在不就后以后会有包括type hints支持在内更多的便利特性. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-07-25 21:36:28 "}}